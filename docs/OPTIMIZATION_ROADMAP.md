# è´¢ç»æŠ¥å‘Šç³»ç»Ÿä¼˜åŒ–è·¯çº¿å›¾

> ğŸ“… åˆ›å»ºæ—¥æœŸ: 2025-10-11  
> ğŸ¯ ä¼˜åŒ–ç›®æ ‡: æå‡æŠ¥å‘Šè´¨é‡ã€å‡†ç¡®åº¦ã€å¯æ“ä½œæ€§  
> ğŸ“Š å½“å‰ç‰ˆæœ¬: v1.0  

---

## ğŸ“‹ ä¼˜åŒ–æ¦‚è§ˆ

| ç±»åˆ« | ä¼˜åŒ–é¡¹æ•°é‡ | å·²å®Œæˆ | è¿›è¡Œä¸­ | å¾…å¼€å§‹ |
|------|-----------|--------|--------|--------|
| æ•°æ®è´¨é‡ | 4 | 0 | 0 | 4 |
| AIåˆ†æä¼˜åŒ– | 6 | 0 | 0 | 6 |
| æ€§èƒ½ä¼˜åŒ– | 3 | 0 | 0 | 3 |
| ç”¨æˆ·ä½“éªŒ | 4 | 0 | 0 | 4 |
| ç³»ç»Ÿç¨³å®šæ€§ | 3 | 0 | 0 | 3 |
| **æ€»è®¡** | **20** | **0** | **0** | **20** |

---

## ğŸ¯ ä¼˜å…ˆçº§åˆ†çº§

- ğŸ”´ **P0 (ç«‹å³å®æ–½)**: å¯¹æŠ¥å‘Šè´¨é‡/å‡†ç¡®åº¦å½±å“æœ€å¤§ï¼Œå®æ–½æˆæœ¬ä½
- ğŸŸ  **P1 (çŸ­æœŸå®æ–½)**: é‡è¦ä½†éœ€è¦ä¸€å®šå¼€å‘æ—¶é—´ (1-2å‘¨)
- ğŸŸ¡ **P2 (ä¸­æœŸå®æ–½)**: é”¦ä¸Šæ·»èŠ±ï¼Œå¯é€æ­¥å®æ–½ (1-2æœˆ)
- ğŸŸ¢ **P3 (é•¿æœŸè§„åˆ’)**: é«˜çº§åŠŸèƒ½ï¼Œå¯é€‰å®æ–½ (3æœˆ+)

---

## ğŸ”´ P0: ç«‹å³å®æ–½ (æœ€é«˜ROI)

### 1. å¢åŠ "è¯æ®é“¾"æœºåˆ¶ â­â­â­

**çŠ¶æ€**: â¬œ å¾…å¼€å§‹  
**ä¼˜å…ˆçº§**: P0  
**é¢„è®¡å·¥æ—¶**: 2å°æ—¶  
**å®Œæˆæ—¥æœŸ**: _____  

#### é—®é¢˜æè¿°
å½“å‰AIç»™å‡ºç»“è®ºï¼Œä½†ä¸çŸ¥é“åŸºäºå“ªæ¡æ–°é—»ï¼Œç¼ºä¹å¯è¿½æº¯æ€§å’Œå¯éªŒè¯æ€§ã€‚

#### è§£å†³æ–¹æ¡ˆ
1. ç»™æ¯æ¡æ–°é—»æ·»åŠ ç¼–å·ç´¢å¼•
2. ä¿®æ”¹Promptè¦æ±‚AIå¼•ç”¨æ¥æº
3. åŒºåˆ†"æ–°é—»æ˜ç¡®æåŠ" vs "åˆ†ææ¨æ–­"

#### æŠ€æœ¯å®ç°
```python
# æ–‡ä»¶: scripts/utils/news_formatter.py
def format_news_with_index(articles):
    """ç»™æ¯æ¡æ–°é—»åŠ ä¸Šç¼–å·ï¼Œæ–¹ä¾¿AIå¼•ç”¨"""
    formatted = []
    for i, article in enumerate(articles, 1):
        formatted.append(f"""
ã€æ–°é—»{i}ã€‘
æ¥æº: {article.source_name}
æ ‡é¢˜: {article.title}
å‘å¸ƒæ—¶é—´: {article.published}
å†…å®¹: {article.summary}
é“¾æ¥: {article.link}
---
""")
    return "\n".join(formatted)
```

#### Prompt ä¿®æ”¹
åœ¨ `task/financial_analysis_prompt_pro.md` ä¸­æ·»åŠ ï¼š
```markdown
### è¯æ®å¼•ç”¨è¦æ±‚
æ¯ä¸ªé‡è¦è§‚ç‚¹å¿…é¡»æ³¨æ˜æ¥æºï¼š
- ä½¿ç”¨ã€æ–°é—»Xã€‘æ ‡æ³¨å¼•ç”¨
- åŒºåˆ†"æ–°é—»æ˜ç¡®æåŠ"vs"åˆ†ææ¨æ–­"
- ä¼˜å…ˆä½¿ç”¨æ–°é—»ä¸­çš„æ•°æ®ï¼Œé¿å…è‡†æµ‹

ç¤ºä¾‹ï¼š
**å¸‚åœºæƒ…ç»ª**: å¸‚åœºæƒ…ç»ªå·²è½¬ä¸ºæåº¦ææ…Œã€æ–°é—»3:ç¾è‚¡æš´è·Œã€‘ã€‚
VIXæŒ‡æ•°å¤§å¹…é£™å‡ã€æ¨æ–­ï¼šåŸºäºé¿é™©æƒ…ç»ªã€‘ã€‚
```

#### é¢„æœŸæ•ˆæœ
- âœ… æŠ¥å‘Šå¯è¿½æº¯ã€å¯éªŒè¯
- âœ… æå‡ç”¨æˆ·ä¿¡ä»»åº¦
- âœ… æ–¹ä¾¿åç»­å®¡æ ¸å’Œä¼˜åŒ–

#### æ¶‰åŠæ–‡ä»¶
- [ ] `scripts/utils/news_formatter.py` (æ–°å»º)
- [ ] `task/financial_analysis_prompt_pro.md` (ä¿®æ”¹)
- [ ] `scripts/ai_analyze.py` (è°ƒç”¨formatter)
- [ ] `scripts/ai_analyze_deepseek.py` (è°ƒç”¨formatter)

---

### 2. åˆ é™¤å®¹æ˜“å‡ºé”™çš„"å…·ä½“æ¨è" â­â­â­

**çŠ¶æ€**: â¬œ å¾…å¼€å§‹  
**ä¼˜å…ˆçº§**: P0  
**é¢„è®¡å·¥æ—¶**: 1å°æ—¶  
**å®Œæˆæ—¥æœŸ**: _____  

#### é—®é¢˜æè¿°
AIä¸çŸ¥é“å®æ—¶å¸‚åœºæ•°æ®ï¼Œä½†Promptè¦æ±‚è¾“å‡ºï¼š
- å…·ä½“è‚¡ç¥¨ä»£ç ï¼ˆå¯èƒ½ç¼–é€ ï¼‰
- ç›®æ ‡æ¶¨å¹…ç™¾åˆ†æ¯”ï¼ˆæ²¡æœ‰ä¾æ®ï¼‰
- æœªæ¥äº‹ä»¶æ—¥å†ï¼ˆAIä¸çŸ¥é“ï¼‰

#### è§£å†³æ–¹æ¡ˆ
ä¿®æ”¹è¾“å‡ºæ ¼å¼ï¼Œæ”¹ä¸ºæ–¹å‘æ€§å»ºè®®è€Œéå…·ä½“æ ‡çš„

#### Prompt ä¿®æ”¹
**åˆ é™¤éƒ¨åˆ†**:
```markdown
âŒ åˆ é™¤
## ğŸ’¼ æŠ•èµ„ç»„åˆå»ºè®®
| è‚¡ç¥¨ä»£ç  | è‚¡ç¥¨åç§° | æ¨èç†ç”± | ç›®æ ‡æ¶¨å¹… | é£é™©ç­‰çº§ |
```

**æ›¿æ¢ä¸º**:
```markdown
âœ… æ”¹ä¸º
## ğŸ’¼ æŠ•èµ„æ–¹å‘å»ºè®®
| æŠ•èµ„æ–¹å‘ | å—ç›Šé€»è¾‘ | é£é™©ç­‰çº§ | å‚è€ƒæ ‡çš„ç±»å‹ | æ–°é—»æ¥æº |
|---------|---------|---------|------------|---------|
| ç‡ƒæ°”è½®æœºåˆ¶é€  | AIæ•°æ®ä¸­å¿ƒç”µåŠ›éœ€æ±‚ | ä¸­ | å¤§å‹è®¾å¤‡åˆ¶é€ å•† | ã€æ–°é—»5,12ã€‘ |
| é»„é‡‘çŸ¿ä¼ | é¿é™©éœ€æ±‚+å»ç¾å…ƒåŒ– | ä½ | é»„é‡‘ETFæˆ–çŸ¿ä¼ | ã€æ–°é—»3,7ã€‘ |

### æ“ä½œå»ºè®®ï¼ˆä¸ç»™å…·ä½“æ•°å­—ï¼‰
- **æ—¶é—´çª—å£**: åŸºäºæ–°é—»åˆ¤æ–­åˆç†æŠ•èµ„å‘¨æœŸ
- **ä»“ä½å»ºè®®**: å•ä¸€æ–¹å‘ä¸è¶…è¿‡20%ï¼Œåˆ†æ•£é…ç½®
- **é£é™©æ§åˆ¶**: å»ºè®®æ­¢æŸä½åœ¨ä¹°å…¥ä»·-8%è‡³-10%
- **å…³æ³¨æŒ‡æ ‡**: [åŸºäºæ–°é—»æç‚¼çš„å…³é”®æŒ‡æ ‡]
```

#### é¢„æœŸæ•ˆæœ
- âœ… é¿å…AIç¼–é€ ä¿¡æ¯
- âœ… é™ä½è¯¯å¯¼é£é™©
- âœ… æ›´ç¬¦åˆæŠ•èµ„å»ºè®®åˆè§„æ€§

#### æ¶‰åŠæ–‡ä»¶
- [ ] `task/financial_analysis_prompt_pro.md` (ä¿®æ”¹)
- [ ] `task/financial_analysis_prompt_safe.md` (å¯é€‰åˆ›å»ºå®‰å…¨ç‰ˆæœ¬)

---

### 3. æ–°é—»è´¨é‡ç­›é€‰å’Œæ’åº â­â­â­

**çŠ¶æ€**: â¬œ å¾…å¼€å§‹  
**ä¼˜å…ˆçº§**: P0  
**é¢„è®¡å·¥æ—¶**: 4å°æ—¶  
**å®Œæˆæ—¥æœŸ**: _____  

#### é—®é¢˜æè¿°
å½“å‰æ‰€æœ‰æ–°é—»å¹³ç­‰å¯¹å¾…ï¼Œä½†è´¨é‡å‚å·®ä¸é½ï¼š
- ä½è´¨é‡å†…å®¹ï¼ˆæ ‡é¢˜å…šã€è¥é”€è½¯æ–‡ï¼‰
- é‡å¤å†…å®¹ï¼ˆåŒä¸€æ–°é—»å¤šä¸ªæ¥æºï¼‰
- ç¼ºå°‘ä¼˜å…ˆçº§æ’åº

#### è§£å†³æ–¹æ¡ˆ
å®ç°æ™ºèƒ½è¿‡æ»¤å’Œæ’åºç³»ç»Ÿ

#### æŠ€æœ¯å®ç°
```python
# æ–‡ä»¶: scripts/utils/quality_filter.py

def quality_filter_and_rank(articles):
    """æ–°é—»è´¨é‡ç­›é€‰+æ’åº"""
    
    # 1. æ¥æºæƒé‡é…ç½®
    SOURCE_WEIGHTS = {
        "åå°”è¡—è§é—»": 3.0,
        "FTä¸­æ–‡ç½‘": 3.0,
        "Bloomberg": 3.0,
        "å›½å®¶ç»Ÿè®¡å±€": 5.0,  # å®˜æ–¹æ•°æ®æœ€é«˜
        "å¤®è¡Œ": 5.0,
        "36æ°ª": 1.5,
        "ä¸œæ–¹è´¢å¯Œ": 1.5,
    }
    
    # 2. é‡è¦å…³é”®è¯ï¼ˆæå‡æƒé‡ï¼‰
    IMPORTANT_KEYWORDS = [
        "ç¾è”å‚¨", "å¤®è¡Œ", "GDP", "CPI", "åŠ æ¯", "é™æ¯",
        "è´¢æŠ¥", "å¹¶è´­", "ç ´äº§", "IPO",
        "æ”¿ç­–", "ç›‘ç®¡", "åˆ¶è£", "å…³ç¨"
    ]
    
    # 3. åƒåœ¾å…³é”®è¯ï¼ˆé™ä½æƒé‡ï¼‰
    SPAM_KEYWORDS = [
        "ç‚¹å‡»è´­ä¹°", "é™æ—¶ä¼˜æƒ ", "æ‰«ç å…³æ³¨", 
        "å¹¿å‘Š", "æ¨å¹¿", "èµåŠ©"
    ]
    
    scored_articles = []
    
    for article in articles:
        score = 0.0
        
        # æ¥æºæƒé‡
        score += SOURCE_WEIGHTS.get(article.source_name, 1.0)
        
        # å†…å®¹é•¿åº¦ï¼ˆè´¨é‡æŒ‡æ ‡ï¼‰
        if len(article.summary or "") > 200:
            score += 1.0
        if article.content and len(article.content) > 500:
            score += 1.0
        
        # é‡è¦å…³é”®è¯
        text = f"{article.title} {article.summary or ''}"
        for kw in IMPORTANT_KEYWORDS:
            if kw in text:
                score += 0.5
        
        # åƒåœ¾å†…å®¹æƒ©ç½š
        for kw in SPAM_KEYWORDS:
            if kw in text:
                score -= 2.0
        
        # æ ‡é¢˜å…šæ£€æµ‹ï¼ˆè¿‡å¤šæ ‡ç‚¹ç¬¦å·ï¼‰
        punctuation_count = sum(text.count(p) for p in "ï¼ï¼Ÿ!?")
        if punctuation_count > 3:
            score -= 1.0
        
        scored_articles.append((article, score))
    
    # æ’åº
    scored_articles.sort(key=lambda x: x[1], reverse=True)
    
    # è¿‡æ»¤ä½è´¨é‡ï¼ˆé˜ˆå€¼å¯è°ƒï¼‰
    QUALITY_THRESHOLD = 2.0
    filtered = [a for a, s in scored_articles if s >= QUALITY_THRESHOLD]
    
    # æ™ºèƒ½å»é‡
    filtered = smart_dedup(filtered)
    
    logger.info(f"ç­›é€‰å‰: {len(articles)}ç¯‡, ç­›é€‰å: {len(filtered)}ç¯‡")
    return filtered

def smart_dedup(articles):
    """æ™ºèƒ½å»é‡ï¼šæ ‡é¢˜ç›¸ä¼¼åº¦>0.8è§†ä¸ºåŒä¸€æ–°é—»"""
    from difflib import SequenceMatcher
    
    groups = []
    for article in articles:
        matched = False
        for group in groups:
            similarity = SequenceMatcher(
                None, 
                article.title, 
                group[0].title
            ).ratio()
            if similarity > 0.8:
                group.append(article)
                matched = True
                break
        if not matched:
            groups.append([article])
    
    # æ¯ç»„é€‰æœ€ä¼˜è´¨çš„
    best_articles = []
    for group in groups:
        # ä¼˜å…ˆï¼š1.é«˜æƒé‡æ¥æº 2.å†…å®¹å®Œæ•´ 3.å‘å¸ƒæ—¶é—´æ—©
        best = max(group, key=lambda a: (
            SOURCE_WEIGHTS.get(a.source_name, 1.0),
            len(a.content or ""),
            -a.published.timestamp() if a.published else 0
        ))
        best_articles.append(best)
    
    return best_articles
```

#### é›†æˆæ–¹å¼
åœ¨ `ai_analyze.py` ä¸­è°ƒç”¨ï¼š
```python
from utils.quality_filter import quality_filter_and_rank

# æŸ¥è¯¢æ–°é—»å
articles = query_news_from_db(...)
# æ·»åŠ è´¨é‡ç­›é€‰
articles = quality_filter_and_rank(articles)
# å†ä¼ ç»™AIåˆ†æ
```

#### é¢„æœŸæ•ˆæœ
- âœ… æå‡åˆ†æè¾“å…¥è´¨é‡
- âœ… å‡å°‘å™ªéŸ³å’Œå¹²æ‰°
- âœ… é™ä½AIåˆ†ææˆæœ¬ï¼ˆtokenæ•°å‡å°‘ï¼‰

#### æ¶‰åŠæ–‡ä»¶
- [ ] `scripts/utils/quality_filter.py` (æ–°å»º)
- [ ] `scripts/ai_analyze.py` (é›†æˆ)
- [ ] `scripts/ai_analyze_deepseek.py` (é›†æˆ)

---

## ğŸŸ  P1: çŸ­æœŸå®æ–½ (1-2å‘¨)

### 4. ä¸¤é˜¶æ®µåˆ†ææµç¨‹ â­â­â­

**çŠ¶æ€**: â¬œ å¾…å¼€å§‹  
**ä¼˜å…ˆçº§**: P1  
**é¢„è®¡å·¥æ—¶**: 6å°æ—¶  
**å®Œæˆæ—¥æœŸ**: _____  

#### é—®é¢˜æè¿°
å½“å‰ä¸€æ¬¡æ€§ç”ŸæˆæŠ¥å‘Šï¼Œå®¹æ˜“"ä¸ºäº†å¡«è¡¨è€Œå¡«è¡¨"ï¼Œé€»è¾‘é“¾æ¡ä¸å¤Ÿæ¸…æ™°ã€‚

#### è§£å†³æ–¹æ¡ˆ
åˆ†ä¸¤é˜¶æ®µï¼šå…ˆæå–ä¿¡æ¯ï¼Œå†ç”ŸæˆæŠ¥å‘Š

**é˜¶æ®µ1: ä¿¡æ¯æå–**
```markdown
# Prompt: task/analysis_stage1_extraction.md

ä½ æ˜¯ä¸“ä¸šçš„è´¢ç»ä¿¡æ¯åˆ†æå¸ˆï¼Œè¯·ä»ä»¥ä¸‹æ–°é—»ä¸­æå–å…³é”®ä¿¡æ¯ï¼š

## æå–è¦æ±‚

### 1. é‡å¤§äº‹ä»¶
- æ”¿ç­–å˜åŒ–ï¼ˆè´§å¸ã€è´¢æ”¿ã€ç›‘ç®¡ç­‰ï¼‰
- ç»æµæ•°æ®ï¼ˆGDPã€CPIã€å°±ä¸šç­‰ï¼‰
- çªå‘äº‹ä»¶ï¼ˆç ´äº§ã€å¹¶è´­ã€åœ°ç¼˜æ”¿æ²»ç­‰ï¼‰

### 2. å¸‚åœºå˜åŒ–
- æ¶¨è·Œæƒ…å†µï¼ˆæŒ‡æ•°ã€æ¿å—ã€ä¸ªè‚¡ï¼‰
- èµ„é‡‘æµå‘ï¼ˆä¹°å…¥/å–å‡ºã€æµå…¥/æµå‡ºï¼‰
- å¸‚åœºæƒ…ç»ªï¼ˆææ…Œ/ä¹è§‚ã€é¿é™©/é£é™©åå¥½ï¼‰

### 3. æŠ•èµ„æœºä¼š
- çƒ­ç‚¹è¡Œä¸š/ä¸»é¢˜
- å—ç›Šå…¬å¸ç±»å‹
- å‚¬åŒ–å‰‚åˆ†æ

### 4. é£é™©å› ç´ 
- ç³»ç»Ÿæ€§é£é™©
- è¡Œä¸šé£é™©
- å…·ä½“é£é™©äº‹ä»¶

## è¾“å‡ºæ ¼å¼
æ¯ä¸ªè¦ç‚¹å¿…é¡»ï¼š
1. æ³¨æ˜æ¥æºã€æ–°é—»Xã€‘
2. åŒºåˆ†"äº‹å®"ï¼ˆæ–°é—»æ˜ç¡®ï¼‰vs "æ¨æµ‹"ï¼ˆåˆç†æ¨æ–­ï¼‰
3. æå–å…·ä½“æ•°æ®ï¼ˆæ¶¨è·Œå¹…ã€é‡‘é¢ç­‰ï¼‰

## ç¤ºä¾‹
### é‡å¤§äº‹ä»¶
- **è´¸æ˜“æˆ˜å‡çº§**: ç‰¹æœ—æ™®å¨èƒå¯¹ä¸­å›½å•†å“å¾æ”¶100%å…³ç¨ã€æ–°é—»3ã€‘ã€äº‹å®ã€‘
- **å¸‚åœºååº”**: å¯èƒ½å¯¼è‡´ä¾›åº”é“¾ä¸­æ–­ã€æ¨æµ‹ã€‘

### å¸‚åœºå˜åŒ–
- **ç¾è‚¡æš´è·Œ**: æ ‡æ™®è·Œ2.9%ï¼Œçº³æŒ‡è·Œ3.1%ã€æ–°é—»7ã€‘ã€äº‹å®ã€‘
- **é¿é™©æƒ…ç»ª**: é»„é‡‘æ¶¨1.8%çªç ´4000ç¾å…ƒã€æ–°é—»12ã€‘ã€äº‹å®ã€‘
```

**é˜¶æ®µ2: æŠ¥å‘Šç”Ÿæˆ**
```markdown
# Prompt: task/analysis_stage2_report.md

åŸºäºä»¥ä¸‹ä¿¡æ¯æå–ç»“æœï¼Œç”Ÿæˆä¸“ä¸šæŠ•èµ„åˆ†ææŠ¥å‘Šã€‚

## æŠ¥å‘Šè¦æ±‚
1. é€»è¾‘é“¾æ¡æ¸…æ™°ï¼šäº‹ä»¶ â†’ å½±å“ â†’ æœºä¼š â†’ é£é™©
2. å»ºè®®å¯æ“ä½œï¼šæ˜ç¡®æ—¶é—´çª—å£ã€é£é™©ç­‰çº§
3. é£é™©æç¤ºå……åˆ†ï¼šä¸è¿‡åº¦ä¹è§‚
4. ä¿ç•™æ–°é—»ç´¢å¼•ï¼šæ–¹ä¾¿è¿½æº¯éªŒè¯

## ä¿¡æ¯æå–ç»“æœ
[æ’å…¥é˜¶æ®µ1çš„è¾“å‡º]
```

#### æŠ€æœ¯å®ç°
```python
# æ–‡ä»¶: scripts/ai_analyze.py æ·»åŠ å‡½æ•°

def two_stage_analysis(articles, model='gemini'):
    """ä¸¤é˜¶æ®µAIåˆ†æ"""
    
    # æ ¼å¼åŒ–æ–°é—»ï¼ˆå¸¦ç´¢å¼•ï¼‰
    formatted_news = format_news_with_index(articles)
    
    # é˜¶æ®µ1: ä¿¡æ¯æå–
    stage1_prompt = load_prompt('task/analysis_stage1_extraction.md')
    stage1_input = stage1_prompt + "\n\n" + formatted_news
    
    print("ğŸ” é˜¶æ®µ1: ä¿¡æ¯æå–ä¸­...")
    stage1_result = call_ai_api(stage1_input, model)
    
    # ä¿å­˜ä¸­é—´ç»“æœï¼ˆä¾¿äºè°ƒè¯•å’Œå®¡æ ¸ï¼‰
    save_stage1_result(stage1_result)
    
    # å¯é€‰ï¼šäººå·¥å®¡æ ¸ç‚¹
    if os.getenv('MANUAL_REVIEW') == 'true':
        print("\n=== é˜¶æ®µ1æå–ç»“æœ ===")
        print(stage1_result)
        if input("\nç»§ç»­é˜¶æ®µ2ï¼Ÿ[y/n]: ").lower() != 'y':
            return None
    
    # é˜¶æ®µ2: æŠ¥å‘Šç”Ÿæˆ
    stage2_prompt = load_prompt('task/analysis_stage2_report.md')
    stage2_input = stage2_prompt + "\n\n" + stage1_result
    
    print("ğŸ“ é˜¶æ®µ2: æŠ¥å‘Šç”Ÿæˆä¸­...")
    stage2_result = call_ai_api(stage2_input, model)
    
    return stage2_result
```

#### é¢„æœŸæ•ˆæœ
- âœ… æå‡åˆ†æè´¨é‡å’Œé€»è¾‘æ€§
- âœ… å¯åœ¨ä¸­é—´æ’å…¥éªŒè¯ç¯èŠ‚
- âœ… ä¾¿äºè°ƒè¯•å’Œä¼˜åŒ–

#### æ¶‰åŠæ–‡ä»¶
- [ ] `task/analysis_stage1_extraction.md` (æ–°å»º)
- [ ] `task/analysis_stage2_report.md` (æ–°å»º)
- [ ] `scripts/ai_analyze.py` (æ·»åŠ two_stage_analysiså‡½æ•°)
- [ ] `scripts/ai_analyze_deepseek.py` (åŒæ­¥ä¿®æ”¹)

---

### 5. æŠ¥å‘Šè´¨é‡è‡ªåŠ¨æ£€æŸ¥ â­â­

**çŠ¶æ€**: â¬œ å¾…å¼€å§‹  
**ä¼˜å…ˆçº§**: P1  
**é¢„è®¡å·¥æ—¶**: 3å°æ—¶  
**å®Œæˆæ—¥æœŸ**: _____  

#### é—®é¢˜æè¿°
ç”Ÿæˆçš„æŠ¥å‘Šè´¨é‡ä¸ç¨³å®šï¼Œç¼ºå°‘è‡ªåŠ¨åŒ–è´¨é‡æ£€æŸ¥æœºåˆ¶ã€‚

#### è§£å†³æ–¹æ¡ˆ
å®ç°æŠ¥å‘Šè´¨é‡è‡ªåŠ¨æ£€æŸ¥ç³»ç»Ÿ

#### æŠ€æœ¯å®ç°
```python
# æ–‡ä»¶: scripts/utils/quality_checker.py

import re
from typing import List, Dict

def check_report_quality(report_text: str) -> Dict:
    """æ£€æŸ¥æŠ¥å‘Šè´¨é‡"""
    
    issues = []
    warnings = []
    stats = {}
    
    # 1. åŸºæœ¬ç»“æ„æ£€æŸ¥
    required_sections = [
        "å¸‚åœºæ¦‚å†µ", "æŠ•èµ„ä¸»é¢˜", "é£é™©", "å»ºè®®"
    ]
    for section in required_sections:
        if section not in report_text:
            issues.append(f"âŒ ç¼ºå°‘å¿…è¦ç« èŠ‚: {section}")
    
    # 2. è¯æ®å¼•ç”¨æ£€æŸ¥
    citations = re.findall(r'ã€æ–°é—»\d+ã€‘', report_text)
    stats['citations_count'] = len(citations)
    if len(citations) < 10:
        warnings.append(f"âš ï¸ å¼•ç”¨æ¥æºè¾ƒå°‘({len(citations)}å¤„)ï¼Œå»ºè®®å¢åŠ ")
    
    # 3. æ¨¡ç³Šè¡¨è¿°æ£€æŸ¥
    vague_phrases = ["å¯èƒ½", "æˆ–è®¸", "æ®è¯´", "æœ‰äººè®¤ä¸º", "ä¹Ÿè®¸"]
    vague_count = sum(report_text.count(p) for p in vague_phrases)
    stats['vague_count'] = vague_count
    if vague_count > 15:
        warnings.append(f"âš ï¸ æ¨¡ç³Šè¡¨è¿°è¿‡å¤š({vague_count}å¤„)")
    
    # 4. æ•°æ®æ”¯æ’‘æ£€æŸ¥
    data_patterns = [
        r'\d+\.?\d*%',  # ç™¾åˆ†æ¯”
        r'\d+\.?\d*äº¿',  # é‡‘é¢ï¼ˆäº¿ï¼‰
        r'\d+\.?\d*ä¸‡äº¿',
        r'\$\d+',  # ç¾å…ƒ
    ]
    data_count = sum(
        len(re.findall(pattern, report_text)) 
        for pattern in data_patterns
    )
    stats['data_points'] = data_count
    if data_count < 5:
        warnings.append("âš ï¸ å…·ä½“æ•°æ®æ”¯æ’‘è¾ƒå°‘")
    
    # 5. å¯æ“ä½œæ€§æ£€æŸ¥
    actionable_keywords = [
        "å»ºè®®", "ç­–ç•¥", "æ“ä½œ", "é…ç½®", 
        "æ—¶é—´çª—å£", "ä»“ä½", "æ­¢æŸ"
    ]
    actionable_count = sum(
        report_text.count(kw) for kw in actionable_keywords
    )
    stats['actionable_count'] = actionable_count
    if actionable_count < 5:
        issues.append("âŒ å¯æ“ä½œæ€§ä¸è¶³ï¼Œç¼ºå°‘å…·ä½“å»ºè®®")
    
    # 6. é£é™©æç¤ºæ£€æŸ¥
    if report_text.count("é£é™©") < 5:
        issues.append("âŒ é£é™©æç¤ºä¸è¶³")
    
    # 7. é•¿åº¦æ£€æŸ¥
    word_count = len(report_text)
    stats['word_count'] = word_count
    if word_count < 3000:
        warnings.append(f"âš ï¸ æŠ¥å‘Šè¾ƒçŸ­({word_count}å­—)ï¼Œå¯èƒ½ä¸å¤Ÿè¯¦ç»†")
    elif word_count > 15000:
        warnings.append(f"âš ï¸ æŠ¥å‘Šè¿‡é•¿({word_count}å­—)ï¼Œå»ºè®®ç²¾ç®€")
    
    # 8. ç¼–é€ æ£€æµ‹ï¼ˆç®€å•ç‰ˆï¼‰
    suspicious_patterns = [
        r'è‚¡ç¥¨ä»£ç [:ï¼š]\s*[A-Z]{2,4}',  # å¯èƒ½ç¼–é€ çš„è‚¡ç¥¨ä»£ç 
        r'é¢„è®¡æ¶¨å¹…[:ï¼š]\s*\d+%',  # å…·ä½“æ¶¨å¹…æ•°å­—
    ]
    for pattern in suspicious_patterns:
        matches = re.findall(pattern, report_text)
        if matches:
            issues.append(f"âš ï¸ æ£€æµ‹åˆ°å¯èƒ½çš„ç¼–é€ å†…å®¹: {matches[:3]}")
    
    # ç”ŸæˆæŠ¥å‘Š
    quality_score = 100
    quality_score -= len(issues) * 10
    quality_score -= len(warnings) * 3
    quality_score = max(0, quality_score)
    
    result = {
        'score': quality_score,
        'issues': issues,
        'warnings': warnings,
        'stats': stats,
        'passed': len(issues) == 0
    }
    
    return result

def print_quality_report(result: Dict):
    """æ‰“å°è´¨é‡æ£€æŸ¥æŠ¥å‘Š"""
    print("\n" + "="*60)
    print("ğŸ“Š æŠ¥å‘Šè´¨é‡æ£€æŸ¥ç»“æœ")
    print("="*60)
    
    print(f"\næ€»ä½“è¯„åˆ†: {result['score']}/100")
    
    if result['issues']:
        print(f"\nâŒ ä¸¥é‡é—®é¢˜ ({len(result['issues'])}ä¸ª):")
        for issue in result['issues']:
            print(f"  {issue}")
    
    if result['warnings']:
        print(f"\nâš ï¸ è­¦å‘Š ({len(result['warnings'])}ä¸ª):")
        for warning in result['warnings']:
            print(f"  {warning}")
    
    print(f"\nğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
    for key, value in result['stats'].items():
        print(f"  {key}: {value}")
    
    if result['passed']:
        print("\nâœ… è´¨é‡æ£€æŸ¥é€šè¿‡")
    else:
        print("\nâŒ è´¨é‡æ£€æŸ¥æœªé€šè¿‡ï¼Œå»ºè®®ä¼˜åŒ–åå†å‘å¸ƒ")
    
    print("="*60 + "\n")
```

#### é›†æˆæ–¹å¼
```python
# åœ¨ ai_analyze.py ä¸­
from utils.quality_checker import check_report_quality, print_quality_report

# ç”ŸæˆæŠ¥å‘Šå
report = generate_report(...)
quality_result = check_report_quality(report)
print_quality_report(quality_result)

# å¯é€‰ï¼šä¸é€šè¿‡åˆ™é‡è¯•
if not quality_result['passed'] and retry_count < 3:
    print("è´¨é‡ä¸è¾¾æ ‡ï¼Œé‡æ–°ç”Ÿæˆ...")
    report = generate_report(...)
```

#### é¢„æœŸæ•ˆæœ
- âœ… è‡ªåŠ¨åŒ–è´¨é‡æŠŠæ§
- âœ… åŠæ—¶å‘ç°é—®é¢˜
- âœ… å¯é‡åŒ–çš„è´¨é‡æŒ‡æ ‡

#### æ¶‰åŠæ–‡ä»¶
- [ ] `scripts/utils/quality_checker.py` (æ–°å»º)
- [ ] `scripts/ai_analyze.py` (é›†æˆ)
- [ ] `scripts/ai_analyze_deepseek.py` (é›†æˆ)

---

### 6. å¹¶å‘æŠ“å–ä¼˜åŒ– â­â­

**çŠ¶æ€**: â¬œ å¾…å¼€å§‹  
**ä¼˜å…ˆçº§**: P1  
**é¢„è®¡å·¥æ—¶**: 5å°æ—¶  
**å®Œæˆæ—¥æœŸ**: _____  

#### é—®é¢˜æè¿°
å½“å‰ä¸²è¡ŒæŠ“å–14ä¸ªRSSæºï¼Œè€—æ—¶3-5åˆ†é’Ÿã€‚

#### è§£å†³æ–¹æ¡ˆ
æ”¹ç”¨å¼‚æ­¥å¹¶å‘æŠ“å–

#### æŠ€æœ¯å®ç°
```python
# æ–‡ä»¶: scripts/rss_finance_analyzer.py æ”¹é€ 

import asyncio
import aiohttp
from typing import List

async def fetch_rss_async(source: dict, session: aiohttp.ClientSession):
    """å¼‚æ­¥æŠ“å–å•ä¸ªRSSæº"""
    try:
        async with session.get(
            source['url'], 
            timeout=aiohttp.ClientTimeout(total=30)
        ) as response:
            content = await response.text()
            return parse_rss(content, source)
    except Exception as e:
        logger.error(f"æŠ“å–å¤±è´¥ {source['name']}: {e}")
        return []

async def fetch_all_rss_sources(sources: List[dict]):
    """å¹¶å‘æŠ“å–æ‰€æœ‰RSSæº"""
    async with aiohttp.ClientSession() as session:
        tasks = [
            fetch_rss_async(source, session) 
            for source in sources
        ]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # åˆå¹¶ç»“æœ
        all_articles = []
        for result in results:
            if isinstance(result, list):
                all_articles.extend(result)
        
        return all_articles

# ä¸»å‡½æ•°è°ƒç”¨
def main():
    sources = load_rss_sources()
    
    # å¼‚æ­¥æŠ“å–
    articles = asyncio.run(fetch_all_rss_sources(sources))
    
    # åç»­å¤„ç†...
```

#### é¢„æœŸæ•ˆæœ
- âœ… æŠ“å–æ—¶é—´ï¼š3-5åˆ†é’Ÿ â†’ 30ç§’-1åˆ†é’Ÿ
- âœ… æå‡ç”¨æˆ·ä½“éªŒ
- âœ… æ›´å¿«è·å–æœ€æ–°æ•°æ®

#### æ¶‰åŠæ–‡ä»¶
- [ ] `scripts/rss_finance_analyzer.py` (é‡æ„)
- [ ] `requirements.txt` (æ·»åŠ aiohttpä¾èµ–)

---

### 7. æ•°æ®åº“ç´¢å¼•ä¼˜åŒ– â­

**çŠ¶æ€**: â¬œ å¾…å¼€å§‹  
**ä¼˜å…ˆçº§**: P1  
**é¢„è®¡å·¥æ—¶**: 1å°æ—¶  
**å®Œæˆæ—¥æœŸ**: _____  

#### é—®é¢˜æè¿°
å½“å‰æ•°æ®åº“æŸ¥è¯¢æœªä¼˜åŒ–ï¼Œæ•°æ®é‡å¢å¤§åå¯èƒ½å˜æ…¢ã€‚

#### è§£å†³æ–¹æ¡ˆ
æ·»åŠ å¿…è¦çš„ç´¢å¼•

#### æŠ€æœ¯å®ç°
```python
# æ–‡ä»¶: scripts/utils/db_manager.py

def optimize_database(db_path):
    """æ•°æ®åº“ä¼˜åŒ–ï¼šæ·»åŠ ç´¢å¼•"""
    conn = sqlite3.connect(db_path)
    cur = conn.cursor()
    
    # æ·»åŠ ç´¢å¼•
    indexes = [
        "CREATE INDEX IF NOT EXISTS idx_collection_date ON news_articles(collection_date)",
        "CREATE INDEX IF NOT EXISTS idx_source_id ON news_articles(source_id)",
        "CREATE INDEX IF NOT EXISTS idx_published ON news_articles(published)",
        "CREATE INDEX IF NOT EXISTS idx_source_date ON news_articles(source_id, collection_date)",
    ]
    
    for idx_sql in indexes:
        cur.execute(idx_sql)
    
    # ä¼˜åŒ–å…¨æ–‡æœç´¢ï¼ˆå¦‚æœä½¿ç”¨FTS5ï¼‰
    cur.execute("""
        CREATE VIRTUAL TABLE IF NOT EXISTS news_fts 
        USING fts5(title, summary, content, content='news_articles')
    """)
    
    conn.commit()
    conn.close()
    
    logger.info("æ•°æ®åº“ç´¢å¼•ä¼˜åŒ–å®Œæˆ")
```

#### é¢„æœŸæ•ˆæœ
- âœ… æŸ¥è¯¢é€Ÿåº¦æå‡50%+
- âœ… æ”¯æŒæ›´å¤§æ•°æ®é‡

#### æ¶‰åŠæ–‡ä»¶
- [ ] `scripts/utils/db_manager.py` (æ·»åŠ å‡½æ•°)
- [ ] `scripts/setup.sh` (é›†æˆä¼˜åŒ–è„šæœ¬)

---

## ğŸŸ¡ P2: ä¸­æœŸå®æ–½ (1-2æœˆ)

### 8. åŒæ¨¡å‹äº¤å‰éªŒè¯ â­â­

**çŠ¶æ€**: â¬œ å¾…å¼€å§‹  
**ä¼˜å…ˆçº§**: P2  
**é¢„è®¡å·¥æ—¶**: 4å°æ—¶  
**å®Œæˆæ—¥æœŸ**: _____  

#### é—®é¢˜æè¿°
å•ä¸€æ¨¡å‹å¯èƒ½æœ‰åå·®ï¼Œç¼ºå°‘äº¤å‰éªŒè¯æœºåˆ¶ã€‚

#### è§£å†³æ–¹æ¡ˆ
è®©Geminiå’ŒDeepSeekåŒæ—¶åˆ†æï¼Œç„¶åå¯¹æ¯”ç»¼åˆ

#### æŠ€æœ¯å®ç°
```python
# æ–‡ä»¶: scripts/ai_analyze_dual.py (æ–°å»º)

def dual_model_analysis(articles):
    """åŒæ¨¡å‹äº¤å‰éªŒè¯"""
    
    print("ğŸ¤– Geminiåˆ†æä¸­...")
    gemini_result = analyze_with_model(articles, 'gemini')
    
    print("ğŸ¤– DeepSeekåˆ†æä¸­...")
    deepseek_result = analyze_with_model(articles, 'deepseek')
    
    # å¯¹æ¯”åˆ†æ
    comparison_prompt = f"""
è¯·å¯¹æ¯”ä»¥ä¸‹ä¸¤ä»½AIåˆ†ææŠ¥å‘Šï¼Œç”Ÿæˆç»¼åˆæŠ¥å‘Šï¼š

## ä»»åŠ¡è¦æ±‚
1. æ‰¾å‡ºå…±è¯†è§‚ç‚¹ï¼ˆä¸¤ä¸ªæ¨¡å‹éƒ½è®¤åŒçš„ï¼‰â†’ æ ‡æ³¨ã€å…±è¯†ã€‘
2. æ‰¾å‡ºåˆ†æ­§è§‚ç‚¹ï¼ˆå­˜åœ¨å·®å¼‚çš„ï¼‰â†’ åˆ†åˆ«æ ‡æ³¨ã€Geminiã€‘ã€DeepSeekã€‘
3. æ‰¾å‡ºäº’è¡¥ä¿¡æ¯ï¼ˆå„è‡ªç‹¬ç‰¹çš„æ´å¯Ÿï¼‰
4. ç»¼åˆåˆ¤æ–­ï¼šåŸºäºå¯¹æ¯”ç»™å‡ºæ›´å…¨é¢çš„åˆ†æ

## Geminiåˆ†æ
{gemini_result}

## DeepSeekåˆ†æ
{deepseek_result}

## è¾“å‡ºæ ¼å¼
ä¿æŒåŸæœ‰æŠ¥å‘Šç»“æ„ï¼Œä½†åœ¨å…³é”®è§‚ç‚¹åæ ‡æ³¨æ¥æºå’Œå…±è¯†ç¨‹åº¦ã€‚
"""
    
    print("ğŸ”„ ç»¼åˆåˆ†æä¸­...")
    final_report = call_ai_api(comparison_prompt, 'gemini')
    
    return final_report
```

#### é¢„æœŸæ•ˆæœ
- âœ… æå‡åˆ†æå‡†ç¡®åº¦
- âœ… å‡å°‘å•ä¸€æ¨¡å‹åå·®
- âœ… å‘ç°äº’è¡¥è§†è§’

#### æ¶‰åŠæ–‡ä»¶
- [ ] `scripts/ai_analyze_dual.py` (æ–°å»º)
- [ ] `scripts/interactive_runner.py` (æ·»åŠ åŒæ¨¡å‹é€‰é¡¹)

---

### 9. è¶‹åŠ¿åˆ†æåŠŸèƒ½ â­â­

**çŠ¶æ€**: â¬œ å¾…å¼€å§‹  
**ä¼˜å…ˆçº§**: P2  
**é¢„è®¡å·¥æ—¶**: 8å°æ—¶  
**å®Œæˆæ—¥æœŸ**: _____  

#### åŠŸèƒ½è¯´æ˜
åˆ†æ7å¤©/30å¤©çš„å…³é”®è¯çƒ­åº¦è¶‹åŠ¿ã€è¯é¢˜æ¼”å˜ã€‚

#### æŠ€æœ¯å®ç°
```python
# æ–‡ä»¶: scripts/trend_analyzer.py (æ–°å»º)

def analyze_keyword_trends(days=7):
    """å…³é”®è¯çƒ­åº¦è¶‹åŠ¿åˆ†æ"""
    # ä»æ•°æ®åº“æå–Nå¤©æ•°æ®
    # ç»Ÿè®¡å…³é”®è¯é¢‘ç‡å˜åŒ–
    # ç”Ÿæˆè¶‹åŠ¿æŠ¥å‘Š
    pass

def analyze_topic_evolution(topic, days=30):
    """è¯é¢˜æ¼”å˜è¿½è¸ª"""
    # è¿½è¸ªç‰¹å®šè¯é¢˜çš„æ–°é—»
    # åˆ†æå†…å®¹å˜åŒ–
    # ç”Ÿæˆæ¼”å˜æŠ¥å‘Š
    pass
```

#### æ¶‰åŠæ–‡ä»¶
- [ ] `scripts/trend_analyzer.py` (æ–°å»º)

---

### 10. æ•°æ®å¯è§†åŒ– â­â­

**çŠ¶æ€**: â¬œ å¾…å¼€å§‹  
**ä¼˜å…ˆçº§**: P2  
**é¢„è®¡å·¥æ—¶**: 10å°æ—¶  
**å®Œæˆæ—¥æœŸ**: _____  

#### åŠŸèƒ½è¯´æ˜
ç”Ÿæˆå›¾è¡¨ï¼šè¯äº‘ã€æ—¶é—´çº¿ã€æƒ…ç»ªæ›²çº¿ç­‰

#### æŠ€æœ¯æ–¹æ¡ˆ
ä½¿ç”¨ pyecharts æˆ– plotly ç”Ÿæˆäº¤äº’å¼å›¾è¡¨

#### æ¶‰åŠæ–‡ä»¶
- [ ] `scripts/visualize.py` (æ–°å»º)
- [ ] `requirements.txt` (æ·»åŠ pyecharts)

---

### 11. é€šçŸ¥ç³»ç»Ÿå¢å¼º â­

**çŠ¶æ€**: â¬œ å¾…å¼€å§‹  
**ä¼˜å…ˆçº§**: P2  
**é¢„è®¡å·¥æ—¶**: 4å°æ—¶  
**å®Œæˆæ—¥æœŸ**: _____  

#### åŠŸèƒ½è¯´æ˜
æ‰©å±•é€šçŸ¥æ¸ é“ï¼šé‚®ä»¶ã€å¾®ä¿¡ã€Telegram

#### æ¶‰åŠæ–‡ä»¶
- [ ] `scripts/utils/notifier.py` (æ‰©å±•)

---

### 12. Web APIæ¥å£ â­

**çŠ¶æ€**: â¬œ å¾…å¼€å§‹  
**ä¼˜å…ˆçº§**: P2  
**é¢„è®¡å·¥æ—¶**: 12å°æ—¶  
**å®Œæˆæ—¥æœŸ**: _____  

#### åŠŸèƒ½è¯´æ˜
æä¾›FastAPIæ¥å£ï¼Œæ”¯æŒç¨‹åºåŒ–è®¿é—®

#### æ¶‰åŠæ–‡ä»¶
- [ ] `scripts/api_server.py` (æ–°å»º)
- [ ] `requirements.txt` (æ·»åŠ fastapiã€uvicorn)

---

## ğŸŸ¢ P3: é•¿æœŸè§„åˆ’ (3æœˆ+)

### 13. çŸ¥è¯†å›¾è°± â­

**çŠ¶æ€**: â¬œ å¾…å¼€å§‹  
**ä¼˜å…ˆçº§**: P3  
**é¢„è®¡å·¥æ—¶**: 40å°æ—¶  

æ„å»ºå®ä½“å…³ç³»ï¼šå…¬å¸ã€äººç‰©ã€äº‹ä»¶ã€æ”¿ç­–

---

### 14. é¢„æµ‹åŠŸèƒ½ â­

**çŠ¶æ€**: â¬œ å¾…å¼€å§‹  
**ä¼˜å…ˆçº§**: P3  
**é¢„è®¡å·¥æ—¶**: 40å°æ—¶  

åŸºäºå†å²æ•°æ®é¢„æµ‹è¯é¢˜çƒ­åº¦ã€å¸‚åœºæƒ…ç»ª

---

### 15. AI AgentåŒ– â­

**çŠ¶æ€**: â¬œ å¾…å¼€å§‹  
**ä¼˜å…ˆçº§**: P3  
**é¢„è®¡å·¥æ—¶**: 60å°æ—¶  

å¤šAgentåä½œï¼šé‡‡é›†Agentã€åˆ†æAgentã€å†™ä½œAgent

---

### 16-20. å…¶ä»–é«˜çº§åŠŸèƒ½

è¯¦ç»†è§„åˆ’å¾…è¡¥å……...

---

## ğŸ“ å®æ–½æ—¥å¿—

### 2025-10-11 (æ™šä¸Š)

#### âœ… RSSæºè´¨é‡ä¼˜åŒ–ä¸å®Œæ•´é“¾è·¯æµ‹è¯•

**ä»»åŠ¡æ¦‚è¿°**: ä¼˜åŒ–RSSæ•°æ®æºé…ç½®ï¼Œæå‡æ–°é—»é‡‡é›†è´¨é‡ï¼Œå¹¶éªŒè¯å®Œæ•´ç³»ç»Ÿé“¾è·¯

**å®æ–½æ­¥éª¤**:

1. **RSSæºè´¨é‡æµ‹è¯•** âœ…
   - æµ‹è¯•äº†å…¨éƒ¨23ä¸ªRSSæºçš„å¯ç”¨æ€§
   - æˆåŠŸç‡: 91% (21/23)
   - å‘ç°2ä¸ªå¤±æ•ˆæº: æ¾æ¹ƒæ–°é—»è´¢ç»ã€å½­åšBloombergæ’­å®¢
   - è¯†åˆ«5ä¸ªä½è´¨é‡/ä¸ç›¸å…³æº

2. **ä¼˜åŒ–é…ç½®æ–‡ä»¶** âœ…
   - ç§»é™¤8ä¸ªä½è´¨é‡æº:
     - æ¾æ¹ƒæ–°é—»è´¢ç» (RSSå¤±æ•ˆ)
     - å½­åš Bloomberg (æ— æ–°é—»å†…å®¹)
     - Investing.com (è´¨é‡ä¸­ç­‰)
     - è™å—…ç½‘ã€é’›åª’ä½“ (éæ ¸å¿ƒè´¢ç»)
     - Decryptã€CoinDesk (åŒºå—é“¾ï¼Œæ³¢åŠ¨æ€§å¤§)
   - ä¿ç•™16ä¸ªé«˜è´¨é‡æº:
     - å›½å†…è´¢ç»(5): åå°”è¡—è§é—»ã€ä¸œæ–¹è´¢å¯Œã€36æ°ªã€ä¸­æ–°ç½‘ã€ç™¾åº¦è‚¡ç¥¨
     - å›½é™…è´¢ç»(8): FTä¸­æ–‡ç½‘ã€WSJã€ç»æµå­¦äººã€BBCã€CNBCã€ZeroHedgeã€ETF Trendsã€è·¯é€ç¤¾
     - å®˜æ–¹æ•°æ®(3): å›½å®¶ç»Ÿè®¡å±€ã€ç¾è”å‚¨ã€SEC
   - æŒ‰ä¼˜å…ˆçº§é‡æ–°æ’åºé…ç½®

3. **æ•°æ®æŠ“å–é“¾è·¯æµ‹è¯•** âœ…
   - æ‰§è¡Œå‘½ä»¤: `python scripts/rss_finance_analyzer.py --fetch-content`
   - ç»“æœ:
     - é…ç½®æº: 16ä¸ª
     - æŠ“å–æˆåŠŸ: 12/16 (75%)
     - è·å–æ–‡ç« : 60ç¯‡
     - å…¥åº“æ–°æ–‡ç« : 28ç¯‡ï¼ˆè‡ªåŠ¨å»é‡ï¼‰
   - çŠ¶æ€: âœ… é€šè¿‡

4. **AIåˆ†æé“¾è·¯æµ‹è¯•** âœ…
   - æ‰§è¡Œå‘½ä»¤: `python scripts/ai_analyze.py --content-field summary`
   - ç»“æœ:
     - æˆåŠŸç”ŸæˆGeminiæŠ¥å‘Š: 17KB
     - æˆåŠŸç”ŸæˆDeepSeekæŠ¥å‘Š: 7.7KB
     - ç”Ÿæˆå…ƒæ•°æ®æ–‡ä»¶: analysis_meta.json
     - æŠ¥å‘Šè´¨é‡: ä¼˜ç§€ï¼ˆç»“æ„å®Œæ•´ã€é€»è¾‘æ¸…æ™°ã€åŸºäºé«˜è´¨é‡æºï¼‰
   - çŠ¶æ€: âœ… é€šè¿‡

5. **æ–‡æ¡£ç”Ÿæˆé“¾è·¯æµ‹è¯•** âœ…
   - æ‰§è¡Œå‘½ä»¤: `python scripts/generate_mkdocs_nav.py && mkdocs build`
   - ç»“æœ:
     - å¯¼èˆªé…ç½®è‡ªåŠ¨ç”Ÿæˆ
     - é™æ€ç½‘ç«™æ„å»ºæˆåŠŸ
     - è¾“å‡ºç›®å½•: site/
     - åŒ…å«æœ€æ–°æŠ¥å‘Šï¼ˆ2025-10-11ï¼‰
   - çŠ¶æ€: âœ… é€šè¿‡

**ä¼˜åŒ–æ•ˆæœ**:
- âœ… æ•°æ®æºè´¨é‡æå‡: ä»23ä¸ª â†’ 16ä¸ªç²¾é€‰é«˜è´¨é‡æº
- âœ… é‡‡é›†æˆåŠŸç‡: 91% â†’ 75%ï¼ˆå‰”é™¤å¤±æ•ˆæºåçš„å®é™…æˆåŠŸç‡ï¼‰
- âœ… æŠ¥å‘Šè´¨é‡æå‡: åŸºäºé«˜è´¨é‡æºçš„åˆ†ææ›´ä¸“ä¸šã€å‡†ç¡®
- âœ… ç³»ç»Ÿç¨³å®šæ€§: å®Œæ•´é“¾è·¯æµ‹è¯•é€šè¿‡

**é‡åˆ°çš„é—®é¢˜**:
- æ— é‡å¤§é—®é¢˜
- éƒ¨åˆ†å›½é™…æºå¶å°”å“åº”è¾ƒæ…¢ï¼ˆåœ¨å¯æ¥å—èŒƒå›´å†…ï¼‰

**ç»“è®º**:
âœ… RSSæºä¼˜åŒ–å®Œæˆï¼Œç³»ç»Ÿå®Œæ•´é“¾è·¯éªŒè¯é€šè¿‡ï¼Œå¯ä»¥æŠ•å…¥æ—¥å¸¸ä½¿ç”¨

---

#### âœ… AIåˆ†æè„šæœ¬é‡æ„ - ä»£ç ä¼˜åŒ–

**ä»»åŠ¡æ¦‚è¿°**: æ¶ˆé™¤ä»£ç é‡å¤ï¼Œæå‡ä»£ç è´¨é‡å’Œå¯ç»´æŠ¤æ€§

**èƒŒæ™¯**: 
- `ai_analyze.py` (Geminiç‰ˆ) å’Œ `ai_analyze_deepseek.py` (DeepSeekç‰ˆ) å­˜åœ¨å¤§é‡é‡å¤ä»£ç 
- é‡å¤ç‡çº¦70%ï¼Œæ€»ä»£ç 977è¡Œï¼Œç»´æŠ¤æˆæœ¬é«˜

**å®æ–½æ­¥éª¤**:

1. **åˆ›å»ºå…¬å…±æ¨¡å—** âœ…
   - æ–‡ä»¶: `scripts/utils/ai_analyzer_common.py` (273è¡Œ)
   - å°è£…å…±äº«é€»è¾‘:
     - æ—¥æœŸå¤„ç†å’ŒéªŒè¯ (`validate_date`, `resolve_date_range`)
     - æ•°æ®åº“æ“ä½œ (`open_connection`, `query_articles`)
     - æ–‡ç« è¿‡æ»¤ (`filter_articles`)
     - è¯­æ–™æ„å»º (`build_corpus`, `build_source_stats_block`)
     - æ–‡ä»¶ä¿å­˜ (`save_markdown`, `save_metadata`, `write_json`)
     - è¾“å‡ºå·¥å…· (ä» `utils.print_utils` å¯¼å…¥)

2. **é‡æ„ Gemini åˆ†æè„šæœ¬** âœ…
   - æ–‡ä»¶: `scripts/ai_analyze.py`
   - é‡æ„å‰: 473è¡Œ
   - é‡æ„å: 260è¡Œ
   - å‡å°‘: 213è¡Œ (-45%)
   - ä¿ç•™ Gemini ç‰¹å®šé€»è¾‘:
     - æ¨¡å‹é€‰æ‹©å’Œé™çº§ç­–ç•¥
     - google.generativeai SDK è°ƒç”¨
     - API Key åŠ è½½

3. **é‡æ„ DeepSeek åˆ†æè„šæœ¬** âœ…
   - æ–‡ä»¶: `scripts/ai_analyze_deepseek.py`
   - é‡æ„å‰: 504è¡Œ
   - é‡æ„å: 255è¡Œ
   - å‡å°‘: 249è¡Œ (-49%)
   - ä¿ç•™ DeepSeek ç‰¹å®šé€»è¾‘:
     - OpenAI SDK è°ƒç”¨
     - Base URL é…ç½®
     - æç¤ºè¯ç‰ˆæœ¬é€‰æ‹© (safe/pro)

4. **è‡ªæµ‹éªŒè¯** âœ…
   - [x] Python è¯­æ³•æ£€æŸ¥: `py_compile` é€šè¿‡
   - [x] æ¨¡å—å¯¼å…¥æµ‹è¯•: æ— é”™è¯¯
   - [x] å‘½ä»¤è¡Œå‚æ•°: `--help` æ­£å¸¸æ˜¾ç¤º
   - [x] åŠŸèƒ½æµ‹è¯•: Gemini å’Œ DeepSeek æ¨¡å‹å‡å¯æ­£å¸¸è°ƒç”¨
   - [x] å…¼å®¹æ€§æµ‹è¯•: `interactive_runner.py` å’Œ `start.sh` æ— éœ€ä¿®æ”¹

**é‡æ„æ•ˆæœ**:

| æŒ‡æ ‡ | é‡æ„å‰ | é‡æ„å | ä¼˜åŒ– |
|------|--------|--------|------|
| æ€»ä»£ç è¡Œæ•° | 977è¡Œ | 788è¡Œ | -189è¡Œ (-19%) |
| ai_analyze.py | 473è¡Œ | 260è¡Œ | -213è¡Œ (-45%) |
| ai_analyze_deepseek.py | 504è¡Œ | 255è¡Œ | -249è¡Œ (-49%) |
| å…¬å…±æ¨¡å— | 0è¡Œ | 273è¡Œ | +273è¡Œ (æ–°å¢) |
| ä»£ç é‡å¤ç‡ | ~70% | ~5% | -65% |
| ç»´æŠ¤æˆæœ¬ | é«˜ | ä½ | â¬‡ï¸ 50% |

**æŠ€æœ¯äº®ç‚¹**:
- âœ… å•ä¸€èŒè´£åŸåˆ™: æ¯ä¸ªæ¨¡å—èŒè´£æ¸…æ™°
- âœ… DRYåŸåˆ™: æ¶ˆé™¤é‡å¤ä»£ç 
- âœ… å‘åå…¼å®¹: æ— éœ€ä¿®æ”¹è°ƒç”¨æ–¹ä»£ç 
- âœ… å¯æµ‹è¯•æ€§: å…¬å…±å‡½æ•°æ˜“äºå•å…ƒæµ‹è¯•
- âœ… å¯æ‰©å±•æ€§: æ–°å¢æ¨¡å‹åªéœ€ç¼–å†™ç‰¹å®šé€»è¾‘

**æ¶‰åŠæ–‡ä»¶**:
- âœ… `scripts/utils/ai_analyzer_common.py` (æ–°å»º)
- âœ… `scripts/ai_analyze.py` (é‡æ„)
- âœ… `scripts/ai_analyze_deepseek.py` (é‡æ„)
- âœ… `scripts/ai_analyze.py.backup` (å·²æ¸…ç†)
- âœ… `scripts/ai_analyze_deepseek.py.backup` (å·²æ¸…ç†)

**ç»“è®º**:
âœ… ä»£ç é‡æ„å®Œæˆï¼Œè´¨é‡æ˜¾è‘—æå‡ï¼Œç»´æŠ¤æˆæœ¬å¤§å¹…é™ä½ï¼Œä¸ºåç»­åŠŸèƒ½æ‰©å±•æ‰“ä¸‹è‰¯å¥½åŸºç¡€

---

### 2025-10-11 (ä¸‹åˆ)
- âœ… åˆ›å»ºä¼˜åŒ–è·¯çº¿å›¾æ–‡æ¡£
- ğŸ“‹ è§„åˆ’20é¡¹ä¼˜åŒ–ä»»åŠ¡
- ğŸ¯ ç¡®å®šä¼˜å…ˆçº§å’Œé¢„æœŸæ•ˆæœ

---

## ğŸ“Š å®Œæˆç»Ÿè®¡

**æ€»è¿›åº¦**: 0/20 (0%)  
*æ³¨: RSSæºä¼˜åŒ–ä¸åœ¨åŸè§„åˆ’çš„20é¡¹ä»»åŠ¡ä¸­ï¼Œå±äºåŸºç¡€ä¼˜åŒ–å·¥ä½œ*

**æŒ‰ä¼˜å…ˆçº§**:
- P0 (ç«‹å³): 0/3 (0%)
- P1 (çŸ­æœŸ): 0/4 (0%)
- P2 (ä¸­æœŸ): 0/5 (0%)
- P3 (é•¿æœŸ): 0/8 (0%)

**æŒ‰ç±»åˆ«**:
- æ•°æ®è´¨é‡: 0/4 (0%)
- AIåˆ†æä¼˜åŒ–: 0/6 (0%)
- æ€§èƒ½ä¼˜åŒ–: 0/3 (0%)
- ç”¨æˆ·ä½“éªŒ: 0/4 (0%)
- ç³»ç»Ÿç¨³å®šæ€§: 0/3 (0%)

**é¢å¤–å®Œæˆ**:
- âœ… RSSæºè´¨é‡ä¼˜åŒ–ï¼ˆ2025-10-11 æ™šä¸Šï¼‰
- âœ… å®Œæ•´ç³»ç»Ÿé“¾è·¯æµ‹è¯•ï¼ˆ2025-10-11 æ™šä¸Šï¼‰
- âœ… AIåˆ†æè„šæœ¬é‡æ„ï¼ˆ2025-10-11 æ™šä¸Šï¼‰- ä»£ç å‡å°‘19%ï¼Œé‡å¤ç‡é™ä½65%

---

## ğŸ¯ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

**å»ºè®®ä¼˜å…ˆå®æ–½ï¼ˆæœ€é«˜ROIï¼‰**:
1. âœ… å¢åŠ è¯æ®é“¾æœºåˆ¶ï¼ˆ2å°æ—¶ï¼‰
2. âœ… åˆ é™¤å®¹æ˜“å‡ºé”™çš„å…·ä½“æ¨èï¼ˆ1å°æ—¶ï¼‰
3. âœ… æ–°é—»è´¨é‡ç­›é€‰å’Œæ’åºï¼ˆ4å°æ—¶ï¼‰

**é¢„è®¡æ”¶ç›Š**:
- æŠ¥å‘Šå‡†ç¡®åº¦ â¬†ï¸ 30-40%
- ç”¨æˆ·ä¿¡ä»»åº¦ â¬†ï¸ 50%
- AIåˆ†ææˆæœ¬ â¬‡ï¸ 20-30%

---

## ğŸ“ˆ è´¨é‡æå‡è®°å½•

### RSSæºä¼˜åŒ–å‰åå¯¹æ¯”

| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æå‡ |
|------|--------|--------|------|
| RSSæºæ•°é‡ | 23ä¸ª | 16ä¸ª | ç²¾ç®€30% |
| æœ‰æ•ˆæºå æ¯” | 91% | 100% | +9% |
| é«˜è´¨é‡æºå æ¯” | ~60% | 100% | +40% |
| å•æ¬¡æŠ“å–æ–‡ç« æ•° | ä¼°è®¡50-80ç¯‡ | 60ç¯‡ | ç¨³å®š |
| æ•°æ®å…¥åº“ | - | 28ç¯‡æ–°æ–‡ç«  | - |
| æŠ¥å‘Šç”Ÿæˆ | æ­£å¸¸ | ä¼˜ç§€ | è´¨é‡æå‡ |

### ä»£ç è´¨é‡ä¼˜åŒ–å¯¹æ¯”

| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æå‡ |
|------|--------|--------|------|
| æ€»ä»£ç è¡Œæ•° | 977è¡Œ | 788è¡Œ | -19% |
| ä»£ç é‡å¤ç‡ | ~70% | ~5% | -65% |
| ç»´æŠ¤æˆæœ¬ | é«˜ | ä½ | â¬‡ï¸ 50% |
| å¯æµ‹è¯•æ€§ | ä½ | é«˜ | â¬†ï¸ æ˜¾è‘— |
| å¯æ‰©å±•æ€§ | ä¸­ | é«˜ | â¬†ï¸ æ˜¾è‘— |

### å½“å‰ç³»ç»ŸçŠ¶æ€
- âœ… **æ•°æ®é‡‡é›†**: ç¨³å®šè¿è¡Œï¼Œ16ä¸ªé«˜è´¨é‡æº
- âœ… **AIåˆ†æ**: Gemini + DeepSeek åŒæ¨¡å‹æ­£å¸¸ï¼Œä»£ç å·²ä¼˜åŒ–
- âœ… **æ–‡æ¡£ç”Ÿæˆ**: MkDocsè‡ªåŠ¨åŒ–æµç¨‹é€šç•…
- âœ… **ç³»ç»Ÿå¥åº·**: å®Œæ•´é“¾è·¯éªŒè¯é€šè¿‡
- âœ… **ä»£ç è´¨é‡**: é‡å¤ç‡é™ä½65%ï¼Œç»´æŠ¤æ€§æå‡50%

---

*æœ€åæ›´æ–°: 2025-10-11 23:00*

