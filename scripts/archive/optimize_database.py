#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ•°æ®åº“ç´¢å¼•ä¼˜åŒ–è„šæœ¬

åŠŸèƒ½ï¼š
1. æ·»åŠ å¤åˆç´¢å¼•ï¼Œä¼˜åŒ–å¸¸ç”¨æŸ¥è¯¢
2. åˆ†æå¹¶ä¼˜åŒ–æ•°æ®åº“ç»“æ„
3. é…ç½®FTS5å…¨æ–‡æ£€ç´¢åŒæ­¥
4. æ¸…ç†å’Œç»´æŠ¤æ•°æ®åº“

ä½¿ç”¨ï¼š
    python scripts/optimize_database.py              # ä¼˜åŒ–é»˜è®¤æ•°æ®åº“
    python scripts/optimize_database.py --analyze    # åˆ†ææŸ¥è¯¢æ€§èƒ½
    python scripts/optimize_database.py --vacuum     # æ¸…ç†å‹ç¼©æ•°æ®åº“
"""

import sqlite3
import argparse
from pathlib import Path
from typing import List, Tuple
import sys


PROJECT_ROOT = Path(__file__).resolve().parents[1]
DB_PATH = PROJECT_ROOT / 'data' / 'news_data.db'


def print_step(text: str):
    """æ‰“å°æ­¥éª¤"""
    print(f"\nğŸ“ {text}")


def print_success(text: str):
    """æ‰“å°æˆåŠŸ"""
    print(f"âœ… {text}")


def print_info(text: str):
    """æ‰“å°ä¿¡æ¯"""
    print(f"â„¹ï¸  {text}")


def print_warning(text: str):
    """æ‰“å°è­¦å‘Š"""
    print(f"âš ï¸  {text}")


def check_existing_indexes(conn: sqlite3.Connection) -> dict:
    """
    æ£€æŸ¥ç°æœ‰ç´¢å¼•
    
    Returns:
        {table_name: [(index_name, index_sql), ...]}
    """
    cursor = conn.cursor()
    cursor.execute("""
        SELECT name, tbl_name, sql 
        FROM sqlite_master 
        WHERE type='index' AND sql IS NOT NULL
        ORDER BY tbl_name, name
    """)
    
    indexes = {}
    for row in cursor.fetchall():
        index_name, table_name, sql = row
        if table_name not in indexes:
            indexes[table_name] = []
        indexes[table_name].append((index_name, sql))
    
    return indexes


def add_composite_indexes(conn: sqlite3.Connection, dry_run: bool = False):
    """
    æ·»åŠ å¤åˆç´¢å¼•
    
    å¤åˆç´¢å¼•è®¾è®¡åŸåˆ™ï¼š
    1. å·¦å‰ç¼€åŸåˆ™ï¼šæœ€å¸¸ç”¨äºWHEREçš„å­—æ®µæ”¾å·¦è¾¹
    2. ç­‰å€¼ä¼˜å…ˆï¼šç­‰å€¼æŸ¥è¯¢>èŒƒå›´æŸ¥è¯¢
    3. åŒºåˆ†åº¦é«˜ï¼šåŒºåˆ†åº¦é«˜çš„å­—æ®µä¼˜å…ˆ
    """
    
    print_step("æ·»åŠ å¤åˆç´¢å¼•")
    
    # å¤åˆç´¢å¼•åˆ—è¡¨
    indexes = [
        # 1. æ—¥æœŸèŒƒå›´æŸ¥è¯¢ + å‘å¸ƒæ—¶é—´æ’åºï¼ˆæœ€å¸¸ç”¨ï¼‰
        {
            'name': 'idx_articles_date_published',
            'table': 'news_articles',
            'columns': '(collection_date, published)',
            'desc': 'ä¼˜åŒ–æ—¥æœŸèŒƒå›´æŸ¥è¯¢å¹¶æŒ‰å‘å¸ƒæ—¶é—´æ’åº'
        },
        
        # 2. æ—¥æœŸèŒƒå›´æŸ¥è¯¢ + åˆ›å»ºæ—¶é—´æ’åºï¼ˆå¤‡ç”¨æ’åºï¼‰
        {
            'name': 'idx_articles_date_created',
            'table': 'news_articles',
            'columns': '(collection_date, created_at)',
            'desc': 'ä¼˜åŒ–æ—¥æœŸèŒƒå›´æŸ¥è¯¢å¹¶æŒ‰åˆ›å»ºæ—¶é—´æ’åº'
        },
        
        # 3. æ¥æº + æ—¥æœŸç»„åˆæŸ¥è¯¢
        {
            'name': 'idx_articles_source_date',
            'table': 'news_articles',
            'columns': '(source_id, collection_date)',
            'desc': 'ä¼˜åŒ–æŒ‰æ¥æºç­›é€‰çš„æ—¥æœŸèŒƒå›´æŸ¥è¯¢'
        },
        
        # 4. æ¥æº + å‘å¸ƒæ—¶é—´ï¼ˆæ¥æºåˆ†æï¼‰
        {
            'name': 'idx_articles_source_published',
            'table': 'news_articles',
            'columns': '(source_id, published)',
            'desc': 'ä¼˜åŒ–æŒ‰æ¥æºçš„æ—¶é—´åºåˆ—æŸ¥è¯¢'
        },
    ]
    
    cursor = conn.cursor()
    created_count = 0
    skipped_count = 0
    
    for idx in indexes:
        try:
            # æ£€æŸ¥ç´¢å¼•æ˜¯å¦å·²å­˜åœ¨
            cursor.execute(
                "SELECT name FROM sqlite_master WHERE type='index' AND name=?",
                (idx['name'],)
            )
            
            if cursor.fetchone():
                print_info(f"  è·³è¿‡ï¼ˆå·²å­˜åœ¨ï¼‰: {idx['name']}")
                skipped_count += 1
                continue
            
            # åˆ›å»ºç´¢å¼•
            sql = f"CREATE INDEX IF NOT EXISTS {idx['name']} ON {idx['table']} {idx['columns']}"
            
            if dry_run:
                print_info(f"  [æ¨¡æ‹Ÿ] {sql}")
                print_info(f"           è¯´æ˜: {idx['desc']}")
            else:
                cursor.execute(sql)
                print_success(f"  å·²åˆ›å»º: {idx['name']}")
                print_info(f"           è¯´æ˜: {idx['desc']}")
            
            created_count += 1
            
        except sqlite3.Error as e:
            print_warning(f"  åˆ›å»ºå¤±è´¥: {idx['name']} - {e}")
    
    if not dry_run:
        conn.commit()
    
    print()
    print_success(f"å¤åˆç´¢å¼•ä¼˜åŒ–å®Œæˆï¼šæ–°å¢ {created_count} ä¸ªï¼Œè·³è¿‡ {skipped_count} ä¸ª")


def setup_fts5_triggers(conn: sqlite3.Connection, dry_run: bool = False):
    """
    é…ç½®FTS5å…¨æ–‡æ£€ç´¢è‡ªåŠ¨åŒæ­¥è§¦å‘å™¨
    
    è§¦å‘å™¨ç¡®ä¿ï¼š
    1. æ’å…¥æ–°æ–‡ç« æ—¶è‡ªåŠ¨æ·»åŠ åˆ°FTS5ç´¢å¼•
    2. æ›´æ–°æ–‡ç« æ—¶è‡ªåŠ¨æ›´æ–°FTS5ç´¢å¼•
    3. åˆ é™¤æ–‡ç« æ—¶è‡ªåŠ¨ä»FTS5ç´¢å¼•ç§»é™¤
    """
    
    print_step("é…ç½®FTS5å…¨æ–‡æ£€ç´¢åŒæ­¥")
    
    # æ£€æŸ¥FTS5è¡¨æ˜¯å¦å­˜åœ¨
    cursor = conn.cursor()
    cursor.execute("""
        SELECT name FROM sqlite_master 
        WHERE type='table' AND name='news_articles_fts'
    """)
    
    if not cursor.fetchone():
        print_info("  FTS5è¡¨ä¸å­˜åœ¨ï¼Œè·³è¿‡è§¦å‘å™¨é…ç½®")
        return
    
    triggers = [
        # INSERTè§¦å‘å™¨
        {
            'name': 'news_articles_fts_insert',
            'sql': '''
                CREATE TRIGGER IF NOT EXISTS news_articles_fts_insert AFTER INSERT ON news_articles
                BEGIN
                    INSERT INTO news_articles_fts(rowid, title, summary, content)
                    VALUES (new.id, new.title, new.summary, new.content);
                END
            ''',
            'desc': 'æ’å…¥æ–°æ–‡ç« æ—¶è‡ªåŠ¨æ·»åŠ åˆ°å…¨æ–‡ç´¢å¼•'
        },
        
        # UPDATEè§¦å‘å™¨
        {
            'name': 'news_articles_fts_update',
            'sql': '''
                CREATE TRIGGER IF NOT EXISTS news_articles_fts_update AFTER UPDATE ON news_articles
                BEGIN
                    UPDATE news_articles_fts 
                    SET title=new.title, summary=new.summary, content=new.content
                    WHERE rowid=new.id;
                END
            ''',
            'desc': 'æ›´æ–°æ–‡ç« æ—¶è‡ªåŠ¨æ›´æ–°å…¨æ–‡ç´¢å¼•'
        },
        
        # DELETEè§¦å‘å™¨
        {
            'name': 'news_articles_fts_delete',
            'sql': '''
                CREATE TRIGGER IF NOT EXISTS news_articles_fts_delete AFTER DELETE ON news_articles
                BEGIN
                    DELETE FROM news_articles_fts WHERE rowid=old.id;
                END
            ''',
            'desc': 'åˆ é™¤æ–‡ç« æ—¶è‡ªåŠ¨ä»å…¨æ–‡ç´¢å¼•ç§»é™¤'
        },
    ]
    
    created_count = 0
    
    for trigger in triggers:
        try:
            # æ£€æŸ¥è§¦å‘å™¨æ˜¯å¦å·²å­˜åœ¨
            cursor.execute(
                "SELECT name FROM sqlite_master WHERE type='trigger' AND name=?",
                (trigger['name'],)
            )
            
            if cursor.fetchone():
                print_info(f"  è·³è¿‡ï¼ˆå·²å­˜åœ¨ï¼‰: {trigger['name']}")
                continue
            
            if dry_run:
                print_info(f"  [æ¨¡æ‹Ÿ] åˆ›å»ºè§¦å‘å™¨: {trigger['name']}")
                print_info(f"         è¯´æ˜: {trigger['desc']}")
            else:
                cursor.execute(trigger['sql'])
                print_success(f"  å·²åˆ›å»º: {trigger['name']}")
                print_info(f"           è¯´æ˜: {trigger['desc']}")
            
            created_count += 1
            
        except sqlite3.Error as e:
            print_warning(f"  åˆ›å»ºå¤±è´¥: {trigger['name']} - {e}")
    
    if not dry_run:
        conn.commit()
    
    print()
    print_success(f"FTS5è§¦å‘å™¨é…ç½®å®Œæˆï¼šæ–°å¢ {created_count} ä¸ª")


def analyze_database(conn: sqlite3.Connection):
    """
    åˆ†ææ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯
    
    SQLite ANALYZEå‘½ä»¤ï¼š
    - æ”¶é›†è¡¨å’Œç´¢å¼•çš„ç»Ÿè®¡ä¿¡æ¯
    - å¸®åŠ©æŸ¥è¯¢ä¼˜åŒ–å™¨é€‰æ‹©æœ€ä½³æ‰§è¡Œè®¡åˆ’
    - å»ºè®®å®šæœŸè¿è¡Œï¼ˆç‰¹åˆ«æ˜¯æ•°æ®é‡å˜åŒ–å¤§æ—¶ï¼‰
    """
    
    print_step("åˆ†ææ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯")
    
    cursor = conn.cursor()
    
    try:
        # æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
        cursor.execute("ANALYZE")
        conn.commit()
        print_success("æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯å·²æ›´æ–°")
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        cursor.execute("SELECT * FROM sqlite_stat1 ORDER BY tbl, idx")
        stats = cursor.fetchall()
        
        if stats:
            print()
            print_info("ç´¢å¼•ä½¿ç”¨ç»Ÿè®¡ï¼š")
            print(f"  {'è¡¨å':<30} {'ç´¢å¼•å':<40} {'ç»Ÿè®¡ä¿¡æ¯'}")
            print(f"  {'-'*30} {'-'*40} {'-'*20}")
            for row in stats:
                tbl, idx, stat = row
                print(f"  {tbl:<30} {idx or '(æ— ç´¢å¼•)':<40} {stat}")
        
    except sqlite3.Error as e:
        print_warning(f"åˆ†æå¤±è´¥: {e}")


def vacuum_database(conn: sqlite3.Connection):
    """
    æ¸…ç†å‹ç¼©æ•°æ®åº“
    
    VACUUMå‘½ä»¤ï¼š
    - é‡å»ºæ•°æ®åº“æ–‡ä»¶ï¼Œå›æ”¶ç©ºé—²ç©ºé—´
    - ä¼˜åŒ–æ•°æ®åº“ç»“æ„
    - å¯èƒ½ä¼šç¼©å°æ•°æ®åº“æ–‡ä»¶å¤§å°
    
    æ³¨æ„ï¼šVACUUMä¼šé”å®šæ•´ä¸ªæ•°æ®åº“ï¼Œè€—æ—¶è¾ƒé•¿
    """
    
    print_step("æ¸…ç†å‹ç¼©æ•°æ®åº“")
    print_warning("æ­¤æ“ä½œä¼šé”å®šæ•°æ®åº“ï¼Œè¯·ç¡®ä¿æ²¡æœ‰å…¶ä»–ç¨‹åºæ­£åœ¨ä½¿ç”¨")
    
    cursor = conn.cursor()
    
    try:
        # è·å–å½“å‰å¤§å°
        cursor.execute("SELECT page_count * page_size as size FROM pragma_page_count(), pragma_page_size()")
        size_before = cursor.fetchone()[0]
        
        # æ‰§è¡ŒVACUUM
        cursor.execute("VACUUM")
        
        # è·å–æ–°å¤§å°
        cursor.execute("SELECT page_count * page_size as size FROM pragma_page_count(), pragma_page_size()")
        size_after = cursor.fetchone()[0]
        
        saved = size_before - size_after
        saved_mb = saved / (1024 * 1024)
        
        print_success(f"æ•°æ®åº“å·²æ¸…ç†å‹ç¼©")
        print_info(f"  åŸå¤§å°: {size_before / (1024 * 1024):.2f} MB")
        print_info(f"  æ–°å¤§å°: {size_after / (1024 * 1024):.2f} MB")
        print_info(f"  èŠ‚çœç©ºé—´: {saved_mb:.2f} MB ({saved / size_before * 100:.1f}%)")
        
    except sqlite3.Error as e:
        print_warning(f"æ¸…ç†å¤±è´¥: {e}")


def show_database_info(conn: sqlite3.Connection):
    """æ˜¾ç¤ºæ•°æ®åº“ä¿¡æ¯"""
    
    print_step("æ•°æ®åº“ä¿¡æ¯")
    
    cursor = conn.cursor()
    
    # è¡¨ç»Ÿè®¡
    cursor.execute("SELECT name FROM sqlite_master WHERE type='table' ORDER BY name")
    tables = [row[0] for row in cursor.fetchall()]
    
    print()
    print_info(f"æ•°æ®åº“è·¯å¾„: {DB_PATH}")
    print_info(f"è¡¨æ•°é‡: {len(tables)}")
    
    print()
    print("ğŸ“Š è¡¨ç»Ÿè®¡ï¼š")
    for table in tables:
        if table.startswith('sqlite_'):
            continue
        
        cursor.execute(f"SELECT COUNT(*) FROM {table}")
        count = cursor.fetchone()[0]
        print(f"  â€¢ {table}: {count:,} è¡Œ")
    
    # ç´¢å¼•ç»Ÿè®¡
    print()
    print("ğŸ” ç´¢å¼•ç»Ÿè®¡ï¼š")
    indexes = check_existing_indexes(conn)
    
    for table_name, table_indexes in sorted(indexes.items()):
        if table_name.startswith('sqlite_'):
            continue
        print(f"  â€¢ {table_name}: {len(table_indexes)} ä¸ªç´¢å¼•")
        for idx_name, idx_sql in table_indexes:
            print(f"    - {idx_name}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ•°æ®åº“ç´¢å¼•ä¼˜åŒ–å·¥å…·')
    parser.add_argument('--db', type=str, help='æ•°æ®åº“è·¯å¾„ï¼ˆé»˜è®¤: data/news_data.dbï¼‰')
    parser.add_argument('--dry-run', action='store_true', help='æ¨¡æ‹Ÿè¿è¡Œï¼Œä¸å®é™…ä¿®æ”¹æ•°æ®åº“')
    parser.add_argument('--analyze', action='store_true', help='åˆ†ææ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯')
    parser.add_argument('--vacuum', action='store_true', help='æ¸…ç†å‹ç¼©æ•°æ®åº“')
    parser.add_argument('--info', action='store_true', help='æ˜¾ç¤ºæ•°æ®åº“ä¿¡æ¯')
    parser.add_argument('--all', action='store_true', help='æ‰§è¡Œæ‰€æœ‰ä¼˜åŒ–æ“ä½œ')
    
    args = parser.parse_args()
    
    # ç¡®å®šæ•°æ®åº“è·¯å¾„
    db_path = Path(args.db) if args.db else DB_PATH
    
    if not db_path.exists():
        print(f"âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {db_path}")
        sys.exit(1)
    
    print("="*70)
    print("        æ•°æ®åº“ç´¢å¼•ä¼˜åŒ–å·¥å…·")
    print("="*70)
    
    if args.dry_run:
        print()
        print_warning("æ¨¡æ‹Ÿè¿è¡Œæ¨¡å¼ï¼ˆä¸ä¼šå®é™…ä¿®æ”¹æ•°æ®åº“ï¼‰")
    
    # è¿æ¥æ•°æ®åº“
    try:
        conn = sqlite3.connect(db_path)
        conn.row_factory = sqlite3.Row
        
        # æ˜¾ç¤ºä¿¡æ¯
        if args.info or args.all:
            show_database_info(conn)
        
        # æ·»åŠ å¤åˆç´¢å¼•
        if not args.info and not args.analyze and not args.vacuum:
            # é»˜è®¤æ“ä½œï¼šæ·»åŠ ç´¢å¼•
            add_composite_indexes(conn, args.dry_run)
            setup_fts5_triggers(conn, args.dry_run)
        
        if args.all:
            add_composite_indexes(conn, args.dry_run)
            setup_fts5_triggers(conn, args.dry_run)
        
        # åˆ†ææ•°æ®åº“
        if args.analyze or args.all:
            if not args.dry_run:
                analyze_database(conn)
            else:
                print_info("è·³è¿‡åˆ†æï¼ˆæ¨¡æ‹Ÿè¿è¡Œæ¨¡å¼ï¼‰")
        
        # æ¸…ç†æ•°æ®åº“
        if args.vacuum:
            if not args.dry_run:
                vacuum_database(conn)
            else:
                print_info("è·³è¿‡æ¸…ç†ï¼ˆæ¨¡æ‹Ÿè¿è¡Œæ¨¡å¼ï¼‰")
        
        conn.close()
        
        print()
        print("="*70)
        print_success("æ•°æ®åº“ä¼˜åŒ–å®Œæˆ")
        print("="*70)
        
        if not args.dry_run:
            print()
            print_info("å»ºè®®ï¼šå®šæœŸè¿è¡Œ 'python scripts/optimize_database.py --analyze' æ›´æ–°ç»Ÿè®¡ä¿¡æ¯")
        
    except sqlite3.Error as e:
        print(f"\nâŒ æ•°æ®åº“é”™è¯¯: {e}")
        sys.exit(1)


if __name__ == '__main__':
    main()

