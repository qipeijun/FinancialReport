#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIåˆ†æè„šæœ¬ - é›†æˆå®æ—¶æ•°æ®éªŒè¯ç‰ˆ (Gemini)

æ ¸å¿ƒåŠŸèƒ½:
1. ä»æ•°æ®åº“è¯»å–æ–°é—»
2. è·å–å®æ—¶å¸‚åœºæ•°æ®
3. æ³¨å…¥æ•°æ®åˆ°AI Prompt
4. è°ƒç”¨Geminiç”ŸæˆæŠ¥å‘Š
5. äº‹å®æ ¸æŸ¥éªŒè¯
6. è´¨é‡è¯„åˆ†
7. è‡ªåŠ¨é‡è¯•(ä¸è¾¾æ ‡)
8. ä¿å­˜éªŒè¯æŠ¥å‘Š

ä½¿ç”¨æ–¹æ³•:
    python3 scripts/ai_analyze_verified.py --date 2026-01-07
    python3 scripts/ai_analyze_verified.py --date 2026-01-07 --skip-verification
"""

import argparse
import os
import sys
from pathlib import Path
from typing import Optional, Tuple, Dict, Any, List
from datetime import datetime
import yaml

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(PROJECT_ROOT))

# å¯¼å…¥å…¬å…±æ¨¡å—
from scripts.utils.ai_analyzer_common import *
from scripts.utils.quality_filter import filter_and_rank_articles
from scripts.utils.print_utils import (
    print_header, print_success, print_warning, print_error,
    print_info, print_progress, print_step
)

# å¯¼å…¥æ–°çš„éªŒè¯æ¨¡å—
from scripts.utils.realtime_data_fetcher import RealtimeDataFetcher
from scripts.utils.fact_checker import FactChecker
from scripts.utils.quality_checker_v2 import check_report_quality_v2, print_quality_report_v2

try:
    import google.generativeai as genai
except Exception:
    genai = None

DB_PATH = PROJECT_ROOT / 'data' / 'news_data.db'


def parse_args() -> argparse.Namespace:
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='ç”Ÿæˆå¸¦å®æ—¶æ•°æ®éªŒè¯çš„AIè´¢ç»åˆ†ææŠ¥å‘Š')

    # æ—¥æœŸå‚æ•°
    date_group = parser.add_mutually_exclusive_group()
    date_group.add_argument('--date', type=str, help='æŒ‡å®šå•æ—¥ï¼ˆYYYY-MM-DDï¼‰')
    parser.add_argument('--start', type=str, help='å¼€å§‹æ—¥æœŸï¼ˆYYYY-MM-DDï¼‰')
    parser.add_argument('--end', type=str, help='ç»“æŸæ—¥æœŸï¼ˆYYYY-MM-DDï¼‰')

    # æ•°æ®ç­›é€‰
    parser.add_argument('--limit', type=int, default=100, help='æœ€å¤šè¯»å–å¤šå°‘æ¡è®°å½•')
    parser.add_argument('--max-articles', type=int, help='å‚ä¸åˆ†æçš„æ–‡ç« æ•°é‡ä¸Šé™')
    parser.add_argument('--filter-source', type=str, help='ä»…åˆ†ææŒ‡å®šæ¥æºï¼ˆé€—å·åˆ†éš”ï¼‰')
    parser.add_argument('--filter-keyword', type=str, help='å…³é”®è¯è¿‡æ»¤ï¼ˆé€—å·åˆ†éš”ï¼‰')

    # APIé…ç½®
    parser.add_argument('--api-key', type=str, help='Gemini API Key')
    parser.add_argument('--config', type=str, help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--model', type=str, help='æŒ‡å®šGeminiæ¨¡å‹')

    # éªŒè¯å‚æ•°
    parser.add_argument('--skip-verification', action='store_true',
                       help='è·³è¿‡äº‹å®éªŒè¯(æµ‹è¯•ç”¨)')
    parser.add_argument('--max-retries', type=int, default=3,
                       help='è´¨é‡ä¸è¾¾æ ‡æ—¶çš„æœ€å¤§é‡è¯•æ¬¡æ•°')
    parser.add_argument('--min-score', type=int, default=80,
                       help='æœ€ä½è´¨é‡è¯„åˆ†(0-100)')

    # è¾“å‡ºå‚æ•°
    parser.add_argument('--output', type=str, help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--verbose', action='store_true', help='è¯¦ç»†æ—¥å¿—')

    return parser.parse_args()


def load_api_key(args: argparse.Namespace) -> str:
    """åŠ è½½Gemini API Key"""
    config_path = Path(args.config) if args.config else (PROJECT_ROOT / 'config' / 'config.yml')

    # 1. å‘½ä»¤è¡Œå‚æ•°
    if args.api_key:
        print_success('ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°æä¾›çš„ API Key')
        return args.api_key

    # 2. ç¯å¢ƒå˜é‡
    env_key = os.getenv('GEMINI_API_KEY')
    if env_key:
        print_success('ä½¿ç”¨ç¯å¢ƒå˜é‡ GEMINI_API_KEY')
        return env_key

    # 3. é…ç½®æ–‡ä»¶
    if config_path.exists():
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                cfg = yaml.safe_load(f) or {}
            api_key = (
                (cfg.get('api_keys') or {}).get('gemini')
                or (cfg.get('gemini') or {}).get('api_key')
            )
            if api_key:
                print_success(f'ä½¿ç”¨é…ç½®æ–‡ä»¶: {config_path}')
                return api_key
        except Exception as e:
            print_warning(f'è¯»å–é…ç½®å¤±è´¥: {e}')

    raise SystemExit(
        "æœªæ‰¾åˆ° Gemini API Keyã€‚è¯·ä½¿ç”¨ä»¥ä¸‹ä»»ä¸€æ–¹å¼é…ç½®:\n"
        "  1. ç¯å¢ƒå˜é‡: export GEMINI_API_KEY='your-key'\n"
        "  2. é…ç½®æ–‡ä»¶: config/config.yml\n"
        "  3. å‘½ä»¤è¡Œå‚æ•°: --api-key 'your-key'"
    )


def fetch_news_from_db(date: str, limit: int = 100) -> List[Dict]:
    """ä»æ•°æ®åº“è·å–æ–°é—»"""
    import sqlite3

    if not DB_PATH.exists():
        raise SystemExit(f"æ•°æ®åº“ä¸å­˜åœ¨: {DB_PATH}")

    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    query = """
    SELECT id, title, summary, content, url, source_id, published, collection_date
    FROM news_articles
    WHERE collection_date = ?
    AND content IS NOT NULL
    AND content != ''
    ORDER BY published DESC
    LIMIT ?
    """

    cursor.execute(query, (date, limit))
    rows = cursor.fetchall()
    conn.close()

    articles = []
    for row in rows:
        articles.append({
            'id': row[0],
            'title': row[1],
            'summary': row[2],
            'content': row[3],
            'url': row[4],
            'source_id': row[5],
            'published': row[6],
            'collection_date': row[7]
        })

    print_success(f"ä»æ•°æ®åº“è·å–åˆ° {len(articles)} ç¯‡æ–°é—» (æ—¥æœŸ: {date})")
    return articles


def call_gemini_with_realtime_data(
    api_key: str,
    articles: List[Dict],
    realtime_data: Dict,
    preferred_model: Optional[str] = None
) -> Tuple[str, Dict[str, Any]]:
    """
    è°ƒç”¨Geminiç”ŸæˆæŠ¥å‘Š(æ³¨å…¥å®æ—¶æ•°æ®)

    Args:
        api_key: Gemini APIå¯†é’¥
        articles: æ–°é—»åˆ—è¡¨
        realtime_data: å®æ—¶æ•°æ®(æ¥è‡ªRealtimeDataFetcher)
        preferred_model: æŒ‡å®šæ¨¡å‹(å¯é€‰)

    Returns:
        (æŠ¥å‘Šæ–‡æœ¬, ä½¿ç”¨å…ƒæ•°æ®)
    """
    if genai is None:
        raise SystemExit('æœªå®‰è£… google-generativeai')

    # é€‰æ‹©æ¨¡å‹
    if preferred_model:
        model_names = [f'models/{preferred_model}' if not preferred_model.startswith('models/') else preferred_model]
        print_info(f'ä½¿ç”¨æŒ‡å®šæ¨¡å‹: {model_names[0]}')
    else:
        model_names = [
            'models/gemini-3-flash-preview',      # ğŸ¥‡ æœ€æ–°! Gemini 3.0 Flash (2025-12å‘å¸ƒ)
            'models/gemini-3-pro-preview',         # ğŸ¥ˆ Gemini 3.0 Pro (2025-11å‘å¸ƒ)
            'models/gemini-2.0-flash-exp',         # ğŸ¥‰ Gemini 2.0 (å¤‡ç”¨)
            'models/gemini-1.5-pro',
            'models/gemini-1.5-flash'
        ]
        print_info('æŒ‰ä¼˜å…ˆçº§å°è¯•æ¨¡å‹: 3.0-flash â†’ 3.0-pro â†’ 2.0-flash-exp â†’ 1.5-pro â†’ 1.5-flash')

    genai.configure(api_key=api_key)

    # è¯»å–å¢å¼ºç‰ˆPromptæ¨¡æ¿
    prompt_path = PROJECT_ROOT / 'task' / 'financial_analysis_prompt_pro_v2.md'
    if not prompt_path.exists():
        # å›é€€åˆ°æ—§ç‰ˆ
        prompt_path = PROJECT_ROOT / 'task' / 'financial_analysis_prompt_pro.md'
        print_warning('æœªæ‰¾åˆ°v2ç‰ˆPrompt,ä½¿ç”¨æ—§ç‰ˆ(å¯èƒ½ç¼ºå°‘ä¸¥æ ¼çº¦æŸ)')

    with open(prompt_path, 'r', encoding='utf-8') as f:
        system_prompt_template = f.read()

    # æ„å»ºæ–°é—»å†…å®¹
    news_content = "\n\n".join([
        f"ã€æ–°é—»{i+1}ã€‘{article['title']}\n"
        f"æ¥æº: {article['source_id']} | å‘å¸ƒæ—¶é—´: {article['published']}\n"
        f"æ‘˜è¦: {article.get('summary', '')}\n"
        f"æ­£æ–‡: {article.get('content', '')[:800]}..."  # é™åˆ¶é•¿åº¦
        for i, article in enumerate(articles[:50])  # æœ€å¤š50ç¯‡
    ])

    # ç»„è£…å®Œæ•´Prompt
    final_prompt = f"""
{system_prompt_template}

---

{realtime_data.get('prompt', '')}

---

## ğŸ“° ä»Šæ—¥æ–°é—»å†…å®¹

{news_content}

---

**é‡è¦æé†’**:
1. æ‰€æœ‰è‚¡ç¥¨æ¨è**å¿…é¡»å¼•ç”¨ä¸Šé¢çš„å®æ—¶æ•°æ®**(ä»·æ ¼ã€æ¶¨è·Œå¹…)
2. **ç¦æ­¢**ç¼–é€ ä»»ä½•æœªåœ¨å®æ—¶æ•°æ®ä¸­å‡ºç°çš„æ•°å€¼
3. æ¯ä¸ªè§‚ç‚¹éƒ½è¦ç”¨ã€æ–°é—»Xã€‘æ ‡æ³¨æ¥æº
4. åœ¨æŠ¥å‘Šæœ«å°¾æ ‡æ³¨"æ•°æ®æ¥æº: æ–°æµªè´¢ç» | æ›´æ–°æ—¶é—´: {realtime_data.get('timestamp', '')}"
"""

    print_progress(f'æ­£åœ¨ç”ŸæˆæŠ¥å‘Š (æ–°é—»: {len(articles)}ç¯‡, å­—ç¬¦æ•°: {len(final_prompt):,})')

    # å°è¯•å¤šä¸ªæ¨¡å‹
    last_error: Optional[Exception] = None
    for i, model_name in enumerate(model_names, 1):
        try:
            print_step(i, len(model_names), f'å°è¯•æ¨¡å‹: {model_name}')

            model = genai.GenerativeModel(model_name)
            resp = model.generate_content(final_prompt)
            print_success(f'æ¨¡å‹è°ƒç”¨æˆåŠŸ: {model_name}')

            # æå–ä½¿ç”¨ä¿¡æ¯
            usage = {'model': model_name}
            try:
                if hasattr(resp, 'usage_metadata') and resp.usage_metadata:
                    usage_metadata = resp.usage_metadata
                    usage['prompt_tokens'] = getattr(usage_metadata, 'prompt_token_count', 0)
                    usage['candidates_tokens'] = getattr(usage_metadata, 'candidates_token_count', 0)
                    usage['total_tokens'] = getattr(usage_metadata, 'total_token_count', 0)
            except Exception:
                pass

            return resp.text, usage

        except Exception as e:
            last_error = e
            print_warning(f'æ¨¡å‹ {model_name} è°ƒç”¨å¤±è´¥: {e}')
            continue

    raise RuntimeError(f'æ‰€æœ‰æ¨¡å‹è°ƒç”¨å¤±è´¥,æœ€åé”™è¯¯: {last_error}')


def generate_verified_report(
    api_key: str,
    date: str,
    args: argparse.Namespace
) -> Dict:
    """
    ç”Ÿæˆå¸¦éªŒè¯çš„å®Œæ•´æŠ¥å‘Š

    Returns:
        {
            'report': æœ€ç»ˆæŠ¥å‘Šæ–‡æœ¬,
            'quality': è´¨é‡è¯„åˆ†ç»“æœ,
            'metadata': å…ƒæ•°æ®,
            'success': æ˜¯å¦æˆåŠŸ
        }
    """
    print_header(f"ç”Ÿæˆå¸¦éªŒè¯çš„AIæŠ¥å‘Š: {date}")

    # æ­¥éª¤1: è·å–æ–°é—»
    print_step(1, 7, "ä»æ•°æ®åº“è·å–æ–°é—»")
    articles = fetch_news_from_db(date, limit=args.limit)

    if not articles:
        print_error("æ²¡æœ‰å¯ç”¨çš„æ–°é—»æ•°æ®")
        return {'success': False, 'error': 'æ²¡æœ‰æ–°é—»æ•°æ®'}

    # æ­¥éª¤2: è·å–å®æ—¶æ•°æ®
    print_step(2, 7, "è·å–å®æ—¶å¸‚åœºæ•°æ®")
    fetcher = RealtimeDataFetcher()
    realtime_data = fetcher.fetch_all_for_articles(articles)

    print_success(f"å®æ—¶æ•°æ®è·å–å®Œæˆ: "
                 f"è‚¡ç¥¨ {len(realtime_data.get('stocks', {}))}ä¸ª, "
                 f"é»„é‡‘ {'æœ‰' if realtime_data.get('gold') else 'æ— '}, "
                 f"å¤–æ±‡ {len(realtime_data.get('forex', {}))}ä¸ª")

    # è·³è¿‡éªŒè¯(æµ‹è¯•æ¨¡å¼)
    if args.skip_verification:
        print_warning("âš ï¸ è·³è¿‡éªŒè¯æ­¥éª¤(æµ‹è¯•æ¨¡å¼)")

        print_step(3, 7, "è°ƒç”¨Geminiç”ŸæˆæŠ¥å‘Š")
        report_text, usage = call_gemini_with_realtime_data(
            api_key, articles, realtime_data, args.model
        )

        return {
            'report': report_text,
            'quality': {'score': 0, 'passed': False},
            'usage': usage,
            'metadata': {
                'date': date,
                'llm': 'gemini',
                'articles_count': len(articles),
                'verification_skipped': True
            },
            'success': True
        }

    # æ­¥éª¤3-7: ç”ŸæˆæŠ¥å‘Š + éªŒè¯(å¸¦é‡è¯•)
    fact_checker = FactChecker(fetcher)

    for attempt in range(1, args.max_retries + 1):
        print_step(3, 7, f"ç”ŸæˆæŠ¥å‘Š (å°è¯• {attempt}/{args.max_retries})")

        # è°ƒç”¨Gemini
        report_text, usage = call_gemini_with_realtime_data(
            api_key, articles, realtime_data, args.model
        )

        print_success(f"æŠ¥å‘Šç”Ÿæˆå®Œæˆ (é•¿åº¦: {len(report_text):,} å­—ç¬¦)")

        # æ­¥éª¤4: äº‹å®æ ¸æŸ¥
        print_step(4, 7, "äº‹å®æ ¸æŸ¥éªŒè¯")
        claims = fact_checker.extract_claims(report_text)
        print_info(f"æå–åˆ° {len(claims)} ä¸ªæ–­è¨€")

        verified_claims = fact_checker.verify_claims(claims, realtime_data)
        verified_count = sum(1 for c in verified_claims if c.verified)
        print_info(f"éªŒè¯å®Œæˆ: {verified_count}/{len(claims)} é€šè¿‡")

        # æ­¥éª¤5: è´¨é‡è¯„åˆ†
        print_step(5, 7, "è®¡ç®—è´¨é‡è¯„åˆ†")
        quality_result = check_report_quality_v2(
            report_text=report_text,
            claims=verified_claims,
            realtime_data=realtime_data
        )

        # æ‰“å°è´¨é‡æŠ¥å‘Š
        print_quality_report_v2(quality_result, verbose=args.verbose)

        # æ­¥éª¤6: æ£€æŸ¥æ˜¯å¦é€šè¿‡
        if quality_result['passed'] and quality_result['score'] >= args.min_score:
            print_step(6, 7, "æŠ¥å‘Šè´¨é‡æ£€æŸ¥: âœ… é€šè¿‡")

            # è¿½åŠ äº‹å®æ ¸æŸ¥æŠ¥å‘Š
            print_step(7, 7, "è¿½åŠ äº‹å®æ ¸æŸ¥æŠ¥å‘Š")
            annotation = fact_checker.generate_report_annotation(verified_claims)
            final_report = report_text + annotation

            print_success(f"âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆ! (è¯„åˆ†: {quality_result['score']}, å°è¯•: {attempt})")

            return {
                'report': final_report,
                'quality': quality_result,
                'usage': usage,
                'metadata': {
                    'date': date,
                    'llm': 'gemini',
                    'model': usage.get('model', ''),
                    'articles_count': len(articles),
                    'attempts': attempt,
                    'realtime_data_used': True,
                    'fact_checked': True,
                    'verified_claims': verified_count,
                    'total_claims': len(claims)
                },
                'success': True
            }
        else:
            print_warning(f"âŒ æŠ¥å‘Šè´¨é‡ä¸è¾¾æ ‡ (è¯„åˆ†: {quality_result['score']}, è¦æ±‚: {args.min_score})")

            if attempt < args.max_retries:
                print_info(f"å‡†å¤‡ç¬¬ {attempt+1} æ¬¡é‡è¯•...")
            else:
                print_error(f"è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({args.max_retries}),ä»æœªé€šè¿‡éªŒè¯")

                # è¿”å›æœ€åä¸€æ¬¡ç»“æœ(å³ä½¿ä¸è¾¾æ ‡)
                annotation = fact_checker.generate_report_annotation(verified_claims)
                final_report = report_text + annotation

                return {
                    'report': final_report,
                    'quality': quality_result,
                    'usage': usage,
                    'metadata': {
                        'date': date,
                        'llm': 'gemini',
                        'articles_count': len(articles),
                        'attempts': attempt,
                        'failed': True
                    },
                    'success': False
                }

    return {'success': False, 'error': 'æœªçŸ¥é”™è¯¯'}


def save_report(report: str, date: str, metadata: Dict, output_path: Optional[str] = None):
    """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶"""
    if output_path:
        output_file = Path(output_path)
    else:
        # é»˜è®¤è·¯å¾„: docs/archive/YYYY-MM/YYYY-MM-DD/reports/
        year_month = date[:7]  # 2026-01
        report_dir = PROJECT_ROOT / 'docs' / 'archive' / year_month / date / 'reports'
        report_dir.mkdir(parents=True, exist_ok=True)

        timestamp = datetime.now().strftime('%H%M')
        output_file = report_dir / f"ğŸ“… {date} è´¢ç»åˆ†ææŠ¥å‘Š_gemini_verified_{timestamp}.md"

    output_file.parent.mkdir(parents=True, exist_ok=True)

    # å†™å…¥æŠ¥å‘Š
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(report)

    # å†™å…¥å…ƒæ•°æ®
    metadata_file = output_file.with_suffix('.json')
    import json
    with open(metadata_file, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)

    print_success(f"æŠ¥å‘Šå·²ä¿å­˜: {output_file}")
    print_info(f"å…ƒæ•°æ®å·²ä¿å­˜: {metadata_file}")

    return output_file


def main():
    args = parse_args()

    # ç¡®å®šæ—¥æœŸ
    if args.date:
        date = args.date
    elif args.start:
        date = args.start
    else:
        date = datetime.now().strftime('%Y-%m-%d')

    print_header(f"AIè´¢ç»æŠ¥å‘Šç”Ÿæˆå™¨ (å¸¦å®æ—¶æ•°æ®éªŒè¯)")
    print_info(f"æ—¥æœŸ: {date}")
    print_info(f"éªŒè¯æ¨¡å¼: {'å…³é—­' if args.skip_verification else 'å¼€å¯'}")
    print_info(f"æœ€å¤§é‡è¯•: {args.max_retries}")
    print_info(f"æœ€ä½è¯„åˆ†: {args.min_score}")

    try:
        # åŠ è½½API Key
        api_key = load_api_key(args)

        # ç”ŸæˆæŠ¥å‘Š
        result = generate_verified_report(api_key, date, args)

        if not result['success']:
            print_error(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            sys.exit(1)

        # ä¿å­˜æŠ¥å‘Š
        output_file = save_report(
            result['report'],
            date,
            result['metadata'],
            args.output
        )

        # æ‰“å°ç»Ÿè®¡
        print_header("ç”Ÿæˆç»Ÿè®¡")
        print_info(f"æ¨¡å‹: {result['usage'].get('model', 'N/A')}")
        print_info(f"Tokenä½¿ç”¨: {result['usage'].get('total_tokens', 0):,}")
        print_info(f"æ–‡ç« æ•°: {result['metadata']['articles_count']}")
        print_info(f"å°è¯•æ¬¡æ•°: {result['metadata'].get('attempts', 1)}")

        if not args.skip_verification:
            print_info(f"éªŒè¯æ–­è¨€: {result['metadata'].get('verified_claims', 0)}/{result['metadata'].get('total_claims', 0)}")
            print_info(f"è´¨é‡è¯„åˆ†: {result['quality']['score']}/100")

        # é€€å‡ºç 
        sys.exit(0 if result['quality'].get('passed', False) else 1)

    except KeyboardInterrupt:
        print_warning("\nç”¨æˆ·ä¸­æ–­")
        sys.exit(130)
    except Exception as e:
        print_error(f"å‘ç”Ÿé”™è¯¯: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
