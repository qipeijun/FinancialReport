#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®åº“ç»´æŠ¤å·¥å…·

åŠŸèƒ½ï¼š
- ç´¢å¼•ä¼˜åŒ–å’Œé‡å»º
- æ•°æ®åº“æ¸…ç†å’Œç¢ç‰‡æ•´ç†
- å¥åº·æ£€æŸ¥å’Œè¯Šæ–­
- æ•°æ®å½’æ¡£å’Œæ¸…ç†
"""

import sqlite3
import sys
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, Any, Optional
import argparse

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = Path(__file__).resolve().parents[2]
sys.path.insert(0, str(PROJECT_ROOT))

from scripts.utils.logger import get_logger
from scripts.utils.print_utils import (
    print_header, print_success, print_warning, print_error,
    print_info, print_statistics
)

logger = get_logger('db_maintenance')


class DatabaseMaintenance:
    """æ•°æ®åº“ç»´æŠ¤å·¥å…·"""

    def __init__(self, db_path: Path):
        """
        åˆå§‹åŒ–æ•°æ®åº“ç»´æŠ¤å·¥å…·

        Args:
            db_path: æ•°æ®åº“æ–‡ä»¶è·¯å¾„
        """
        self.db_path = Path(db_path)
        if not self.db_path.exists():
            raise FileNotFoundError(f"æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {db_path}")

    def optimize_indexes(self, rebuild: bool = False):
        """
        ä¼˜åŒ–ç´¢å¼•

        Args:
            rebuild: æ˜¯å¦é‡å»ºæ‰€æœ‰ç´¢å¼•
        """
        print_header("ğŸ“Š ç´¢å¼•ä¼˜åŒ–")

        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()

            if rebuild:
                print_info("æ­£åœ¨é‡å»ºç´¢å¼•...")

                # 1. åˆ é™¤å†—ä½™ç´¢å¼•
                redundant_indexes = [
                    'idx_articles_date_created',
                    'idx_articles_date_published',
                    'idx_articles_source_date',
                ]

                for idx_name in redundant_indexes:
                    try:
                        cursor.execute(f"DROP INDEX IF EXISTS {idx_name}")
                        logger.info(f"åˆ é™¤å†—ä½™ç´¢å¼•: {idx_name}")
                    except sqlite3.Error as e:
                        logger.warning(f"åˆ é™¤ç´¢å¼•å¤±è´¥ {idx_name}: {e}")

                # 2. åˆ›å»ºä¼˜åŒ–çš„å¤åˆç´¢å¼•
                optimized_indexes = [
                    # æ—¥æœŸ + æ¥æº + å‘å¸ƒæ—¶é—´ï¼ˆè¦†ç›–80%æŸ¥è¯¢ï¼‰
                    """
                    CREATE INDEX IF NOT EXISTS idx_date_source_published
                    ON news_articles(collection_date, source_id, published DESC)
                    """,

                    # æ¥æº + æ—¥æœŸï¼ˆåå‘æŸ¥è¯¢ï¼‰
                    """
                    CREATE INDEX IF NOT EXISTS idx_source_date
                    ON news_articles(source_id, collection_date DESC)
                    """,

                    # AIåˆ†æä¸“ç”¨ç´¢å¼•ï¼ˆä»…åŒ…å«æœ‰å†…å®¹çš„æ–‡ç« ï¼‰
                    """
                    CREATE INDEX IF NOT EXISTS idx_analysis_ready
                    ON news_articles(collection_date, published DESC)
                    WHERE (summary IS NOT NULL AND summary != '')
                       OR (content IS NOT NULL AND content != '')
                    """,
                ]

                for sql in optimized_indexes:
                    try:
                        cursor.execute(sql)
                        logger.info(f"åˆ›å»ºç´¢å¼•æˆåŠŸ")
                    except sqlite3.Error as e:
                        logger.error(f"åˆ›å»ºç´¢å¼•å¤±è´¥: {e}")

                conn.commit()
                print_success("âœ“ ç´¢å¼•é‡å»ºå®Œæˆ")

            # 3. æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            print_info("æ›´æ–°ç»Ÿè®¡ä¿¡æ¯...")
            cursor.execute("ANALYZE")
            conn.commit()
            print_success("âœ“ ç»Ÿè®¡ä¿¡æ¯å·²æ›´æ–°")

            # 4. ä¼˜åŒ–æŸ¥è¯¢è®¡åˆ’
            print_info("ä¼˜åŒ–æŸ¥è¯¢è®¡åˆ’...")
            cursor.execute("PRAGMA optimize")
            conn.commit()
            print_success("âœ“ æŸ¥è¯¢è®¡åˆ’å·²ä¼˜åŒ–")

        logger.info("ç´¢å¼•ä¼˜åŒ–å®Œæˆ")

    def vacuum(self):
        """æ‰§è¡ŒVACUUMæ“ä½œï¼ˆæ¸…ç†ç¢ç‰‡ã€å›æ”¶ç©ºé—´ï¼‰"""
        print_header("ğŸ§¹ æ•°æ®åº“æ¸…ç†")

        # è·å–ä¼˜åŒ–å‰å¤§å°
        size_before = self.db_path.stat().st_size / (1024 * 1024)  # MB
        print_info(f"å½“å‰æ•°æ®åº“å¤§å°: {size_before:.2f} MB")

        print_info("æ­£åœ¨æ‰§è¡Œ VACUUMï¼ˆå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰...")

        with sqlite3.connect(self.db_path) as conn:
            conn.execute("VACUUM")

        # è·å–ä¼˜åŒ–åå¤§å°
        size_after = self.db_path.stat().st_size / (1024 * 1024)
        saved = size_before - size_after

        print_success(f"âœ“ VACUUM å®Œæˆ")
        print_statistics({
            'ä¼˜åŒ–å‰': f'{size_before:.2f} MB',
            'ä¼˜åŒ–å': f'{size_after:.2f} MB',
            'èŠ‚çœç©ºé—´': f'{saved:.2f} MB ({saved/size_before*100:.1f}%)'
        })

        logger.info(f"VACUUMå®Œæˆï¼ŒèŠ‚çœ {saved:.2f} MB")

    def health_check(self) -> Dict[str, Any]:
        """
        å¥åº·æ£€æŸ¥

        Returns:
            å¥åº·çŠ¶æ€æŠ¥å‘Š
        """
        print_header("ğŸ¥ æ•°æ®åº“å¥åº·æ£€æŸ¥")

        health = {
            'status': 'healthy',
            'checks': {},
            'warnings': [],
            'errors': []
        }

        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()

            # 1. å®Œæ•´æ€§æ£€æŸ¥
            print_info("æ£€æŸ¥æ•°æ®å®Œæ•´æ€§...")
            cursor.execute("PRAGMA integrity_check")
            integrity_result = cursor.fetchone()[0]

            if integrity_result == 'ok':
                health['checks']['integrity'] = 'ok'
                print_success("âœ“ æ•°æ®å®Œæ•´æ€§æ­£å¸¸")
            else:
                health['status'] = 'error'
                health['errors'].append(f'å®Œæ•´æ€§æ£€æŸ¥å¤±è´¥: {integrity_result}')
                print_error(f"âœ— æ•°æ®å®Œæ•´æ€§å¼‚å¸¸: {integrity_result}")

            # 2. ç¢ç‰‡æ£€æŸ¥
            print_info("æ£€æŸ¥ç¢ç‰‡ç‡...")
            cursor.execute("PRAGMA freelist_count")
            fragmentation = cursor.fetchone()[0]
            health['checks']['fragmentation_pages'] = fragmentation

            if fragmentation > 1000:
                health['warnings'].append(f'ç¢ç‰‡è¾ƒå¤š: {fragmentation} é¡µï¼Œå»ºè®®æ‰§è¡Œ VACUUM')
                print_warning(f"âš  ç¢ç‰‡é¡µæ•°: {fragmentation}ï¼ˆå»ºè®®æ¸…ç†ï¼‰")
            else:
                print_success(f"âœ“ ç¢ç‰‡é¡µæ•°: {fragmentation}ï¼ˆæ­£å¸¸ï¼‰")

            # 3. ç´¢å¼•æ£€æŸ¥
            print_info("æ£€æŸ¥ç´¢å¼•...")
            cursor.execute("""
                SELECT COUNT(*) FROM sqlite_master
                WHERE type='index' AND tbl_name='news_articles'
            """)
            index_count = cursor.fetchone()[0]
            health['checks']['index_count'] = index_count

            # åˆç†èŒƒå›´ï¼š4-6ä¸ªç´¢å¼•
            if index_count < 4:
                health['warnings'].append(f'ç´¢å¼•æ•°é‡åå°‘: {index_count}')
                print_warning(f"âš  ç´¢å¼•æ•°é‡: {index_count}ï¼ˆåå°‘ï¼‰")
            elif index_count > 8:
                health['warnings'].append(f'ç´¢å¼•æ•°é‡è¿‡å¤š: {index_count}ï¼Œå¯èƒ½å½±å“å†™å…¥æ€§èƒ½')
                print_warning(f"âš  ç´¢å¼•æ•°é‡: {index_count}ï¼ˆè¿‡å¤šï¼‰")
            else:
                print_success(f"âœ“ ç´¢å¼•æ•°é‡: {index_count}ï¼ˆæ­£å¸¸ï¼‰")

            # 4. ç»Ÿè®¡ä¿¡æ¯æ£€æŸ¥
            print_info("æ£€æŸ¥ç»Ÿè®¡ä¿¡æ¯...")
            cursor.execute("SELECT COUNT(*) FROM sqlite_stat1")
            stats_count = cursor.fetchone()[0]
            health['checks']['statistics_tables'] = stats_count

            if stats_count == 0:
                health['warnings'].append('ç¼ºå°‘ç»Ÿè®¡ä¿¡æ¯ï¼Œå»ºè®®æ‰§è¡Œ ANALYZE')
                print_warning("âš  ç¼ºå°‘ç»Ÿè®¡ä¿¡æ¯")
            else:
                print_success(f"âœ“ ç»Ÿè®¡ä¿¡æ¯: {stats_count} ä¸ªè¡¨")

            # 5. æ•°æ®é‡æ£€æŸ¥
            print_info("æ£€æŸ¥æ•°æ®é‡...")
            cursor.execute("SELECT COUNT(*) FROM news_articles")
            article_count = cursor.fetchone()[0]
            health['checks']['article_count'] = article_count
            print_info(f"æ–‡ç« æ€»æ•°: {article_count}")

            # 6. æ•°æ®åº“å¤§å°
            db_size_mb = self.db_path.stat().st_size / (1024 * 1024)
            health['checks']['db_size_mb'] = round(db_size_mb, 2)
            print_info(f"æ•°æ®åº“å¤§å°: {db_size_mb:.2f} MB")

        # æ€»ç»“
        if health['errors']:
            health['status'] = 'error'
            print_error(f"\nâŒ å¥åº·æ£€æŸ¥å‘ç° {len(health['errors'])} ä¸ªé”™è¯¯")
        elif health['warnings']:
            health['status'] = 'warning'
            print_warning(f"\nâš ï¸  å¥åº·æ£€æŸ¥å‘ç° {len(health['warnings'])} ä¸ªè­¦å‘Š")
        else:
            print_success("\nâœ… æ•°æ®åº“å¥åº·çŠ¶å†µè‰¯å¥½")

        return health

    def cleanup_old_data(self, days_to_keep: int = 90, dry_run: bool = True):
        """
        æ¸…ç†æ—§æ•°æ®

        Args:
            days_to_keep: ä¿ç•™æœ€è¿‘Nå¤©çš„æ•°æ®
            dry_run: æ˜¯å¦ä¸ºæ¨¡æ‹Ÿè¿è¡Œï¼ˆä¸å®é™…åˆ é™¤ï¼‰
        """
        print_header(f"ğŸ—‘ï¸  æ•°æ®æ¸…ç†ï¼ˆä¿ç•™ {days_to_keep} å¤©ï¼‰")

        cutoff_date = (datetime.now() - timedelta(days=days_to_keep)).strftime('%Y-%m-%d')
        print_info(f"æˆªæ­¢æ—¥æœŸ: {cutoff_date}")

        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()

            # æŸ¥è¯¢å°†è¢«åˆ é™¤çš„æ•°æ®é‡
            cursor.execute("""
                SELECT COUNT(*) FROM news_articles
                WHERE collection_date < ?
            """, (cutoff_date,))
            to_delete_count = cursor.fetchone()[0]

            if to_delete_count == 0:
                print_info("æ²¡æœ‰éœ€è¦æ¸…ç†çš„æ•°æ®")
                return

            print_warning(f"å°†åˆ é™¤ {to_delete_count} æ¡æ—§æ•°æ®")

            if dry_run:
                print_info("ğŸ” æ¨¡æ‹Ÿè¿è¡Œæ¨¡å¼ï¼ˆä¸ä¼šå®é™…åˆ é™¤ï¼‰")
                print_info("å¦‚éœ€æ‰§è¡Œåˆ é™¤ï¼Œè¯·ä½¿ç”¨ --no-dry-run å‚æ•°")
            else:
                # å®é™…åˆ é™¤
                cursor.execute("""
                    DELETE FROM news_articles
                    WHERE collection_date < ?
                """, (cutoff_date,))

                deleted = cursor.rowcount
                conn.commit()

                print_success(f"âœ“ å·²åˆ é™¤ {deleted} æ¡æ•°æ®")
                logger.info(f"æ¸…ç†äº† {deleted} æ¡æ—§æ•°æ®ï¼ˆ{cutoff_date}ä¹‹å‰ï¼‰")

    def full_maintenance(self):
        """æ‰§è¡Œå®Œæ•´ç»´æŠ¤æµç¨‹"""
        print_header("ğŸ”§ æ‰§è¡Œå®Œæ•´æ•°æ®åº“ç»´æŠ¤")

        # 1. å¥åº·æ£€æŸ¥
        health = self.health_check()

        # 2. æ ¹æ®å¥åº·çŠ¶å†µå†³å®šç»´æŠ¤ç­–ç•¥
        if health['checks'].get('fragmentation_pages', 0) > 1000:
            self.vacuum()

        if health['checks'].get('statistics_tables', 0) == 0:
            self.optimize_indexes(rebuild=False)

        # 3. æœ€ç»ˆä¼˜åŒ–
        print_header("ğŸ¯ æœ€ç»ˆä¼˜åŒ–")
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("PRAGMA optimize")
        print_success("âœ“ æ•°æ®åº“ç»´æŠ¤å®Œæˆ")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ•°æ®åº“ç»´æŠ¤å·¥å…·')
    parser.add_argument(
        '--db-path',
        type=str,
        default='data/news_data.db',
        help='æ•°æ®åº“æ–‡ä»¶è·¯å¾„'
    )
    parser.add_argument(
        '--optimize',
        action='store_true',
        help='æ‰§è¡Œå®Œæ•´ä¼˜åŒ–'
    )
    parser.add_argument(
        '--rebuild-indexes',
        action='store_true',
        help='é‡å»ºç´¢å¼•'
    )
    parser.add_argument(
        '--vacuum',
        action='store_true',
        help='æ‰§è¡ŒVACUUM'
    )
    parser.add_argument(
        '--health-check',
        action='store_true',
        help='å¥åº·æ£€æŸ¥'
    )
    parser.add_argument(
        '--cleanup',
        type=int,
        metavar='DAYS',
        help='æ¸…ç†Nå¤©ä¹‹å‰çš„æ•°æ®'
    )
    parser.add_argument(
        '--no-dry-run',
        action='store_true',
        help='å®é™…æ‰§è¡Œåˆ é™¤ï¼ˆä¸--cleanupé…åˆä½¿ç”¨ï¼‰'
    )

    args = parser.parse_args()

    # æ„å»ºæ•°æ®åº“è·¯å¾„
    db_path = PROJECT_ROOT / args.db_path

    try:
        maintenance = DatabaseMaintenance(db_path)

        if args.optimize:
            maintenance.full_maintenance()
        elif args.rebuild_indexes:
            maintenance.optimize_indexes(rebuild=True)
        elif args.vacuum:
            maintenance.vacuum()
        elif args.health_check:
            maintenance.health_check()
        elif args.cleanup:
            maintenance.cleanup_old_data(
                days_to_keep=args.cleanup,
                dry_run=not args.no_dry_run
            )
        else:
            # é»˜è®¤ï¼šå¥åº·æ£€æŸ¥
            maintenance.health_check()

    except Exception as e:
        print_error(f"æ‰§è¡Œå¤±è´¥: {e}")
        logger.error(f"æ•°æ®åº“ç»´æŠ¤å¤±è´¥", exc_info=True)
        sys.exit(1)


if __name__ == '__main__':
    main()
