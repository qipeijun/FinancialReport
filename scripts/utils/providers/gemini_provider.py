#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Google Gemini æ¨¡å‹æä¾›å•†
"""

from typing import Tuple, Dict, Any, Optional
from .base_provider import BaseProvider

try:
    import google.generativeai as genai
except ImportError:
    genai = None


class GeminiProvider(BaseProvider):
    """Google Gemini æ¨¡å‹æä¾›å•†"""

    def __init__(self, api_key: str, **kwargs):
        super().__init__(api_key, **kwargs)

        if genai is None:
            raise ImportError('æœªå®‰è£… google-generativeaiï¼Œè¯·è¿è¡Œ: pip install google-generativeai')

        genai.configure(api_key=self.api_key)

        # é»˜è®¤æ¨¡å‹ä¼˜å…ˆçº§ï¼ˆGemini 3.0ä¼˜å…ˆï¼‰
        self.default_models = kwargs.get('models') or [
            'models/gemini-3-flash-preview',      # ğŸ¥‡ Gemini 3.0 Flash (æœ€æ–°)
            'models/gemini-3-pro-preview',         # ğŸ¥ˆ Gemini 3.0 Pro
            'models/gemini-2.0-flash-exp',         # ğŸ¥‰ Gemini 2.0 (å¤‡ç”¨)
            'models/gemini-1.5-pro',
            'models/gemini-1.5-flash'
        ]

    def get_available_models(self) -> list:
        """è·å–å¯ç”¨çš„Geminiæ¨¡å‹åˆ—è¡¨"""
        return self.default_models

    def generate(self, prompt: str, content: str, **kwargs) -> Tuple[str, Dict[str, Any]]:
        """
        è°ƒç”¨Geminiç”Ÿæˆåˆ†ææŠ¥å‘Š

        Args:
            prompt: ç³»ç»Ÿæç¤ºè¯
            content: ç”¨æˆ·è¾“å…¥å†…å®¹
            **kwargs:
                - preferred_model: æŒ‡å®šæ¨¡å‹åç§°
                - max_retries: æ¨¡å‹å¤±è´¥æ—¶çš„é‡è¯•æ¬¡æ•°

        Returns:
            Tuple[str, Dict]: (ç”Ÿæˆçš„æ–‡æœ¬, ä½¿ç”¨ç»Ÿè®¡)
        """
        preferred_model = kwargs.get('preferred_model')

        # é€‰æ‹©æ¨¡å‹åˆ—è¡¨
        if preferred_model:
            if not preferred_model.startswith('models/'):
                preferred_model = f'models/{preferred_model}'
            model_names = [preferred_model]
        else:
            model_names = self.default_models

        # å°è¯•å¤šä¸ªæ¨¡å‹
        last_error: Optional[Exception] = None
        for model_name in model_names:
            try:
                # æ›¿æ¢æç¤ºè¯ä¸­çš„æ¨¡å‹å ä½ç¬¦
                final_prompt = prompt.replace(
                    '[ä½¿ç”¨çš„å…·ä½“æ¨¡å‹åç§°]',
                    model_name.replace('models/', '')
                )

                model = genai.GenerativeModel(model_name)
                resp = model.generate_content([final_prompt, content])

                # æå–ä½¿ç”¨ç»Ÿè®¡
                usage = {'model': model_name, 'provider': 'gemini'}
                try:
                    if hasattr(resp, 'usage_metadata') and resp.usage_metadata:
                        metadata = resp.usage_metadata
                        usage['prompt_tokens'] = getattr(metadata, 'prompt_token_count', 0)
                        usage['candidates_tokens'] = getattr(metadata, 'candidates_token_count', 0)
                        usage['total_tokens'] = getattr(metadata, 'total_token_count', 0)
                except Exception:
                    pass

                return resp.text, usage

            except Exception as e:
                last_error = e
                continue

        raise RuntimeError(f'æ‰€æœ‰Geminiæ¨¡å‹è°ƒç”¨å¤±è´¥ï¼Œæœ€åé”™è¯¯ï¼š{last_error}')
