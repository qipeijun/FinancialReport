#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–°é—»è´¨é‡ç­›é€‰å’Œæ’åºæ¨¡å—

åŠŸèƒ½ï¼š
- åŸºäºæ¥æºæƒé‡çš„è´¨é‡è¯„åˆ†
- é‡è¦å…³é”®è¯æ£€æµ‹å’ŒåŠ æƒ
- åƒåœ¾å†…å®¹è¯†åˆ«å’Œè¿‡æ»¤
- æ ‡é¢˜å…šæ£€æµ‹
- æ™ºèƒ½å»é‡ï¼ˆåŸºäºç›¸ä¼¼åº¦ï¼‰
- ç»¼åˆè´¨é‡è¯„åˆ†å’Œæ’åº
"""

import re
import sys
import yaml
from typing import List, Dict, Any, Tuple, Optional
from datetime import datetime
from pathlib import Path

# æ·»åŠ scriptsç›®å½•åˆ°è·¯å¾„ï¼ˆç”¨äºç›´æ¥è¿è¡Œæµ‹è¯•ï¼‰
if __name__ == '__main__':
    scripts_path = Path(__file__).resolve().parents[1]
    if str(scripts_path) not in sys.path:
        sys.path.insert(0, str(scripts_path))

# å°è¯•ç›¸å¯¹å¯¼å…¥ï¼Œå¤±è´¥åˆ™ä½¿ç”¨ç»å¯¹å¯¼å…¥
try:
    from .logger import get_logger
    from .deduplication import deduplicate_items
except ImportError:
    from utils.logger import get_logger
    from utils.deduplication import deduplicate_items

logger = get_logger('quality_filter')

# è·å–é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).resolve().parents[2]
DEFAULT_CONFIG_PATH = PROJECT_ROOT / 'config' / 'quality_filter_config.yml'


# ============================================================================
# é…ç½®ç®¡ç†ç±»
# ============================================================================

class QualityFilterConfig:
    """è´¨é‡ç­›é€‰é…ç½®ç®¡ç†ç±»"""
    
    def __init__(self, config_path: Optional[Path] = None):
        """
        åˆå§‹åŒ–é…ç½®
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„ï¼ŒNoneåˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„
        """
        self.config_path = config_path or DEFAULT_CONFIG_PATH
        self.config = self._load_config()
        
    def _load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            if not self.config_path.exists():
                logger.warning(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.config_path}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                return self._get_default_config()
            
            with open(self.config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            
            logger.info(f"å·²åŠ è½½è´¨é‡ç­›é€‰é…ç½®: {self.config_path}")
            return config
        except Exception as e:
            logger.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return self._get_default_config()
    
    def _get_default_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤é…ç½®ï¼ˆå¤‡ç”¨ï¼‰"""
        return {
            'quality_threshold': 2.5,
            'dedup_threshold': 0.85,
            'enable_dedup': True,
            'max_articles': 0,
            'source_weights': {'default': 1.0},
            'important_keywords': {},
            'spam_keywords': [],
            'low_quality_patterns': [],
            'scoring_weights': {
                'keyword_contribution': 0.3,
                'spam_penalty_per_keyword': 0.5,
                'spam_penalty_max': 3.0,
                'title_penalty_per_pattern': 0.5,
                'title_penalty_max': 2.0,
            },
            'content_length_scoring': {'summary': [], 'content': []},
            'timeliness_scoring': [],
            'advanced': {
                'enable_debug_log': False,
                'show_top_articles': True,
                'top_articles_count': 10,
                'dedup_priority_keys': ['content', 'summary', 'quality_score'],
                'use_fast_dedup': True,
            }
        }
    
    @property
    def quality_threshold(self) -> float:
        """è´¨é‡é˜ˆå€¼"""
        return self.config.get('quality_threshold', 2.5)
    
    @property
    def dedup_threshold(self) -> float:
        """å»é‡ç›¸ä¼¼åº¦é˜ˆå€¼"""
        return self.config.get('dedup_threshold', 0.85)
    
    @property
    def enable_dedup(self) -> bool:
        """æ˜¯å¦å¯ç”¨å»é‡"""
        return self.config.get('enable_dedup', True)
    
    @property
    def max_articles(self) -> int:
        """æœ€å¤§æ–‡ç« æ•°"""
        return self.config.get('max_articles', 0)
    
    @property
    def source_weights(self) -> Dict[str, float]:
        """æ¥æºæƒé‡"""
        return self.config.get('source_weights', {})
    
    @property
    def important_keywords(self) -> Dict[str, float]:
        """é‡è¦å…³é”®è¯"""
        return self.config.get('important_keywords', {})
    
    @property
    def spam_keywords(self) -> List[str]:
        """åƒåœ¾å…³é”®è¯"""
        return self.config.get('spam_keywords', [])
    
    @property
    def low_quality_patterns(self) -> List[str]:
        """ä½è´¨é‡æ ‡é¢˜æ¨¡å¼"""
        return self.config.get('low_quality_patterns', [])
    
    @property
    def scoring_weights(self) -> Dict[str, float]:
        """è¯„åˆ†æƒé‡"""
        return self.config.get('scoring_weights', {})
    
    @property
    def content_length_scoring(self) -> Dict[str, List[Dict]]:
        """å†…å®¹é•¿åº¦è¯„åˆ†è§„åˆ™"""
        return self.config.get('content_length_scoring', {})
    
    @property
    def timeliness_scoring(self) -> List[Dict]:
        """æ—¶æ•ˆæ€§è¯„åˆ†è§„åˆ™"""
        return self.config.get('timeliness_scoring', [])
    
    @property
    def advanced(self) -> Dict[str, Any]:
        """é«˜çº§é€‰é¡¹"""
        return self.config.get('advanced', {})
    
    def get_source_weight(self, source_name: str) -> float:
        """è·å–æ¥æºæƒé‡"""
        return self.source_weights.get(source_name, self.source_weights.get('default', 1.0))


# å…¨å±€é…ç½®å®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
_global_config: Optional[QualityFilterConfig] = None


def get_config(config_path: Optional[Path] = None) -> QualityFilterConfig:
    """
    è·å–å…¨å±€é…ç½®å®ä¾‹
    
    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„ï¼ŒNoneåˆ™ä½¿ç”¨é»˜è®¤
    
    Returns:
        é…ç½®å®ä¾‹
    """
    global _global_config
    if _global_config is None or config_path is not None:
        _global_config = QualityFilterConfig(config_path)
    return _global_config


# ============================================================================
# æ ¸å¿ƒåŠŸèƒ½ï¼šè´¨é‡è¯„åˆ†
# ============================================================================

def calculate_quality_score(article: Dict[str, Any], config: Optional[QualityFilterConfig] = None) -> float:
    """
    è®¡ç®—å•ç¯‡æ–‡ç« çš„è´¨é‡å¾—åˆ†
    
    Args:
        article: æ–‡ç« æ•°æ®å­—å…¸ï¼Œéœ€åŒ…å«ä»¥ä¸‹å­—æ®µï¼š
            - source_name: æ¥æºåç§°
            - title: æ ‡é¢˜
            - summary: æ‘˜è¦ï¼ˆå¯é€‰ï¼‰
            - content: æ­£æ–‡ï¼ˆå¯é€‰ï¼‰
            - published: å‘å¸ƒæ—¶é—´ï¼ˆå¯é€‰ï¼‰
        config: é…ç½®å¯¹è±¡ï¼ŒNoneåˆ™ä½¿ç”¨é»˜è®¤é…ç½®
    
    Returns:
        è´¨é‡å¾—åˆ†ï¼ˆ0-10åˆ†ï¼‰
    
    è¯„åˆ†è§„åˆ™ï¼š
        - åŸºç¡€åˆ†ï¼šæ¥æºæƒé‡ï¼ˆ1-5åˆ†ï¼‰
        - å†…å®¹é•¿åº¦ï¼š+0-2åˆ†
        - é‡è¦å…³é”®è¯ï¼š+0-3åˆ†
        - åƒåœ¾å†…å®¹ï¼š-0-3åˆ†
        - æ ‡é¢˜å…šï¼š-0-2åˆ†
        - æ—¶æ•ˆæ€§ï¼š+0-1åˆ†
    """
    if config is None:
        config = get_config()
    
    score = 0.0
    scoring_weights = config.scoring_weights
    
    # 1. æ¥æºæƒé‡ï¼ˆ1-5åˆ†ï¼‰
    source_name = article.get('source_name', '')
    source_weight = config.get_source_weight(source_name)
    score += source_weight * scoring_weights.get('source_weight_multiplier', 1.0)
    
    # 2. å†…å®¹é•¿åº¦ï¼ˆè´¨é‡æŒ‡æ ‡ï¼Œ0-2åˆ†ï¼‰
    content_score = 0.0
    summary = article.get('summary') or ''
    content = article.get('content') or ''
    
    # ä½¿ç”¨é…ç½®ä¸­çš„å†…å®¹é•¿åº¦è¯„åˆ†è§„åˆ™
    length_rules = config.content_length_scoring
    for rule in length_rules.get('summary', []):
        if len(summary) > rule.get('threshold', 0):
            content_score += rule.get('score', 0)
    
    for rule in length_rules.get('content', []):
        if content and len(content) > rule.get('threshold', 0):
            content_score += rule.get('score', 0)
    
    content_score = min(content_score, scoring_weights.get('content_length_max_score', 2.0))
    score += content_score
    
    # 3. é‡è¦å…³é”®è¯æ£€æµ‹ï¼ˆ0-3åˆ†ï¼‰
    title = article.get('title', '')
    full_text = f"{title} {summary}"
    
    keyword_score = 0.0
    matched_keywords = []
    keyword_contribution = scoring_weights.get('keyword_contribution', 0.3)
    
    for keyword, weight in config.important_keywords.items():
        if keyword in full_text:
            keyword_score += weight * keyword_contribution
            matched_keywords.append(keyword)
    
    # å…³é”®è¯å¾—åˆ†ä¸Šé™
    keyword_max = scoring_weights.get('keyword_max_score', 3.0)
    keyword_score = min(keyword_score, keyword_max)
    score += keyword_score
    
    # 4. åƒåœ¾å†…å®¹æ£€æµ‹ï¼ˆ-0åˆ°-3åˆ†ï¼‰
    spam_penalty = 0.0
    spam_found = []
    spam_penalty_per = scoring_weights.get('spam_penalty_per_keyword', 0.5)
    
    for spam_keyword in config.spam_keywords:
        if spam_keyword in full_text:
            spam_penalty += spam_penalty_per
            spam_found.append(spam_keyword)
    
    # åƒåœ¾å†…å®¹æƒ©ç½šä¸Šé™
    spam_max = scoring_weights.get('spam_penalty_max', 3.0)
    spam_penalty = min(spam_penalty, spam_max)
    score -= spam_penalty
    
    # 5. æ ‡é¢˜å…šæ£€æµ‹ï¼ˆ-0åˆ°-2åˆ†ï¼‰
    title_penalty = 0.0
    title_penalty_per = scoring_weights.get('title_penalty_per_pattern', 0.5)
    
    for pattern in config.low_quality_patterns:
        if re.search(pattern, title):
            title_penalty += title_penalty_per
    
    # æ ‡é¢˜å…šæƒ©ç½šä¸Šé™
    title_max = scoring_weights.get('title_penalty_max', 2.0)
    title_penalty = min(title_penalty, title_max)
    score -= title_penalty
    
    # 6. æ—¶æ•ˆæ€§åŠ åˆ†ï¼ˆ0-1åˆ†ï¼‰
    published = article.get('published')
    timeliness_score = 0.0
    if published:
        try:
            # å°è¯•è§£ææ—¶é—´
            if isinstance(published, str):
                # æ”¯æŒå¤šç§æ—¶é—´æ ¼å¼
                from dateutil import parser
                pub_time = parser.parse(published)
            else:
                pub_time = published
            
            now = datetime.now()
            hours_diff = (now - pub_time.replace(tzinfo=None)).total_seconds() / 3600
            
            # ä½¿ç”¨é…ç½®ä¸­çš„æ—¶æ•ˆæ€§è¯„åˆ†è§„åˆ™
            timeliness_rules = config.timeliness_scoring
            for rule in timeliness_rules:
                if hours_diff <= rule.get('hours', 0):
                    timeliness_score = rule.get('score', 0)
                    break
            
            timeliness_weight = scoring_weights.get('timeliness_weight', 1.0)
            score += timeliness_score * timeliness_weight
        except Exception:
            pass
    
    # ç¡®ä¿åˆ†æ•°åœ¨åˆç†èŒƒå›´å†…ï¼ˆ0-10ï¼‰
    score = max(0.0, min(score, 10.0))
    
    # è®°å½•è°ƒè¯•ä¿¡æ¯
    if config.advanced.get('enable_debug_log', False):
        if matched_keywords or spam_found or title_penalty > 0:
            logger.debug(
                f"è´¨é‡è¯„åˆ†: {score:.2f} | {source_name} | {title[:30]}...\n"
                f"  æ¥æºæƒé‡={source_weight:.1f}, å†…å®¹={content_score:.1f}, "
                f"å…³é”®è¯={keyword_score:.1f}, åƒåœ¾=-{spam_penalty:.1f}, "
                f"æ ‡é¢˜å…š=-{title_penalty:.1f}, æ—¶æ•ˆ={timeliness_score:.1f}"
            )
    
    return score


def annotate_articles_with_scores(articles: List[Dict[str, Any]], config: Optional[QualityFilterConfig] = None) -> List[Dict[str, Any]]:
    """
    ä¸ºæ–‡ç« åˆ—è¡¨æ·»åŠ è´¨é‡è¯„åˆ†
    
    Args:
        articles: æ–‡ç« åˆ—è¡¨
        config: é…ç½®å¯¹è±¡ï¼ŒNoneåˆ™ä½¿ç”¨é»˜è®¤é…ç½®
    
    Returns:
        æ·»åŠ äº† 'quality_score' å­—æ®µçš„æ–‡ç« åˆ—è¡¨
    """
    if not articles:
        return articles
    
    if config is None:
        config = get_config()
    
    logger.info(f"å¼€å§‹è®¡ç®—è´¨é‡è¯„åˆ†ï¼Œå…± {len(articles)} ç¯‡æ–‡ç« ")
    
    for article in articles:
        article['quality_score'] = calculate_quality_score(article, config)
    
    # ç»Ÿè®¡ä¿¡æ¯
    scores = [a['quality_score'] for a in articles]
    avg_score = sum(scores) / len(scores) if scores else 0
    max_score = max(scores) if scores else 0
    min_score = min(scores) if scores else 0
    
    logger.info(
        f"è¯„åˆ†ç»Ÿè®¡: å¹³å‡={avg_score:.2f}, æœ€é«˜={max_score:.2f}, æœ€ä½={min_score:.2f}"
    )
    
    return articles


# ============================================================================
# æ ¸å¿ƒåŠŸèƒ½ï¼šè´¨é‡ç­›é€‰å’Œæ’åº
# ============================================================================

def filter_and_rank_articles(
    articles: List[Dict[str, Any]],
    quality_threshold: Optional[float] = None,
    deduplicate: Optional[bool] = None,
    dedup_threshold: Optional[float] = None,
    max_articles: Optional[int] = None,
    config: Optional[QualityFilterConfig] = None
) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:
    """
    è´¨é‡ç­›é€‰ + æ™ºèƒ½å»é‡ + æ’åº
    
    Args:
        articles: åŸå§‹æ–‡ç« åˆ—è¡¨
        quality_threshold: è´¨é‡é˜ˆå€¼ï¼ˆNoneåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ï¼‰
        deduplicate: æ˜¯å¦æ‰§è¡Œå»é‡ï¼ˆNoneåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ï¼‰
        dedup_threshold: å»é‡ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆNoneåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ï¼‰
        max_articles: æœ€å¤šä¿ç•™æ–‡ç« æ•°ï¼ˆNoneåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ï¼Œ0è¡¨ç¤ºä¸é™åˆ¶ï¼‰
        config: é…ç½®å¯¹è±¡ï¼ˆNoneåˆ™ä½¿ç”¨é»˜è®¤é…ç½®ï¼‰
    
    Returns:
        (ç­›é€‰åçš„æ–‡ç« åˆ—è¡¨, ç»Ÿè®¡ä¿¡æ¯)
    
    å¤„ç†æµç¨‹ï¼š
        1. è®¡ç®—è´¨é‡è¯„åˆ†
        2. è¿‡æ»¤ä½è´¨é‡æ–‡ç« 
        3. æ™ºèƒ½å»é‡ï¼ˆå¯é€‰ï¼‰
        4. æŒ‰è´¨é‡å¾—åˆ†æ’åº
        5. æˆªå–æŒ‡å®šæ•°é‡ï¼ˆå¯é€‰ï¼‰
    """
    if not articles:
        return articles, {
            'original_count': 0,
            'after_quality_filter': 0,
            'after_dedup': 0,
            'final_count': 0,
            'removed_by_quality': 0,
            'removed_by_dedup': 0,
            'removed_by_limit': 0
        }
    
    # åŠ è½½é…ç½®
    if config is None:
        config = get_config()
    
    # ä½¿ç”¨é…ç½®çš„é»˜è®¤å€¼ï¼ˆå¦‚æœå‚æ•°æœªæä¾›ï¼‰
    if quality_threshold is None:
        quality_threshold = config.quality_threshold
    if deduplicate is None:
        deduplicate = config.enable_dedup
    if dedup_threshold is None:
        dedup_threshold = config.dedup_threshold
    if max_articles is None:
        max_articles = config.max_articles
    
    original_count = len(articles)
    logger.info(f"\n{'='*70}")
    logger.info(f"ğŸ“Š å¼€å§‹æ–°é—»è´¨é‡ç­›é€‰å’Œæ’åº")
    logger.info(f"{'='*70}")
    logger.info(f"åŸå§‹æ–‡ç« æ•°: {original_count}")
    
    # 1. è®¡ç®—è´¨é‡è¯„åˆ†
    articles = annotate_articles_with_scores(articles, config)
    
    # 2. è¿‡æ»¤ä½è´¨é‡æ–‡ç« 
    logger.info(f"\nğŸ” è´¨é‡è¿‡æ»¤: é˜ˆå€¼ >= {quality_threshold:.1f}")
    
    filtered_articles = [
        a for a in articles 
        if a.get('quality_score', 0) >= quality_threshold
    ]
    
    after_quality_filter = len(filtered_articles)
    removed_by_quality = original_count - after_quality_filter
    
    logger.info(f"  ä¿ç•™: {after_quality_filter} ç¯‡")
    logger.info(f"  è¿‡æ»¤: {removed_by_quality} ç¯‡ (ä½è´¨é‡)")
    
    if not filtered_articles:
        logger.warning("âš ï¸  æ‰€æœ‰æ–‡ç« éƒ½è¢«è´¨é‡è¿‡æ»¤å™¨è¿‡æ»¤ï¼Œè¯·é™ä½é˜ˆå€¼")
        return [], {
            'original_count': original_count,
            'after_quality_filter': 0,
            'after_dedup': 0,
            'final_count': 0,
            'removed_by_quality': removed_by_quality,
            'removed_by_dedup': 0,
            'removed_by_limit': 0
        }
    
    # 3. æ™ºèƒ½å»é‡
    after_dedup = after_quality_filter
    removed_by_dedup = 0
    
    if deduplicate:
        logger.info(f"\nğŸ”„ æ™ºèƒ½å»é‡: ç›¸ä¼¼åº¦é˜ˆå€¼ >= {dedup_threshold:.2f}")
        
        # ä»é…ç½®è¯»å–å»é‡é€‰é¡¹
        advanced_opts = config.advanced
        priority_keys = advanced_opts.get('dedup_priority_keys', ['content', 'summary', 'quality_score'])
        use_fast_mode = advanced_opts.get('use_fast_dedup', True)
        
        deduped_articles, dedup_stats = deduplicate_items(
            filtered_articles,
            key='title',
            threshold=dedup_threshold,
            priority_keys=priority_keys,
            use_fast_mode=use_fast_mode
        )
        
        filtered_articles = deduped_articles
        after_dedup = dedup_stats['after']
        removed_by_dedup = dedup_stats['removed']
        
        logger.info(f"  ä¿ç•™: {after_dedup} ç¯‡")
        logger.info(f"  ç§»é™¤: {removed_by_dedup} ç¯‡ (é‡å¤)")
    
    # 4. æŒ‰è´¨é‡å¾—åˆ†æ’åºï¼ˆé™åºï¼‰
    logger.info(f"\nğŸ“ˆ æŒ‰è´¨é‡å¾—åˆ†æ’åº...")
    filtered_articles.sort(key=lambda x: x.get('quality_score', 0), reverse=True)
    
    # 5. æˆªå–æŒ‡å®šæ•°é‡
    removed_by_limit = 0
    if max_articles > 0 and len(filtered_articles) > max_articles:
        removed_by_limit = len(filtered_articles) - max_articles
        logger.info(f"\nâœ‚ï¸  é™åˆ¶æ•°é‡: æœ€å¤šä¿ç•™ {max_articles} ç¯‡")
        logger.info(f"  ç§»é™¤: {removed_by_limit} ç¯‡ (è¶…å‡ºé™åˆ¶)")
        filtered_articles = filtered_articles[:max_articles]
    
    final_count = len(filtered_articles)
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = {
        'original_count': original_count,
        'after_quality_filter': after_quality_filter,
        'after_dedup': after_dedup,
        'final_count': final_count,
        'removed_by_quality': removed_by_quality,
        'removed_by_dedup': removed_by_dedup,
        'removed_by_limit': removed_by_limit,
        'retention_rate': f"{(final_count / original_count * 100):.1f}%",
    }
    
    # æ‰“å°æ‘˜è¦
    logger.info(f"\n{'='*70}")
    logger.info(f"âœ… ç­›é€‰å®Œæˆ")
    logger.info(f"{'='*70}")
    logger.info(f"åŸå§‹æ–‡ç« :     {original_count} ç¯‡")
    logger.info(f"è´¨é‡è¿‡æ»¤å:   {after_quality_filter} ç¯‡ (ç§»é™¤ {removed_by_quality})")
    logger.info(f"å»é‡å:       {after_dedup} ç¯‡ (ç§»é™¤ {removed_by_dedup})")
    logger.info(f"æœ€ç»ˆä¿ç•™:     {final_count} ç¯‡ (ä¿ç•™ç‡ {stats['retention_rate']})")
    
    # æ˜¾ç¤ºTopæ–‡ç« ï¼ˆä½¿ç”¨é…ç½®ï¼‰
    if filtered_articles and config.advanced.get('show_top_articles', True):
        top_count = config.advanced.get('top_articles_count', 10)
        logger.info(f"\nğŸ† è´¨é‡ Top {top_count}:")
        for i, article in enumerate(filtered_articles[:top_count], 1):
            source = article.get('source_name', 'Unknown')
            title = article.get('title', 'No Title')
            score = article.get('quality_score', 0)
            logger.info(f"  {i:2d}. [{score:.2f}] {source} | {title[:60]}...")
    
    logger.info(f"{'='*70}\n")
    
    return filtered_articles, stats


def quick_filter(
    articles: List[Dict[str, Any]],
    quality_threshold: Optional[float] = None,
    max_articles: Optional[int] = None,
    config: Optional[QualityFilterConfig] = None
) -> List[Dict[str, Any]]:
    """
    å¿«é€Ÿç­›é€‰ï¼ˆç®€åŒ–ç‰ˆï¼Œç”¨äºå‘½ä»¤è¡Œå¿«é€Ÿè°ƒç”¨ï¼‰
    
    Args:
        articles: æ–‡ç« åˆ—è¡¨
        quality_threshold: è´¨é‡é˜ˆå€¼ï¼ˆNoneåˆ™ä½¿ç”¨é…ç½®ï¼‰
        max_articles: æœ€å¤šä¿ç•™æ–‡ç« æ•°ï¼ˆNoneåˆ™ä½¿ç”¨é…ç½®ï¼‰
        config: é…ç½®å¯¹è±¡ï¼ˆNoneåˆ™ä½¿ç”¨é»˜è®¤é…ç½®ï¼‰
    
    Returns:
        ç­›é€‰åçš„æ–‡ç« åˆ—è¡¨
    """
    filtered, stats = filter_and_rank_articles(
        articles,
        quality_threshold=quality_threshold,
        deduplicate=True,
        dedup_threshold=None,  # ä½¿ç”¨é…ç½®
        max_articles=max_articles,
        config=config
    )
    return filtered


# ============================================================================
# è¾…åŠ©åŠŸèƒ½ï¼šè´¨é‡æŠ¥å‘Š
# ============================================================================

def generate_quality_report(articles: List[Dict[str, Any]]) -> str:
    """
    ç”Ÿæˆè´¨é‡åˆ†ææŠ¥å‘Š
    
    Args:
        articles: æ–‡ç« åˆ—è¡¨ï¼ˆéœ€å·²è¯„åˆ†ï¼‰
    
    Returns:
        Markdownæ ¼å¼çš„è´¨é‡æŠ¥å‘Š
    """
    if not articles:
        return "# è´¨é‡æŠ¥å‘Š\n\næ— æ–‡ç« æ•°æ®"
    
    # ç»Ÿè®¡å„æ¥æºçš„æ–‡ç« æ•°å’Œå¹³å‡è´¨é‡
    source_stats = {}
    for article in articles:
        source = article.get('source_name', 'Unknown')
        score = article.get('quality_score', 0)
        
        if source not in source_stats:
            source_stats[source] = {'count': 0, 'total_score': 0, 'articles': []}
        
        source_stats[source]['count'] += 1
        source_stats[source]['total_score'] += score
        source_stats[source]['articles'].append(article)
    
    # è®¡ç®—å¹³å‡åˆ†
    for source, data in source_stats.items():
        data['avg_score'] = data['total_score'] / data['count']
    
    # ç”ŸæˆæŠ¥å‘Š
    report = "# ğŸ“Š æ–°é—»è´¨é‡åˆ†ææŠ¥å‘Š\n\n"
    
    report += "## æ€»ä½“ç»Ÿè®¡\n\n"
    report += f"- æ–‡ç« æ€»æ•°: {len(articles)}\n"
    report += f"- æ¥æºæ•°: {len(source_stats)}\n"
    
    scores = [a.get('quality_score', 0) for a in articles]
    avg_score = sum(scores) / len(scores)
    report += f"- å¹³å‡è´¨é‡: {avg_score:.2f}\n"
    report += f"- è´¨é‡èŒƒå›´: {min(scores):.2f} - {max(scores):.2f}\n\n"
    
    report += "## å„æ¥æºè´¨é‡ç»Ÿè®¡\n\n"
    report += "| æ¥æº | æ–‡ç« æ•° | å¹³å‡è´¨é‡ | å æ¯” |\n"
    report += "|------|--------|----------|------|\n"
    
    # æŒ‰å¹³å‡è´¨é‡æ’åº
    sorted_sources = sorted(
        source_stats.items(),
        key=lambda x: x[1]['avg_score'],
        reverse=True
    )
    
    for source, data in sorted_sources:
        count = data['count']
        avg = data['avg_score']
        ratio = count / len(articles) * 100
        report += f"| {source} | {count} | {avg:.2f} | {ratio:.1f}% |\n"
    
    return report


# ============================================================================
# æµ‹è¯•ä»£ç 
# ============================================================================

if __name__ == '__main__':
    # ä¿®å¤æ¨¡å—å¯¼å…¥é—®é¢˜
    import sys
    from pathlib import Path
    scripts_path = Path(__file__).resolve().parents[1]
    if str(scripts_path) not in sys.path:
        sys.path.insert(0, str(scripts_path))
    
    print("=== æµ‹è¯•æ–°é—»è´¨é‡ç­›é€‰æ¨¡å— ===\n")
    
    # æµ‹è¯•æ•°æ®
    test_articles = [
        {
            'id': 1,
            'source_name': 'åå°”è¡—è§é—»',
            'title': 'ç¾è”å‚¨å®£å¸ƒåŠ æ¯50ä¸ªåŸºç‚¹ï¼Œå¸‚åœºæš´è·Œ',
            'summary': 'ç¾è”å‚¨åœ¨ä»Šæ—¥å‡Œæ™¨å®£å¸ƒåŠ æ¯50ä¸ªåŸºç‚¹ï¼Œè¶…å‡ºå¸‚åœºé¢„æœŸã€‚' * 10,
            'content': 'è¯¦ç»†å†…å®¹' * 100,
            'published': '2025-10-11 10:00:00',
            'link': 'http://example.com/1'
        },
        {
            'id': 2,
            'source_name': '36æ°ª',
            'title': 'éœ‡æƒŠï¼ï¼ï¼è¿™åªè‚¡ç¥¨è¦ç¿»å€äº†ï¼ï¼ï¼',
            'summary': 'ç‚¹å‡»è´­ä¹°ï¼Œé™æ—¶ä¼˜æƒ ï¼ŒåŒ…èµšä¸èµ”',
            'content': None,
            'published': '2025-10-10 10:00:00',
            'link': 'http://example.com/2'
        },
        {
            'id': 3,
            'source_name': 'å›½å®¶ç»Ÿè®¡å±€',
            'title': '2025å¹´9æœˆCPIåŒæ¯”ä¸Šæ¶¨2.1%',
            'summary': 'å›½å®¶ç»Ÿè®¡å±€ä»Šæ—¥å‘å¸ƒæ•°æ®...' * 20,
            'content': 'è¯¦ç»†ç»Ÿè®¡æ•°æ®' * 200,
            'published': '2025-10-11 09:00:00',
            'link': 'http://example.com/3'
        },
        {
            'id': 4,
            'source_name': 'FTä¸­æ–‡ç½‘',
            'title': 'äººå·¥æ™ºèƒ½èŠ¯ç‰‡éœ€æ±‚æš´æ¶¨ï¼Œè‹±ä¼Ÿè¾¾è´¢æŠ¥è¶…é¢„æœŸ',
            'summary': 'AIèŠ¯ç‰‡å¸‚åœºæŒç»­ç«çƒ­...' * 15,
            'content': 'è¯¦ç»†åˆ†æ' * 150,
            'published': '2025-10-11 11:00:00',
            'link': 'http://example.com/4'
        },
        {
            'id': 5,
            'source_name': 'ä¸œæ–¹è´¢å¯Œ',
            'title': 'ä»Šæ—¥è‚¡å¸‚è¡Œæƒ…',
            'summary': 'ç®€çŸ­å†…å®¹',
            'content': None,
            'published': '2025-10-11 12:00:00',
            'link': 'http://example.com/5'
        },
        {
            'id': 6,
            'source_name': 'åå°”è¡—è§é—»',
            'title': 'ç¾è”å‚¨åŠ æ¯50åŸºç‚¹ï¼Œè‚¡å¸‚å¤§è·Œ',  # ä¸ç¬¬1æ¡ç›¸ä¼¼
            'summary': 'ç¾è”å‚¨æ˜¨æ—¥å®£å¸ƒåŠ æ¯...' * 8,
            'content': 'è¯¦ç»†å†…å®¹' * 80,
            'published': '2025-10-11 10:30:00',
            'link': 'http://example.com/6'
        },
    ]
    
    print(f"åŸå§‹æ–‡ç« æ•°: {len(test_articles)}\n")
    
    # æµ‹è¯•1: è´¨é‡è¯„åˆ†
    print("=" * 70)
    print("æµ‹è¯•1: è´¨é‡è¯„åˆ†")
    print("=" * 70)
    scored_articles = annotate_articles_with_scores(test_articles)
    
    print("\nè¯„åˆ†ç»“æœ:")
    for article in scored_articles:
        print(f"  [{article['id']}] {article['quality_score']:.2f} | "
              f"{article['source_name']} | {article['title'][:40]}...")
    
    # æµ‹è¯•2: è´¨é‡ç­›é€‰å’Œæ’åº
    print("\n" + "=" * 70)
    print("æµ‹è¯•2: è´¨é‡ç­›é€‰å’Œæ’åº")
    print("=" * 70)
    
    filtered, stats = filter_and_rank_articles(
        test_articles,
        quality_threshold=3.0,
        deduplicate=True,
        dedup_threshold=0.80,
        max_articles=5
    )
    
    print("\nç­›é€‰ç»“æœ:")
    for i, article in enumerate(filtered, 1):
        print(f"  {i}. [{article['quality_score']:.2f}] "
              f"{article['source_name']} | {article['title'][:40]}...")
    
    # æµ‹è¯•3: è´¨é‡æŠ¥å‘Š
    print("\n" + "=" * 70)
    print("æµ‹è¯•3: è´¨é‡æŠ¥å‘Š")
    print("=" * 70)
    report = generate_quality_report(scored_articles)
    print(report)
    
    print("\nâœ… æµ‹è¯•å®Œæˆ")

