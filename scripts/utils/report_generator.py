#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»Ÿä¸€æŠ¥å‘Šç”Ÿæˆå¼•æ“

æ ¸å¿ƒåŠŸèƒ½:
1. æ–‡ç« æŸ¥è¯¢å’Œè¿‡æ»¤
2. è´¨é‡ç­›é€‰å’Œå»é‡
3. è¯­æ–™æ„å»º
4. AIæŠ¥å‘Šç”Ÿæˆï¼ˆæ”¯æŒå¤šä¸ªæä¾›å•†ï¼‰
5. è´¨é‡æ£€æŸ¥å’Œè‡ªåŠ¨é‡è¯•
6. æŠ¥å‘Šä¿å­˜å’Œå…ƒæ•°æ®è®°å½•

ä½¿ç”¨ç¤ºä¾‹:
    from utils.report_generator import ReportGenerator
    from utils.providers import GeminiProvider

    generator = ReportGenerator(
        provider=GeminiProvider(api_key='your-key'),
        enable_verification=True
    )

    result = generator.generate(
        date='2026-01-07',
        quality_check=True,
        max_retries=3
    )
"""

import sys
from pathlib import Path
from typing import Optional, Dict, Any, Tuple
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = Path(__file__).resolve().parents[2]
sys.path.insert(0, str(PROJECT_ROOT))

from scripts.utils.ai_analyzer_common import (
    resolve_date_range, open_connection, query_articles,
    filter_articles, build_corpus, build_source_stats_block,
    save_markdown, save_metadata, write_json
)
from scripts.utils.quality_filter import filter_and_rank_articles
from scripts.utils.quality_checker import (
    check_report_quality, generate_quality_feedback,
    print_quality_summary, add_quality_warning
)
from scripts.utils.print_utils import (
    print_header, print_success, print_warning, print_error,
    print_info, print_progress, print_step, print_statistics
)
from scripts.utils.providers import BaseProvider

# éªŒè¯ç³»ç»Ÿæ¨¡å—ï¼ˆå¯é€‰ï¼‰
try:
    from scripts.utils.realtime_data_fetcher import RealtimeDataFetcher
    from scripts.utils.fact_checker import FactChecker
    from scripts.utils.quality_checker_v2 import check_report_quality_v2, print_quality_report_v2
    VERIFICATION_AVAILABLE = True
except ImportError:
    VERIFICATION_AVAILABLE = False


class ReportGenerator:
    """ç»Ÿä¸€æŠ¥å‘Šç”Ÿæˆå¼•æ“"""

    def __init__(
        self,
        provider: BaseProvider,
        db_path: Optional[Path] = None,
        enable_verification: bool = False,
        **config
    ):
        """
        åˆå§‹åŒ–æŠ¥å‘Šç”Ÿæˆå™¨

        Args:
            provider: AIæ¨¡å‹æä¾›å•†å®ä¾‹
            db_path: æ•°æ®åº“è·¯å¾„ï¼ˆé»˜è®¤ä¸ºé¡¹ç›®æ ¹ç›®å½•/data/news_data.dbï¼‰
            enable_verification: æ˜¯å¦å¯ç”¨éªŒè¯ç³»ç»Ÿï¼ˆå®æ—¶æ•°æ®+äº‹å®æ ¸æŸ¥+é«˜çº§è´¨é‡è¯„åˆ†ï¼‰
            **config: å…¶ä»–é…ç½®å‚æ•°
        """
        self.provider = provider
        self.db_path = db_path or (PROJECT_ROOT / 'data' / 'news_data.db')
        self.enable_verification = enable_verification
        self.config = config

        if enable_verification and not VERIFICATION_AVAILABLE:
            print_warning('éªŒè¯ç³»ç»Ÿæ¨¡å—æœªæ‰¾åˆ°ï¼Œå·²ç¦ç”¨éªŒè¯åŠŸèƒ½')
            self.enable_verification = False

    def load_prompt(self, prompt_version: str = 'pro_v2') -> str:
        """
        åŠ è½½æç¤ºè¯æ¨¡æ¿

        Args:
            prompt_version: æç¤ºè¯ç‰ˆæœ¬
                - 'pro_v2': ä¸“ä¸šç‰ˆv2ï¼ˆå¸¦å®æ—¶æ•°æ®æ³¨å…¥ï¼‰
                - 'pro': ä¸“ä¸šç‰ˆ
                - 'safe': å®‰å…¨ç‰ˆ

        Returns:
            str: æç¤ºè¯å†…å®¹
        """
        prompt_files = {
            'pro_v2': 'financial_analysis_prompt_pro_v2.md',
            'pro': 'financial_analysis_prompt_pro.md',
            'safe': 'financial_analysis_prompt_safe.md'
        }

        prompt_file = prompt_files.get(prompt_version, prompt_files['pro'])
        prompt_path = PROJECT_ROOT / 'task' / prompt_file

        if not prompt_path.exists():
            # å›é€€åˆ°ä¸“ä¸šç‰ˆ
            print_warning(f'æç¤ºè¯ {prompt_file} ä¸å­˜åœ¨ï¼Œå›é€€åˆ° pro ç‰ˆæœ¬')
            prompt_path = PROJECT_ROOT / 'task' / 'financial_analysis_prompt_pro.md'

        if not prompt_path.exists():
            raise FileNotFoundError(f'æç¤ºè¯æ–‡ä»¶ä¸å­˜åœ¨: {prompt_path}')

        with open(prompt_path, 'r', encoding='utf-8') as f:
            return f.read()

    def fetch_realtime_data(self) -> Optional[Dict[str, Any]]:
        """è·å–å®æ—¶å¸‚åœºæ•°æ®ï¼ˆå¦‚æœå¯ç”¨éªŒè¯ï¼‰"""
        if not self.enable_verification:
            return None

        try:
            print_progress('è·å–å®æ—¶å¸‚åœºæ•°æ®...')
            fetcher = RealtimeDataFetcher()
            data = fetcher.fetch_all()
            print_success(f'âœ“ è·å–æˆåŠŸ: {len(data)} ç±»æ•°æ®')
            return data
        except Exception as e:
            print_warning(f'å®æ—¶æ•°æ®è·å–å¤±è´¥: {e}')
            return None

    def generate_with_quality_check(
        self,
        prompt: str,
        content: str,
        quality_check: bool = False,
        max_retries: int = 0,
        min_score: int = 80,
        **kwargs
    ) -> Tuple[str, Dict[str, Any], Dict[str, Any]]:
        """
        ç”ŸæˆæŠ¥å‘Šå¹¶è¿›è¡Œè´¨é‡æ£€æŸ¥

        Args:
            prompt: ç³»ç»Ÿæç¤ºè¯
            content: ç”¨æˆ·è¾“å…¥å†…å®¹
            quality_check: æ˜¯å¦å¯ç”¨è´¨é‡æ£€æŸ¥
            max_retries: è´¨é‡ä¸è¾¾æ ‡æ—¶çš„æœ€å¤§é‡è¯•æ¬¡æ•°
            min_score: æœ€ä½è´¨é‡è¯„åˆ†
            **kwargs: ä¼ é€’ç»™providerçš„å…¶ä»–å‚æ•°

        Returns:
            Tuple[str, Dict, Dict]: (æŠ¥å‘Šæ–‡æœ¬, ä½¿ç”¨ç»Ÿè®¡, è´¨é‡æ£€æŸ¥ç»“æœ)
        """
        quality_checker = check_report_quality_v2 if self.enable_verification else check_report_quality

        for attempt in range(max_retries + 1):
            if attempt > 0:
                print_warning(f'\nğŸ”„ è´¨é‡ä¸è¾¾æ ‡ï¼Œç¬¬{attempt}æ¬¡é‡è¯•ï¼ˆå…±{max_retries}æ¬¡ï¼‰...\n')

            # ç”ŸæˆæŠ¥å‘Š
            if attempt == 0:
                print_progress('è°ƒç”¨AIæ¨¡å‹ç”ŸæˆæŠ•èµ„åˆ†ææŠ¥å‘Š...')

            report, usage = self.provider.generate(prompt, content, **kwargs)

            if attempt == 0:
                print_success('âœ“ æŠ¥å‘Šç”Ÿæˆå®Œæˆ')

            # è´¨é‡æ£€æŸ¥
            if quality_check:
                print_progress('è´¨é‡æ£€æŸ¥ä¸­...')
                quality_result = quality_checker(report)

                if self.enable_verification:
                    print_quality_report_v2(quality_result)
                else:
                    print_quality_summary(quality_result)

                # åˆ¤æ–­æ˜¯å¦é€šè¿‡
                passed = quality_result.get('passed', quality_result.get('score', 0) >= min_score)

                if passed:
                    print_success('âœ… è´¨é‡æ£€æŸ¥é€šè¿‡\n')
                    return report, usage, quality_result
                else:
                    if attempt < max_retries:
                        score = quality_result.get('score', 0)
                        issues_count = len(quality_result.get('issues', []))
                        warnings_count = len(quality_result.get('warnings', []))
                        print_warning(f'âš ï¸ è´¨é‡è¯„åˆ†: {score}/100 (è¦æ±‚â‰¥{min_score})')
                        print_info(f'é—®é¢˜æ•°é‡: {issues_count}ä¸ªä¸¥é‡é—®é¢˜, {warnings_count}ä¸ªè­¦å‘Š')
                    else:
                        print_error(f'âŒ å·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°({max_retries}æ¬¡)ï¼Œä½¿ç”¨å½“å‰ç‰ˆæœ¬')
                        print_warning('æŠ¥å‘Šè´¨é‡å¯èƒ½ä¸ç†æƒ³ï¼Œå»ºè®®äººå·¥å®¡æ ¸')
                        report = add_quality_warning(report, quality_result)
                        return report, usage, quality_result
            else:
                # ä¸å¯ç”¨è´¨é‡æ£€æŸ¥ï¼Œç›´æ¥è¿”å›
                if attempt == 0:
                    print_info('  â„¹ï¸ è´¨é‡æ£€æŸ¥å·²ç¦ç”¨ï¼ŒæŠ¥å‘Šæœªç»äºŒæ¬¡å¤„ç†')
                return report, usage, {}

        # è¿”å›æœ€åä¸€æ¬¡çš„ç»“æœ
        return report, usage, quality_result if quality_check else {}

    def generate(
        self,
        date: Optional[str] = None,
        start: Optional[str] = None,
        end: Optional[str] = None,
        limit: int = 0,
        max_articles: Optional[int] = None,
        filter_source: Optional[str] = None,
        filter_keyword: Optional[str] = None,
        order: str = 'desc',
        max_chars: int = 500000,
        content_field: str = 'summary',
        quality_check: bool = False,
        max_retries: int = 0,
        min_score: int = 80,
        prompt_version: str = 'pro_v2' if VERIFICATION_AVAILABLE else 'pro',
        output_json: Optional[str] = None,
        **provider_kwargs
    ) -> Dict[str, Any]:
        """
        ç”ŸæˆAIåˆ†ææŠ¥å‘Šï¼ˆä¸»å…¥å£ï¼‰

        Args:
            date: å•æ—¥æ—¥æœŸï¼ˆYYYY-MM-DDï¼‰
            start: å¼€å§‹æ—¥æœŸï¼ˆYYYY-MM-DDï¼‰
            end: ç»“æŸæ—¥æœŸï¼ˆYYYY-MM-DDï¼‰
            limit: æœ€å¤šè¯»å–å¤šå°‘æ¡è®°å½•
            max_articles: å‚ä¸åˆ†æçš„æ–‡ç« æ•°é‡ä¸Šé™
            filter_source: ä»…åˆ†ææŒ‡å®šæ¥æºï¼ˆé€—å·åˆ†éš”ï¼‰
            filter_keyword: å…³é”®è¯è¿‡æ»¤ï¼ˆé€—å·åˆ†éš”ï¼‰
            order: æ’åºæ–¹å‘ï¼ˆasc/descï¼‰
            max_chars: ä¼ å…¥æ¨¡å‹çš„æœ€å¤§å­—ç¬¦æ•°ä¸Šé™
            content_field: åˆ†æå­—æ®µï¼ˆsummary/content/autoï¼‰
            quality_check: æ˜¯å¦å¯ç”¨è´¨é‡æ£€æŸ¥
            max_retries: è´¨é‡ä¸è¾¾æ ‡æ—¶çš„æœ€å¤§é‡è¯•æ¬¡æ•°
            min_score: æœ€ä½è´¨é‡è¯„åˆ†
            prompt_version: æç¤ºè¯ç‰ˆæœ¬
            output_json: å¯é€‰ï¼šå¯¼å‡ºJSONæ–‡ä»¶è·¯å¾„
            **provider_kwargs: ä¼ é€’ç»™providerçš„å…¶ä»–å‚æ•°

        Returns:
            Dict: ç”Ÿæˆç»“æœï¼ŒåŒ…å« report, metadata, quality_result
        """
        # è§£ææ—¥æœŸèŒƒå›´
        class Args:
            pass
        args = Args()
        args.date = date
        args.start = start
        args.end = end
        start_date, end_date = resolve_date_range(args)

        print_header(f"AI è´¢ç»åˆ†æç³»ç»Ÿï¼ˆ{self.provider.get_provider_name()}ï¼‰")
        print_info(f"åˆ†ææ—¥æœŸèŒƒå›´: {start_date} â†’ {end_date}")
        print_info(f"å­—æ®µé€‰æ‹©æ¨¡å¼: {content_field}")
        if self.enable_verification:
            print_info("éªŒè¯ç³»ç»Ÿ: å·²å¯ç”¨ âœ…")
        if max_chars > 0:
            print_info(f"å­—ç¬¦æ•°é™åˆ¶: {max_chars:,}")
        if quality_check:
            print_info(f"è´¨é‡æ£€æŸ¥: å·²å¯ç”¨ï¼ˆæœ€å¤šé‡è¯•{max_retries}æ¬¡ï¼Œæœ€ä½è¯„åˆ†{min_score}ï¼‰")
        print()

        # è·å–å®æ—¶æ•°æ®ï¼ˆå¦‚æœå¯ç”¨éªŒè¯ï¼‰
        realtime_data = self.fetch_realtime_data()

        # æŸ¥è¯¢æ–‡ç« 
        conn = open_connection(self.db_path)
        try:
            rows = query_articles(conn, start_date, end_date, order, limit)
        finally:
            conn.close()

        if not rows:
            print_warning('æœªæ‰¾åˆ°æŒ‡å®šæ—¥æœŸèŒƒå›´çš„æ–‡ç« ï¼Œç»ˆæ­¢åˆ†æã€‚')
            return {'success': False, 'error': 'æœªæ‰¾åˆ°æ–‡ç« '}

        print_info(f'å·²è¯»å–æ–‡ç« ï¼š{len(rows):,} æ¡')

        # è¿‡æ»¤æ–‡ç« 
        selected = filter_articles(
            rows,
            filter_source=filter_source,
            filter_keyword=filter_keyword,
            max_articles=max_articles
        )

        # è´¨é‡ç­›é€‰å’Œæ’åº
        print_progress('è´¨é‡ç­›é€‰: è¿‡æ»¤ä½è´¨é‡æ–‡ç« å¹¶æ™ºèƒ½å»é‡...')
        selected, quality_stats = filter_and_rank_articles(selected)

        if not selected:
            print_warning('è´¨é‡ç­›é€‰åæ— æ–‡ç« å‰©ä½™ï¼Œè¯·é™ä½é˜ˆå€¼æˆ–æ£€æŸ¥æ•°æ®æº')
            return {'success': False, 'error': 'è´¨é‡ç­›é€‰åæ— æ–‡ç« '}

        # æ„å»ºè¯­æ–™
        pairs, total_len = build_corpus(selected, max_chars, per_chunk_chars=3000, content_field=content_field)
        current_len = sum(len(c) for _, chunks in pairs for c in chunks)
        print_info(f'è¯­æ–™é•¿åº¦: {current_len:,} å­—ç¬¦ï¼ˆåŸå§‹ {total_len:,}ï¼Œé™åˆ¶={max_chars:,}ï¼‰')
        if max_chars and max_chars > 0 and total_len > max_chars:
            print_warning(f'è¯­æ–™å·²æŒ‰ä¸Šé™æˆªæ–­ï¼š{total_len:,} â†’ {current_len:,}')

        # æ„å»ºç»Ÿè®¡ä¿¡æ¯
        stats_info = build_source_stats_block(selected, content_field, start_date, end_date)

        # æ³¨å…¥å®æ—¶æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
        if realtime_data:
            print_progress('æ³¨å…¥å®æ—¶å¸‚åœºæ•°æ®åˆ°æç¤ºè¯...')
            realtime_block = self._format_realtime_data(realtime_data)
            stats_info = realtime_block + "\n\n" + stats_info

        joined = '\n\n'.join(c for _, chunks in pairs for c in chunks)
        full_content = stats_info + "\n\n" + joined

        # åŠ è½½æç¤ºè¯
        prompt = self.load_prompt(prompt_version)

        # ç”ŸæˆæŠ¥å‘Šï¼ˆé›†æˆè´¨é‡æ£€æŸ¥ï¼‰
        print()
        try:
            summary_md, usage, quality_result = self.generate_with_quality_check(
                prompt, full_content,
                quality_check=quality_check,
                max_retries=max_retries,
                min_score=min_score,
                **provider_kwargs
            )
        except Exception as e:
            print_error(f'æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}')
            import traceback
            traceback.print_exc()
            return {'success': False, 'error': str(e)}

        # äº‹å®æ ¸æŸ¥ï¼ˆå¦‚æœå¯ç”¨éªŒè¯ï¼‰
        if self.enable_verification and realtime_data:
            print_progress('äº‹å®æ ¸æŸ¥: éªŒè¯æŠ¥å‘Šä¸­çš„æ•°æ®æ–­è¨€...')
            try:
                checker = FactChecker(realtime_data)
                check_result = checker.check_report(summary_md)

                # è¿½åŠ æ ¸æŸ¥æŠ¥å‘Š
                verification_report = checker.generate_verification_report(check_result)
                summary_md += "\n\n" + verification_report
                print_success(f'âœ“ äº‹å®æ ¸æŸ¥å®Œæˆ: {check_result["stats"]["total"]} ä¸ªæ–­è¨€')
            except Exception as e:
                print_warning(f'äº‹å®æ ¸æŸ¥å¤±è´¥ï¼ˆè·³è¿‡ï¼‰: {e}')

        # ä¿å­˜æŠ¥å‘Š
        print_progress('ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶...')
        model_suffix = self.provider.get_provider_name().lower()
        saved_path = save_markdown(end_date, summary_md, model_suffix=model_suffix)

        # ä¿å­˜å…ƒæ•°æ®
        meta = {
            'date_range': {'start': start_date, 'end': end_date},
            'articles_used': len(selected),
            'chunks': sum(len(ch) for _, ch in pairs),
            'model_usage': usage,
            'quality_check': quality_result if quality_result else None,
            'verification_enabled': self.enable_verification,
        }
        save_metadata(end_date, meta, model_suffix=model_suffix)

        # å¯é€‰å¯¼å‡ºJSON
        if output_json:
            out_path = Path(output_json)
            if not out_path.is_absolute():
                out_path = PROJECT_ROOT / out_path
            write_json(out_path, summary_md, rows)

        print_success('åˆ†æå®Œæˆï¼')

        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        stats = {
            'åˆ†ææ—¥æœŸèŒƒå›´': f"{start_date} â†’ {end_date}",
            'å¤„ç†æ–‡ç« æ•°': len(selected),
            'è¯­æ–™å—æ•°': sum(len(ch) for _, ch in pairs),
            'æœ€ç»ˆå­—ç¬¦æ•°': f"{current_len:,}",
            'ä½¿ç”¨æ¨¡å‹': usage.get('model', 'æœªçŸ¥'),
            'Tokenæ¶ˆè€—': f"{usage.get('total_tokens', 0):,}" if usage.get('total_tokens') else 'æœªçŸ¥'
        }
        print_statistics(stats)

        return {
            'success': True,
            'report_path': str(saved_path),
            'report_text': summary_md,
            'metadata': meta,
            'quality_result': quality_result
        }

    def _format_realtime_data(self, realtime_data: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–å®æ—¶æ•°æ®ä¸ºMarkdownå—"""
        lines = ["## ğŸ“Š å®æ—¶å¸‚åœºæ•°æ®", ""]

        for key, value in realtime_data.items():
            if isinstance(value, dict):
                lines.append(f"### {key}")
                for k, v in value.items():
                    lines.append(f"- **{k}**: {v}")
                lines.append("")
            else:
                lines.append(f"- **{key}**: {value}")

        return "\n".join(lines)
