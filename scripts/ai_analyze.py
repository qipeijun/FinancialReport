#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AI åˆ†æè„šæœ¬ï¼ˆGeminiç‰ˆæœ¬ï¼‰- é‡æ„ç‰ˆ

åŠŸèƒ½ï¼š
- ä» `data/news_data.db` è¯»å–æŒ‡å®šæ—¥æœŸèŒƒå›´å†…çš„æ–‡ç« 
- è°ƒç”¨ Gemini æ¨¡å‹ç”Ÿæˆ Markdown åˆ†æ
- è‡ªåŠ¨æ·»åŠ å®æ—¶è‚¡ç¥¨æ•°æ®
- å°†æŠ¥å‘Šä¿å­˜åˆ° `docs/archive/YYYY-MM/YYYY-MM-DD/reports/` ä¸‹

ç¤ºä¾‹ï¼š
      python3 scripts/ai_analyze.py
  python3 scripts/ai_analyze.py --date 2025-10-11
  python3 scripts/ai_analyze.py --start 2025-10-10 --end 2025-10-11
"""

import argparse
import os
from pathlib import Path
from typing import Optional, Tuple, Dict, Any
import yaml

# å¯¼å…¥å…¬å…±æ¨¡å—
from utils.ai_analyzer_common import *
# from utils.data_enrichment import DataEnricher  # å·²ç¦ç”¨æ•°æ®å¢å¼ºåŠŸèƒ½
from utils.quality_filter import filter_and_rank_articles
from utils.quality_checker import (
    check_report_quality, generate_quality_feedback, 
    print_quality_report, print_quality_summary, add_quality_warning
)
from utils.print_utils import (
    print_header, print_success, print_warning, print_error,
    print_info, print_progress, print_step, print_statistics
)

try:
    import google.generativeai as genai
except Exception:
    genai = None


PROJECT_ROOT = Path(__file__).resolve().parents[1]
DB_PATH = PROJECT_ROOT / 'data' / 'news_data.db'


def parse_args() -> argparse.Namespace:
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='ä»æ•°æ®åº“è¯»å–æ–°é—»å¹¶è°ƒç”¨ Gemini ç”Ÿæˆåˆ†ææŠ¥å‘Š')
    date_group = parser.add_mutually_exclusive_group()
    date_group.add_argument('--date', type=str, help='æŒ‡å®šå•æ—¥ï¼ˆYYYY-MM-DDï¼‰')
    parser.add_argument('--start', type=str, help='å¼€å§‹æ—¥æœŸï¼ˆYYYY-MM-DDï¼‰ï¼Œé»˜è®¤ä¸ºå½“å¤©')
    parser.add_argument('--end', type=str, help='ç»“æŸæ—¥æœŸï¼ˆYYYY-MM-DDï¼‰ï¼Œé»˜è®¤ä¸ºå½“å¤©')
    parser.add_argument('--limit', type=int, default=0, help='æœ€å¤šè¯»å–å¤šå°‘æ¡è®°å½•ï¼ˆ0è¡¨ç¤ºä¸é™åˆ¶ï¼‰')
    parser.add_argument('--max-articles', type=int, help='å¯é€‰ï¼šå¯¹å‚ä¸åˆ†æçš„æ–‡ç« å†æ§é‡')
    parser.add_argument('--filter-source', type=str, help='ä»…åˆ†ææŒ‡å®šæ¥æºï¼ˆé€—å·åˆ†éš”ï¼‰')
    parser.add_argument('--filter-keyword', type=str, help='ä»…åˆ†ææ ‡é¢˜/æ‘˜è¦åŒ…å«å…³é”®è¯çš„æ–‡ç« ï¼ˆé€—å·åˆ†éš”ï¼‰')
    parser.add_argument('--order', choices=['asc', 'desc'], default='desc', help='æ’åºæ–¹å‘')
    parser.add_argument('--output-json', type=str, help='å¯é€‰ï¼šå°†ç»“æœå¯¼å‡ºä¸º JSON æ–‡ä»¶')
    parser.add_argument('--max-chars', type=int, default=500000, help='ä¼ å…¥æ¨¡å‹çš„æœ€å¤§å­—ç¬¦æ•°ä¸Šé™')
    parser.add_argument('--api-key', type=str, help='å¯é€‰ï¼šæ˜¾å¼ä¼ å…¥ Gemini API Key')
    parser.add_argument('--config', type=str, help='å¯é€‰ï¼šé…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ config/config.ymlï¼‰')
    parser.add_argument('--content-field', choices=['summary', 'content', 'auto'], default='summary', 
                        help='é€‰æ‹©åˆ†æå­—æ®µï¼šsummary(æ‘˜è¦ä¼˜å…ˆ)ã€content(æ­£æ–‡ä¼˜å…ˆ)ã€auto(æ™ºèƒ½é€‰æ‹©)')
    parser.add_argument('--model', type=str, help='å¯é€‰ï¼šæŒ‡å®š Gemini æ¨¡å‹ï¼ˆå¦‚ gemini-2.5-proï¼‰')
    parser.add_argument('--quality-check', action='store_true', default=False,
                        help='å¯ç”¨è´¨é‡æ£€æŸ¥ï¼ˆé»˜è®¤å…³é—­ï¼‰ï¼Œè‡ªåŠ¨æ£€æµ‹æŠ¥å‘Šè´¨é‡å¹¶é‡è¯•')
    parser.add_argument('--max-retries', type=int, default=0,
                        help='è´¨é‡æ£€æŸ¥ä¸é€šè¿‡æ—¶çš„æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤0æ¬¡ï¼Œå³ä¸é‡è¯•ï¼‰')
    return parser.parse_args()


def load_api_key(args: argparse.Namespace) -> str:
    """åŠ è½½Gemini API Keyï¼ˆä¼˜å…ˆçº§ï¼šå‘½ä»¤è¡Œ > ç¯å¢ƒå˜é‡ > é…ç½®æ–‡ä»¶ï¼‰"""
    config_path = Path(args.config) if args.config else (PROJECT_ROOT / 'config' / 'config.yml')
    api_key: Optional[str] = None
    
    # 1. å°è¯•ä»å‘½ä»¤è¡Œå‚æ•°è¯»å–
    if args.api_key:
        api_key = args.api_key
        print_success('ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°æä¾›çš„ API Key')
        return api_key
    
    # 2. å°è¯•ä»ç¯å¢ƒå˜é‡è¯»å–
    env_key = os.getenv('GEMINI_API_KEY')
    if env_key:
        api_key = env_key
        print_success('ä½¿ç”¨ç¯å¢ƒå˜é‡ GEMINI_API_KEY')
        return api_key
    
    # 3. å°è¯•ä»é…ç½®æ–‡ä»¶è¯»å–
    if config_path.exists():
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                cfg = yaml.safe_load(f) or {}
            api_key = (
                (cfg.get('api_keys') or {}).get('gemini')
                or (cfg.get('gemini') or {}).get('api_key')
            )
            if api_key:
                print_success(f'ä½¿ç”¨é…ç½®æ–‡ä»¶ï¼š{config_path}')
                return api_key
        except Exception as e:
            print_warning(f'è¯»å–é…ç½®å¤±è´¥ï¼ˆ{config_path}ï¼‰ï¼š{e}')
    
    # 4. éƒ½æ²¡æ‰¾åˆ°ï¼ŒæŠ¥é”™
    raise SystemExit(
        "æœªæ‰¾åˆ° Gemini API Keyã€‚è¯·ä½¿ç”¨ä»¥ä¸‹ä»»ä¸€æ–¹å¼é…ç½®ï¼š\n"
        "  1. ç¯å¢ƒå˜é‡ï¼šexport GEMINI_API_KEY='your-key'\n"
        "  2. é…ç½®æ–‡ä»¶ï¼šconfig/config.yml ä¸­çš„ api_keys.gemini\n"
        "  3. å‘½ä»¤è¡Œå‚æ•°ï¼š--api-key 'your-key'"
    )


def call_gemini(api_key: str, content: str, preferred_model: Optional[str] = None) -> Tuple[str, Dict[str, Any]]:
    """è°ƒç”¨Geminiæ¨¡å‹ç”Ÿæˆåˆ†æ"""
    if genai is None:
        raise SystemExit('æœªå®‰è£… google-generativeaiï¼Œè¯·å…ˆå®‰è£…ã€‚')

    # é€‰æ‹©æ¨¡å‹
    if preferred_model:
        model_names = [f'models/{preferred_model}' if not preferred_model.startswith('models/') else preferred_model]
        print_info(f'ä½¿ç”¨æŒ‡å®šæ¨¡å‹: {model_names[0]}')
    else:
        model_names = [
            'models/gemini-2.5-pro',
            'models/gemini-2.5-flash',
            'models/gemini-2.0-flash',
            'models/gemini-pro-latest'
        ]
        print_info('æŒ‰ä¼˜å…ˆçº§å°è¯•æ¨¡å‹: 2.5-pro â†’ 2.5-flash â†’ 2.0-flash â†’ pro-latest')

    genai.configure(api_key=api_key)
    print_progress(f'æ­£åœ¨ç”ŸæˆæŠ¥å‘Šï¼ˆè¾“å…¥é•¿åº¦ {len(content):,} å­—ç¬¦ï¼‰')

    # è¯»å–æç¤ºè¯
    prompt_path = PROJECT_ROOT / 'task' / 'financial_analysis_prompt_pro.md'
    if not prompt_path.exists():
        raise SystemExit(f'æç¤ºè¯æ–‡ä»¶ä¸å­˜åœ¨: {prompt_path}')
    
    with open(prompt_path, 'r', encoding='utf-8') as f:
        system_prompt_template = f.read()
    
    # å°è¯•å¤šä¸ªæ¨¡å‹
    last_error: Optional[Exception] = None
    for i, model_name in enumerate(model_names, 1):
        try:
            print_step(i, len(model_names), f'å°è¯•æ¨¡å‹: {model_name}')
            
            # æ›¿æ¢æ¨¡å‹å ä½ç¬¦
            system_prompt = system_prompt_template.replace(
                '[ä½¿ç”¨çš„å…·ä½“æ¨¡å‹åç§°]', 
                model_name.replace('models/', '')
            )
            
            model = genai.GenerativeModel(model_name)
            resp = model.generate_content([system_prompt, content])
            print_success(f'æ¨¡å‹è°ƒç”¨æˆåŠŸ: {model_name}')
            
            usage = {'model': model_name}
            try:
                if hasattr(resp, 'usage_metadata') and resp.usage_metadata:
                    usage_metadata = resp.usage_metadata
                    usage['prompt_tokens'] = getattr(usage_metadata, 'prompt_token_count', 0)
                    usage['candidates_tokens'] = getattr(usage_metadata, 'candidates_token_count', 0)
                    usage['total_tokens'] = getattr(usage_metadata, 'total_token_count', 0)
            except Exception:
                pass
            
            return resp.text, usage
        except Exception as e:
            last_error = e
            continue

    raise RuntimeError(f'æ‰€æœ‰æ¨¡å‹è°ƒç”¨å¤±è´¥ï¼Œæœ€åé”™è¯¯ï¼š{last_error}')


# æ•°æ®å¢å¼ºåŠŸèƒ½å·²ç¦ç”¨ï¼ˆç”¨æˆ·ä¸éœ€è¦æ­¤åŠŸèƒ½ï¼‰
# def enhance_with_realtime_data(api_key: str, report_text: str) -> str:
#     """ä½¿ç”¨AIå¢å¼ºæŠ¥å‘Šï¼Œæ·»åŠ å®æ—¶è‚¡ç¥¨æ•°æ®"""
#     try:
#         genai.configure(api_key=api_key)
#         # æ³¨æ„ï¼šå¦‚æœå°†æ¥éœ€è¦é‡æ–°å¯ç”¨ï¼Œéœ€è¦å°† 'gemini-pro' æ”¹ä¸º 'gemini-2.0-flash-exp' æˆ–å…¶ä»–å¯ç”¨æ¨¡å‹
#         client = genai.GenerativeModel('gemini-pro')
#         enricher = DataEnricher(ai_client=client)
#         enhanced_report = enricher.enrich_report(report_text)
#         print_success('æ•°æ®å¢å¼ºå®Œæˆ')
#         return enhanced_report
#     except Exception as e:
#         print_warning(f'æ•°æ®å¢å¼ºå¤±è´¥ï¼ˆè·³è¿‡ï¼‰: {e}')
#         return report_text


def generate_report_with_quality_check(api_key: str, selected: list, args: argparse.Namespace, 
                                       full_content: str = None) -> Tuple[str, Dict, Dict]:
    """
    ç”ŸæˆæŠ¥å‘Šå¹¶è¿›è¡Œè´¨é‡æ£€æŸ¥ï¼ˆå…¨è‡ªåŠ¨æ¨¡å¼ï¼‰
    
    Args:
        api_key: Gemini API Key
        selected: æ–‡ç« åˆ—è¡¨
        args: å‘½ä»¤è¡Œå‚æ•°
        full_content: å¦‚æœæ˜¯å•é˜¶æ®µæ¨¡å¼ï¼Œä¼ å…¥å®Œæ•´è¯­æ–™
        
    Returns:
        (æŠ¥å‘Šæ–‡æœ¬, ä½¿ç”¨ç»Ÿè®¡, è´¨é‡æ£€æŸ¥ç»“æœ)
    """
    max_retries = args.max_retries
    
    for attempt in range(max_retries + 1):
        if attempt > 0:
            print_warning(f'\nğŸ”„ è´¨é‡ä¸è¾¾æ ‡ï¼Œç¬¬{attempt}æ¬¡é‡è¯•ï¼ˆå…±{max_retries}æ¬¡ï¼‰...\n')
        
        # ç”ŸæˆæŠ¥å‘Š
        if attempt == 0:
            print_progress('è°ƒç”¨Geminiæ¨¡å‹ç”ŸæˆæŠ•èµ„åˆ†ææŠ¥å‘Š...')
        
        report, usage = call_gemini(api_key, full_content, preferred_model=args.model)
        
        if attempt == 0:
            print_success('âœ“ æŠ¥å‘Šç”Ÿæˆå®Œæˆ')
        
        # è´¨é‡æ£€æŸ¥
        if args.quality_check:
            print_progress('è´¨é‡æ£€æŸ¥ä¸­...')
            quality_result = check_report_quality(report)
            print_quality_summary(quality_result)
            
            if quality_result['passed']:
                print_success('âœ… è´¨é‡æ£€æŸ¥é€šè¿‡\n')
                return report, usage, quality_result
            else:
                if attempt < max_retries:
                    # ç”Ÿæˆæ”¹è¿›å»ºè®®
                    feedback = generate_quality_feedback(quality_result)
                    print_warning(f'âš ï¸ è´¨é‡è¯„åˆ†: {quality_result["score"]}/100')
                    print_info(f'é—®é¢˜æ•°é‡: {len(quality_result["issues"])}ä¸ªä¸¥é‡é—®é¢˜, {len(quality_result["warnings"])}ä¸ªè­¦å‘Š')
                    # æ³¨: æ”¹è¿›å»ºè®®ä¸ä¼šè‡ªåŠ¨æ·»åŠ åˆ°æç¤ºè¯ä¸­ï¼Œè€Œæ˜¯ç”¨äºä¸‹ä¸€æ¬¡é‡è¯•æ—¶çš„å‚è€ƒ
                else:
                    print_error(f'âŒ å·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°({max_retries}æ¬¡)ï¼Œä½¿ç”¨å½“å‰ç‰ˆæœ¬')
                    print_warning('æŠ¥å‘Šè´¨é‡å¯èƒ½ä¸ç†æƒ³ï¼Œå»ºè®®äººå·¥å®¡æ ¸')
                    # åœ¨æŠ¥å‘Šå¼€å¤´æ·»åŠ è´¨é‡è­¦å‘Š
                    report = add_quality_warning(report, quality_result)
                    return report, usage, quality_result
        else:
            # ä¸å¯ç”¨è´¨é‡æ£€æŸ¥ï¼Œç›´æ¥è¿”å›åŸå§‹æŠ¥å‘Šï¼ˆé›¶å¹²é¢„ï¼‰
            if attempt == 0:
                print_info('  â„¹ï¸ è´¨é‡æ£€æŸ¥å·²ç¦ç”¨ï¼ŒæŠ¥å‘Šæœªç»äºŒæ¬¡å¤„ç†')
            return report, usage, {}
    
    # ç†è®ºä¸Šä¸ä¼šåˆ°è¾¾è¿™é‡Œï¼ˆè´¨é‡æ£€æŸ¥å¾ªç¯ç»“æŸä»æœªé€šè¿‡ï¼‰
    # è¿”å›æœ€åä¸€æ¬¡çš„ç»“æœ
    return report, usage, quality_result if args.quality_check else {}


def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()
    start, end = resolve_date_range(args)

    print_header("AI è´¢ç»åˆ†æç³»ç»Ÿï¼ˆGeminiï¼‰")
    print_info(f"åˆ†ææ—¥æœŸèŒƒå›´: {start} â†’ {end}")
    print_info(f"å­—æ®µé€‰æ‹©æ¨¡å¼: {args.content_field}")
    if args.max_chars > 0:
        print_info(f"å­—ç¬¦æ•°é™åˆ¶: {args.max_chars:,}")
    
    # æ˜¾ç¤ºå¯ç”¨çš„åŠŸèƒ½
    features = []
    if args.quality_check:
        features.append(f"è´¨é‡æ£€æŸ¥(æœ€å¤šé‡è¯•{args.max_retries}æ¬¡)")
    if features:
        print_info(f"å¯ç”¨åŠŸèƒ½: {', '.join(features)}")
    print()

    # åŠ è½½API Key
    api_key = load_api_key(args)

    # æŸ¥è¯¢æ–‡ç« 
    conn = open_connection(DB_PATH)
    try:
        rows = query_articles(conn, start, end, args.order, args.limit)
    finally:
        conn.close()

    if not rows:
        print_warning('æœªæ‰¾åˆ°æŒ‡å®šæ—¥æœŸèŒƒå›´çš„æ–‡ç« ï¼Œç»ˆæ­¢åˆ†æã€‚')
        return
    print_info(f'å·²è¯»å–æ–‡ç« ï¼š{len(rows):,} æ¡')

    # è¿‡æ»¤æ–‡ç« 
    selected = filter_articles(
        rows,
        filter_source=args.filter_source,
        filter_keyword=args.filter_keyword,
        max_articles=args.max_articles
    )
    
    # è´¨é‡ç­›é€‰å’Œæ’åºï¼ˆæ–°å¢ï¼‰
    print_progress('è´¨é‡ç­›é€‰: è¿‡æ»¤ä½è´¨é‡æ–‡ç« å¹¶æ™ºèƒ½å»é‡...')
    selected, quality_stats = filter_and_rank_articles(
        selected
        # æ‰€æœ‰å‚æ•°éƒ½ä» config/quality_filter_config.yml è¯»å–
        # å¯é€šè¿‡ä¿®æ”¹é…ç½®æ–‡ä»¶æ¥è°ƒæ•´è´¨é‡é˜ˆå€¼ã€å»é‡å‚æ•°ç­‰
    )
    
    if not selected:
        print_warning('è´¨é‡ç­›é€‰åæ— æ–‡ç« å‰©ä½™ï¼Œè¯·é™ä½é˜ˆå€¼æˆ–æ£€æŸ¥æ•°æ®æº')
        return

    # æ„å»ºè¯­æ–™
    pairs, total_len = build_corpus(selected, args.max_chars, per_chunk_chars=3000, content_field=args.content_field)
    current_len = sum(len(c) for _, chunks in pairs for c in chunks)
    print_info(f'è¯­æ–™é•¿åº¦: {current_len:,} å­—ç¬¦ï¼ˆåŸå§‹ {total_len:,}ï¼Œé™åˆ¶={args.max_chars:,}ï¼‰')
    if args.max_chars and args.max_chars > 0 and total_len > args.max_chars:
        print_warning(f'è¯­æ–™å·²æŒ‰ä¸Šé™æˆªæ–­ï¼š{total_len:,} â†’ {current_len:,}')

    # æ„å»ºç»Ÿè®¡ä¿¡æ¯
    stats_info = build_source_stats_block(selected, args.content_field, start, end)
    joined = '\n\n'.join(c for _, chunks in pairs for c in chunks)
    full_content = stats_info + "\n\n" + joined

    # ç”ŸæˆæŠ¥å‘Šï¼ˆé›†æˆè´¨é‡æ£€æŸ¥ï¼‰
    print()
    try:
        summary_md, usage, quality_result = generate_report_with_quality_check(
            api_key, selected, args, full_content
        )
    except Exception as e:
        print_error(f'æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}')
        import traceback
        traceback.print_exc()
        return

    # æ•°æ®å¢å¼ºï¼šæ·»åŠ å®æ—¶è‚¡ç¥¨æ•°æ®ï¼ˆå·²ç¦ç”¨ï¼Œç”¨æˆ·ä¸éœ€è¦æ­¤åŠŸèƒ½ï¼‰
    # print_progress('æ•°æ®å¢å¼º: ä¸ºæŠ¥å‘Šæ·»åŠ å®æ—¶è‚¡ç¥¨æ•°æ®...')
    # summary_md = enhance_with_realtime_data(api_key, summary_md)

    # ä¿å­˜æŠ¥å‘Š
    print_progress('ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶...')
    saved_path = save_markdown(end, summary_md, model_suffix='gemini')
    
    # ä¿å­˜å…ƒæ•°æ®
    meta = {
        'date_range': {'start': start, 'end': end},
        'articles_used': len(selected),
        'chunks': sum(len(ch) for _, ch in pairs),
        'model_usage': usage,
        'quality_check': quality_result if quality_result else None,
    }
    save_metadata(end, meta, model_suffix='gemini')

    # å¯é€‰å¯¼å‡ºJSON
    if args.output_json:
        out_path = Path(args.output_json)
        if not out_path.is_absolute():
            out_path = PROJECT_ROOT / out_path
        write_json(out_path, summary_md, rows)

    print_success('åˆ†æå®Œæˆï¼')

    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    stats = {
        'åˆ†ææ—¥æœŸèŒƒå›´': f"{start} â†’ {end}",
        'å¤„ç†æ–‡ç« æ•°': len(selected),
        'è¯­æ–™å—æ•°': sum(len(ch) for _, ch in pairs),
        'æœ€ç»ˆå­—ç¬¦æ•°': f"{current_len:,}",
        'ä½¿ç”¨æ¨¡å‹': usage.get('model', 'æœªçŸ¥'),
        'Tokenæ¶ˆè€—': f"{usage.get('total_tokens', 0):,}" if usage.get('total_tokens') else 'æœªçŸ¥'
    }
    print_statistics(stats)


if __name__ == '__main__':
    main()
