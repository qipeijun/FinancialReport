#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AI åˆ†æè„šæœ¬ï¼ˆåŸºäºæ•°æ®åº“ï¼‰

åŠŸèƒ½ï¼š
- ä» `data/news_data.db` è¯»å–æŒ‡å®šæ—¥æœŸèŒƒå›´å†…çš„æ–‡ç« 
- è¯­æ–™æ„é€ ä¼˜å…ˆä½¿ç”¨ `content`ï¼ˆæ­£æ–‡ï¼‰ï¼Œä¸ºç©ºåˆ™å›é€€ `summary`
- è°ƒç”¨ Gemini æ¨¡å‹ç”Ÿæˆ Markdown åˆ†æï¼ˆå¤šæ¨¡å‹å…œåº•ï¼‰
- å°†æŠ¥å‘Šä¿å­˜åˆ° `docs/archive/YYYY-MM/YYYY-MM-DD/reports/` ä¸‹
- å¯é€‰å¯¼å‡º JSONï¼ˆåŒ…å« summary ä¸æ–‡ç« å…ƒæ•°æ®ï¼‰

ç¤ºä¾‹ï¼š
  - åˆ†æå½“å¤©ï¼š
      python3 scripts/ai_analyze.py
  - æŒ‡å®šæ—¥æœŸï¼š
      python3 scripts/ai_analyze.py --date 2025-09-29
  - æŒ‡å®šèŒƒå›´å¹¶å¯¼å‡º JSONï¼š
      python3 scripts/ai_analyze.py --start 2025-09-28 --end 2025-09-29 --output-json /tmp/analysis.json
"""

import argparse
import json
import os
import sqlite3
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple

import pytz
import yaml

try:
    import google.generativeai as genai
except Exception:  # å…è®¸ç¯å¢ƒç¼ºå¤±æ—¶å…ˆè¡Œæç¤º
    genai = None


PROJECT_ROOT = Path(__file__).resolve().parents[1]
DB_PATH = PROJECT_ROOT / 'data' / 'news_data.db'


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description='ä»æ•°æ®åº“è¯»å–æ–°é—»å¹¶è°ƒç”¨ Gemini ç”Ÿæˆåˆ†ææŠ¥å‘Š')
    date_group = parser.add_mutually_exclusive_group()
    date_group.add_argument('--date', type=str, help='æŒ‡å®šå•æ—¥ï¼ˆYYYY-MM-DDï¼‰')
    parser.add_argument('--start', type=str, help='å¼€å§‹æ—¥æœŸï¼ˆYYYY-MM-DDï¼‰ï¼Œé»˜è®¤ä¸ºå½“å¤©')
    parser.add_argument('--end', type=str, help='ç»“æŸæ—¥æœŸï¼ˆYYYY-MM-DDï¼‰ï¼Œé»˜è®¤ä¸ºå½“å¤©')
    parser.add_argument('--limit', type=int, default=0, help='æœ€å¤šè¯»å–å¤šå°‘æ¡è®°å½•ï¼ˆ0è¡¨ç¤ºä¸é™åˆ¶ï¼‰')
    parser.add_argument('--order', choices=['asc', 'desc'], default='desc', help='æ’åºæ–¹å‘ï¼ŒåŸºäº published ä¼˜å…ˆã€å¦åˆ™ created_at')
    parser.add_argument('--output-json', type=str, help='å¯é€‰ï¼šå°†ç»“æœï¼ˆsummary+æ–‡ç« å…ƒæ•°æ®ï¼‰å¯¼å‡ºä¸º JSON æ–‡ä»¶')
    parser.add_argument('--max-chars', type=int, default=200000, help='ä¼ å…¥æ¨¡å‹çš„æœ€å¤§å­—ç¬¦æ•°ä¸Šé™ï¼Œç”¨äºæ§åˆ¶æˆæœ¬ï¼Œ0 è¡¨ç¤ºä¸é™åˆ¶')
    parser.add_argument('--api-key', type=str, help='å¯é€‰ï¼šæ˜¾å¼ä¼ å…¥ Gemini API Keyï¼ˆé»˜è®¤ä»é…ç½®/ç¯å¢ƒè¯»å–ï¼‰')
    parser.add_argument('--config', type=str, help='å¯é€‰ï¼šé…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ config/config.ymlï¼‰')
    return parser.parse_args()


def validate_date(date_str: str) -> str:
    try:
        datetime.strptime(date_str, '%Y-%m-%d')
        return date_str
    except ValueError:
        raise SystemExit(f'æ— æ•ˆæ—¥æœŸæ ¼å¼: {date_str}ï¼Œåº”ä¸º YYYY-MM-DD')


def resolve_date_range(args: argparse.Namespace) -> Tuple[str, str]:
    today = datetime.now(pytz.timezone('Asia/Shanghai')).strftime('%Y-%m-%d')
    if args.date:
        day = validate_date(args.date)
        return day, day
    start = validate_date(args.start) if args.start else today
    end = validate_date(args.end) if args.end else today
    if start > end:
        raise SystemExit(f'å¼€å§‹æ—¥æœŸä¸å¾—æ™šäºç»“æŸæ—¥æœŸ: {start} > {end}')
    return start, end


def open_connection(db_path: Path) -> sqlite3.Connection:
    if not db_path.exists():
        raise SystemExit(f'æ•°æ®åº“ä¸å­˜åœ¨: {db_path}')
    conn = sqlite3.connect(db_path)
    conn.row_factory = sqlite3.Row
    return conn


def build_query(order: str, limit: int) -> Tuple[str, List[Any]]:
    sql = [
        'SELECT a.id, a.collection_date, a.title, a.link, a.published, a.summary, a.content, s.source_name',
        'FROM news_articles a',
        'JOIN rss_sources s ON a.source_id = s.id',
        'WHERE a.collection_date BETWEEN ? AND ?'
    ]
    params: List[Any] = []

    order_dir = 'DESC' if order.lower() == 'desc' else 'ASC'
    sql.append('ORDER BY COALESCE(a.published, a.created_at) ' + order_dir)

    if limit and limit > 0:
        sql.append('LIMIT ?')
        params.append(limit)

    return '\n'.join(sql), params


def query_articles(conn: sqlite3.Connection, start: str, end: str, order: str, limit: int) -> List[Dict[str, Any]]:
    sql, tail = build_query(order, limit)
    params = [start, end] + tail
    cur = conn.execute(sql, params)
    rows = cur.fetchall()
    results: List[Dict[str, Any]] = []
    for r in rows:
        results.append({
            'id': r['id'],
            'collection_date': r['collection_date'],
            'title': r['title'],
            'link': r['link'],
            'source': r['source_name'],
            'published': r['published'],
            'summary': r['summary'],
            'content': r['content']
        })
    return results


def build_corpus(articles: List[Dict[str, Any]], max_chars: int) -> Tuple[str, int]:
    """æ„é€ ä¼ ç»™æ¨¡å‹çš„è¯­æ–™ï¼Œä¼˜å…ˆ content å›é€€ summaryï¼Œå¹¶æ§åˆ¶æœ€å¤§é•¿åº¦ã€‚
    è¿”å› (è£å‰ªåçš„æ–‡æœ¬, åŸå§‹é•¿åº¦)ã€‚
    """
    parts: List[str] = []
    for a in articles:
        body = a.get('content') or a.get('summary') or ''
        title = a.get('title') or ''
        source = a.get('source') or ''
        published = a.get('published') or ''
        link = a.get('link') or ''
        parts.append(f"ã€{title}ã€‘\næ¥æº: {source} | æ—¶é—´: {published}\né“¾æ¥: {link}\n{body}\n\n")

    text_full = ''.join(parts)
    if max_chars and max_chars > 0 and len(text_full) > max_chars:
        return text_full[:max_chars], len(text_full)
    return text_full, len(text_full)


def call_gemini(api_key: str, content: str) -> str:
    """æŒ‰ä¼˜å…ˆçº§å°è¯•å¤šä¸ªæ¨¡å‹ï¼Œè¿”å› Markdown æ–‡æœ¬ã€‚"""
    if genai is None:
        raise SystemExit('æœªå®‰è£… google-generativeaiï¼Œè¯·å…ˆå®‰è£…æˆ–åœ¨ç¯å¢ƒä¸­æä¾›ã€‚')

    model_names = [
        'models/gemini-2.5-pro',
        'models/gemini-2.5-flash',
        'models/gemini-2.0-flash',
        'models/gemini-pro-latest'
    ]

    genai.configure(api_key=api_key)
    print(f'ğŸ¤– æ­£åœ¨ç”ŸæˆæŠ¥å‘Šï¼ˆè¾“å…¥é•¿åº¦ {len(content)} å­—ç¬¦ï¼‰')

    # è¯»å–æç¤ºè¯ï¼ˆå›ºå®šä½¿ç”¨ä¸“ä¸šç‰ˆï¼‰
    prompt_path = PROJECT_ROOT / 'task' / 'financial_analysis_prompt_pro.md'
    if not prompt_path.exists():
        raise SystemExit(f'æç¤ºè¯æ–‡ä»¶ä¸å­˜åœ¨: {prompt_path}')
    with open(prompt_path, 'r', encoding='utf-8') as f:
        system_prompt = f.read()

    last_error: Optional[Exception] = None
    for model_name in model_names:
        try:
            print(f'â†’ å°è¯•æ¨¡å‹: {model_name}')
            model = genai.GenerativeModel(model_name)
            resp = model.generate_content([system_prompt, content])
            print(f'âœ… æ¨¡å‹æˆåŠŸ: {model_name}')
            return resp.text
        except Exception as e:  # å°è¯•ä¸‹ä¸€ä¸ª
            last_error = e
            continue

    raise RuntimeError(f'æ‰€æœ‰æ¨¡å‹è°ƒç”¨å¤±è´¥ï¼Œæœ€åé”™è¯¯ï¼š{last_error}')


def save_markdown(date_str: str, markdown_text: str) -> Path:
    year_month = date_str[:7]
    report_dir = PROJECT_ROOT / 'docs' / 'archive' / year_month / date_str / 'reports'
    report_dir.mkdir(parents=True, exist_ok=True)
    now_str = datetime.now(pytz.timezone('Asia/Shanghai')).strftime('%Y-%m-%d %H:%M:%S')
    header = f"# ğŸ“… {date_str} è´¢ç»åˆ†ææŠ¥å‘Š\n\n> ğŸ“… ç”Ÿæˆæ—¶é—´: {now_str} (åŒ—äº¬æ—¶é—´)\n\n"
    content = header + (markdown_text or '').strip() + '\n'
    report_file = report_dir / f"ğŸ“… {date_str} è´¢ç»åˆ†ææŠ¥å‘Š.md"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(content)
    print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    return report_file


def write_json(path: Path, summary_md: str, articles: List[Dict[str, Any]]):
    data = {
        'summary_markdown': summary_md,
        'articles': articles
    }
    with open(path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    print(f'âœ… å·²å¯¼å‡º JSON: {path}')


def main():
    args = parse_args()
    start, end = resolve_date_range(args)
    print(f'ğŸš€ å¼€å§‹ AI åˆ†æï¼šæ—¥æœŸèŒƒå›´ {start} â†’ {end}')

    # è§£æé…ç½®æ–‡ä»¶ï¼Œä¼˜å…ˆé¡ºåºï¼šconfig.yml > --api-key > ç¯å¢ƒå˜é‡
    config_path = Path(args.config) if args.config else (PROJECT_ROOT / 'config' / 'config.yml')
    api_key: Optional[str] = None
    if config_path.exists():
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                cfg = yaml.safe_load(f) or {}
            # å¸¸è§å±‚çº§å…¼å®¹ï¼šapi_keys.gemini æˆ– gemini.api_key
            api_key = (
                (cfg.get('api_keys') or {}).get('gemini')
                or (cfg.get('gemini') or {}).get('api_key')
            )
            print(f'ğŸ”§ ä½¿ç”¨é…ç½®æ–‡ä»¶ï¼š{config_path}')
        except Exception as e:
            print(f'âš ï¸ è¯»å–é…ç½®å¤±è´¥ï¼ˆ{config_path}ï¼‰ï¼š{e}ï¼Œå°†å°è¯•ä½¿ç”¨å‘½ä»¤è¡Œæˆ–ç¯å¢ƒå˜é‡ã€‚')
    else:
        print(f'âš ï¸ æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶ï¼š{config_path}ï¼Œå°†å°è¯•ä½¿ç”¨å‘½ä»¤è¡Œæˆ–ç¯å¢ƒå˜é‡ã€‚')

    if not api_key:
        api_key = args.api_key or os.getenv('GEMINI_API_KEY')
    if not api_key:
        raise SystemExit("æœªåœ¨é…ç½®/å‚æ•°/ç¯å¢ƒä¸­æ‰¾åˆ° Gemini API Keyã€‚å¯åœ¨ config.yml çš„ api_keys.gemini æˆ– gemini.api_key é…ç½®ï¼Œæˆ–ä½¿ç”¨ --api-key / GEMINI_API_KEYã€‚")

    conn = open_connection(DB_PATH)
    try:
        rows = query_articles(conn, start, end, args.order, args.limit)
    finally:
        conn.close()

    if not rows:
        print('ï¼ˆæ— ç»“æœï¼‰æœªæ‰¾åˆ°æŒ‡å®šæ—¥æœŸèŒƒå›´çš„æ–‡ç« ï¼Œç»ˆæ­¢åˆ†æã€‚')
        return
    print(f'ğŸ“¥ å·²è¯»å–æ–‡ç« ï¼š{len(rows)} æ¡')

    corpus, total_len = build_corpus(rows, args.max_chars)
    print(f'ğŸ” è¯­æ–™é•¿åº¦: {len(corpus)} å­—ç¬¦ï¼ˆåŸå§‹ {total_len}ï¼Œmax={args.max_chars}ï¼‰')
    if args.max_chars and args.max_chars > 0 and total_len > args.max_chars:
        print(f'âœ‚ï¸ è¯­æ–™å·²æŒ‰ä¸Šé™æˆªæ–­ï¼š{total_len} â†’ {len(corpus)}')

    try:
        summary_md = call_gemini(api_key, corpus)
    except Exception as e:
        print(f'âŒ æ¨¡å‹è°ƒç”¨å¤±è´¥: {e}')
        return

    # ä¿å­˜ Markdown æŠ¥å‘Šï¼ˆæŒ‰ end æ—¥æœŸå‘½åï¼Œæ›´è´´è¿‘æ—¥æŠ¥è¯­ä¹‰ï¼‰
    saved_path = save_markdown(end, summary_md)

    # å¯é€‰å¯¼å‡º JSON
    if args.output_json:
        out_path = Path(args.output_json)
        if not out_path.is_absolute():
            out_path = PROJECT_ROOT / out_path
        write_json(out_path, summary_md, rows)

    print('ğŸ‰ åˆ†æå®Œæˆã€‚')


if __name__ == '__main__':
    main()


